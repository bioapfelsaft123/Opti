{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the needed Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import nbimporter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading the functions\n",
    "%run ./DayAhead_Problem1.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load all CSV files\n",
    "Demand_Data_Normalized = pd.read_csv('../Data/ModelData/Demand_YearlyDemandUtilityProfile_Normalized.csv', delimiter=',')\n",
    "Fuel_Cost_Data_Normalized = pd.read_csv('../Data/ModelData/FuelCost_PriceDevelopment50years.csv', delimiter=',')\n",
    "Generation_Data_Normalized = pd.read_csv('../Data/ModelData/VRE_YearlyGenerationProfile_Normalized.csv', delimiter=',')\n",
    "Generation_Asset_Data_Existing = pd.read_csv('../Data/ModelData/Generators_AssetData_Existing.csv', delimiter=',')\n",
    "Demand_Unit_Data = pd.read_csv('../Data/ModelData/Demand_UnitSpecificData.csv', delimiter=',')\n",
    "System_Demand = pd.read_csv('../Data/ModelData/System_Demand.csv', delimiter=',')\n",
    "Transmission_Capacity = pd.read_csv('../Data/ModelData/Transmission Capacity.csv', delimiter=',')\n",
    "Fuel_Cost_Absolute = pd.read_csv('../Data/ModelData/Fuel_Cost_Absolute.csv', delimiter=',')\n",
    "Demand_Developement = pd.read_csv('../Data/ModelData/Demand_Development.csv', delimiter=',')\n",
    "Generation_Asset_Data_New = pd.read_csv('../Data/ModelData/Generators_AssetData_New.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_Seasons = 5\n",
    "Number_of_Years = 2\n",
    "Number_of_Generators= len(Generation_Asset_Data_Existing)\n",
    "Number_of_Demand_Units = len(Demand_Unit_Data)\n",
    "Number_of_Price_Zones = 2\n",
    "Number_of_Hours = 24\n",
    "budget = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0x5b79c754\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 6e+02]\n",
      "Presolve removed 936 rows and 869 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 115 columns, 139 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.0799723e+07   1.629749e+03   0.000000e+00      0s\n",
      "      48    2.0673732e+07   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  2.067373189e+07\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0x46b37caa\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 6e+02]\n",
      "Presolve removed 936 rows and 891 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 93 columns, 117 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.5222967e+07   1.136704e+03   0.000000e+00      0s\n",
      "      48    1.5153098e+07   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  1.515309831e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0xcc05d914\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [8e+00, 6e+02]\n",
      "Presolve removed 936 rows and 870 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 114 columns, 138 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    7.9716643e+06   2.176472e+03   0.000000e+00      0s\n",
      "      48    7.8585378e+06   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  7.858537823e+06\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0x0c002cda\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [9e+00, 6e+02]\n",
      "Presolve removed 936 rows and 871 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 113 columns, 137 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    8.0849291e+06   2.100802e+03   0.000000e+00      0s\n",
      "      48    7.9752220e+06   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  7.975221958e+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0x49d9fa49\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 6e+02]\n",
      "Presolve removed 936 rows and 885 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 99 columns, 123 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.7996353e+07   1.217193e+03   0.000000e+00      0s\n",
      "      48    1.7906154e+07   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  1.790615391e+07\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Gas'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] = Generation_Asset_Data_Existing_Adjusted['C_i ($/MWh)'][g] * Fuel_Cost_Data_Normalized['Coal'][y] + Generation_Asset_Data_Existing_Adjusted['Emission Facor [t/MWh]'][g] * Fuel_Cost_Data_Normalized['Co2'][g]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_Residential'][d] = Demand_Developement['D_Residential'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_IndustryBase'][d] = Demand_Developement['D_IndustryBase'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\1086864082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Demand_Data_Normalized_Adjusted['D_ IndustryPeak'][d] = Demand_Developement['D_ IndustryPeak'][y]\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0xdd98a4f0\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [4e+01, 6e+02]\n",
      "Presolve removed 936 rows and 869 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 115 columns, 139 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.0911984e+07   1.651447e+03   0.000000e+00      0s\n",
      "      48    2.0781506e+07   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  2.078150596e+07\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0x6509b1b3\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 6e+02]\n",
      "Presolve removed 936 rows and 891 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 93 columns, 117 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.5206663e+07   1.136704e+03   0.000000e+00      0s\n",
      "      48    1.5135753e+07   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  1.513575265e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0x453c74e4\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [8e+00, 6e+02]\n",
      "Presolve removed 936 rows and 870 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 114 columns, 138 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    7.9617672e+06   2.176472e+03   0.000000e+00      0s\n",
      "      48    7.8444974e+06   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.02 seconds (0.00 work units)\n",
      "Optimal objective  7.844497368e+06\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0x0da0aa0e\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [9e+00, 6e+02]\n",
      "Presolve removed 936 rows and 871 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 113 columns, 137 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    8.0746927e+06   2.100802e+03   0.000000e+00      0s\n",
      "      48    7.9610953e+06   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  7.961095303e+06\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n",
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Demand_Normalized = pd.concat([Daily_Demand_Normalized, row_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 984 rows, 984 columns and 1920 nonzeros\n",
      "Model fingerprint: 0x76fad15f\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [5e+00, 1e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [3e+01, 6e+02]\n",
      "Presolve removed 936 rows and 885 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 48 rows, 99 columns, 123 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.7979117e+07   1.217193e+03   0.000000e+00      0s\n",
      "      48    1.7887566e+07   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 48 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  1.788756641e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonr\\AppData\\Local\\Temp\\ipykernel_11968\\3480306029.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Daily_Results = pd.concat([Daily_Results, pd.DataFrame([row_data])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "Yearly_Season_Daily_Results = LongTermMarketResults(Demand_Data_Normalized,\n",
    "                           Fuel_Cost_Data_Normalized,\n",
    "                           Generation_Data_Normalized,\n",
    "                           Generation_Asset_Data_Existing,\n",
    "                           Demand_Unit_Data,\n",
    "                           System_Demand,\n",
    "                           Transmission_Capacity,\n",
    "                           Demand_Developement,\n",
    "                           Number_of_Price_Zones,\n",
    "                           Number_of_Generators,\n",
    "                           Number_of_Demand_Units,\n",
    "                           Number_of_Years,\n",
    "                           Number_of_Seasons,\n",
    "                           Number_of_Hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of years:  2\n",
      "Amount of seasons:  5\n",
      "Amount of hours in a season:  24\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 5537 rows, 3856 columns and 10836 nonzeros\n",
      "Model fingerprint: 0x1df4e1c6\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-04, 2e+06]\n",
      "  Objective range  [1e+00, 2e+06]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+02, 1e+03]\n",
      "Presolve removed 3160 rows and 2661 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 2377 rows, 1195 columns, 4759 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0   -0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Use crossover to convert LP symmetric solution to basic solution...\n",
      "Crossover log...\n",
      "\n",
      "       0 DPushes remaining with DInf 0.0000000e+00                 0s\n",
      "\n",
      "       0 PPushes remaining with PInf 0.0000000e+00                 0s\n",
      "\n",
      "  Push phase complete: Pinf 0.0000000e+00, Dinf 0.0000000e+00      0s\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       3   -0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 3 iterations and 0.04 seconds (0.01 work units)\n",
      "Optimal objective -0.000000000e+00\n",
      "Inv_NewCap[0] 0\n",
      "Inv_NewCap[1] 0\n",
      "Inv_NewCap[2] 0\n",
      "Inv_NewCap[3] 0\n",
      "Inv_NewCap[4] 0\n",
      "Inv_NewCap[5] 0\n",
      "Inv_NewCap[6] 0\n",
      "Inv_NewCap[7] 0\n",
      "Inv_NewCap[8] 0\n",
      "Inv_NewCap[9] 0\n",
      "Inv_NewCap[10] 0\n",
      "Inv_NewCap[11] 0\n",
      "Inv_NewCap[12] 0\n",
      "Inv_NewCap[13] 0\n",
      "Inv_NewCap[14] 0\n",
      "Inv_NewCap[15] 0\n",
      "P_NewCap[0,0,0,0] 0\n",
      "P_NewCap[0,0,0,1] 0\n",
      "P_NewCap[0,0,0,2] 0\n",
      "P_NewCap[0,0,0,3] 0\n",
      "P_NewCap[0,0,0,4] 0\n",
      "P_NewCap[0,0,0,5] 0\n",
      "P_NewCap[0,0,0,6] 0\n",
      "P_NewCap[0,0,0,7] 0\n",
      "P_NewCap[0,0,0,8] 0\n",
      "P_NewCap[0,0,0,9] 0\n",
      "P_NewCap[0,0,0,10] 0\n",
      "P_NewCap[0,0,0,11] 0\n",
      "P_NewCap[0,0,0,12] 0\n",
      "P_NewCap[0,0,0,13] 0\n",
      "P_NewCap[0,0,0,14] 0\n",
      "P_NewCap[0,0,0,15] 0\n",
      "P_NewCap[0,0,0,16] 0\n",
      "P_NewCap[0,0,0,17] 0\n",
      "P_NewCap[0,0,0,18] 0\n",
      "P_NewCap[0,0,0,19] 0\n",
      "P_NewCap[0,0,0,20] 0\n",
      "P_NewCap[0,0,0,21] 0\n",
      "P_NewCap[0,0,0,22] 0\n",
      "P_NewCap[0,0,0,23] 0\n",
      "P_NewCap[0,0,1,0] 0\n",
      "P_NewCap[0,0,1,1] 0\n",
      "P_NewCap[0,0,1,2] 0\n",
      "P_NewCap[0,0,1,3] 0\n",
      "P_NewCap[0,0,1,4] 0\n",
      "P_NewCap[0,0,1,5] 0\n",
      "P_NewCap[0,0,1,6] 0\n",
      "P_NewCap[0,0,1,7] 0\n",
      "P_NewCap[0,0,1,8] 0\n",
      "P_NewCap[0,0,1,9] 0\n",
      "P_NewCap[0,0,1,10] 0\n",
      "P_NewCap[0,0,1,11] 0\n",
      "P_NewCap[0,0,1,12] 0\n",
      "P_NewCap[0,0,1,13] 0\n",
      "P_NewCap[0,0,1,14] 0\n",
      "P_NewCap[0,0,1,15] 0\n",
      "P_NewCap[0,0,1,16] 0\n",
      "P_NewCap[0,0,1,17] 0\n",
      "P_NewCap[0,0,1,18] 0\n",
      "P_NewCap[0,0,1,19] 0\n",
      "P_NewCap[0,0,1,20] 0\n",
      "P_NewCap[0,0,1,21] 0\n",
      "P_NewCap[0,0,1,22] 0\n",
      "P_NewCap[0,0,1,23] 0\n",
      "P_NewCap[0,0,2,0] 0\n",
      "P_NewCap[0,0,2,1] 0\n",
      "P_NewCap[0,0,2,2] 0\n",
      "P_NewCap[0,0,2,3] 0\n",
      "P_NewCap[0,0,2,4] 0\n",
      "P_NewCap[0,0,2,5] 0\n",
      "P_NewCap[0,0,2,6] 0\n",
      "P_NewCap[0,0,2,7] 0\n",
      "P_NewCap[0,0,2,8] 0\n",
      "P_NewCap[0,0,2,9] 0\n",
      "P_NewCap[0,0,2,10] 0\n",
      "P_NewCap[0,0,2,11] 0\n",
      "P_NewCap[0,0,2,12] 0\n",
      "P_NewCap[0,0,2,13] 0\n",
      "P_NewCap[0,0,2,14] 0\n",
      "P_NewCap[0,0,2,15] 0\n",
      "P_NewCap[0,0,2,16] 0\n",
      "P_NewCap[0,0,2,17] 0\n",
      "P_NewCap[0,0,2,18] 0\n",
      "P_NewCap[0,0,2,19] 0\n",
      "P_NewCap[0,0,2,20] 0\n",
      "P_NewCap[0,0,2,21] 0\n",
      "P_NewCap[0,0,2,22] 0\n",
      "P_NewCap[0,0,2,23] 0\n",
      "P_NewCap[0,0,3,0] 0\n",
      "P_NewCap[0,0,3,1] 0\n",
      "P_NewCap[0,0,3,2] 0\n",
      "P_NewCap[0,0,3,3] 0\n",
      "P_NewCap[0,0,3,4] 0\n",
      "P_NewCap[0,0,3,5] 0\n",
      "P_NewCap[0,0,3,6] 0\n",
      "P_NewCap[0,0,3,7] 0\n",
      "P_NewCap[0,0,3,8] 0\n",
      "P_NewCap[0,0,3,9] 0\n",
      "P_NewCap[0,0,3,10] 0\n",
      "P_NewCap[0,0,3,11] 0\n",
      "P_NewCap[0,0,3,12] 0\n",
      "P_NewCap[0,0,3,13] 0\n",
      "P_NewCap[0,0,3,14] 0\n",
      "P_NewCap[0,0,3,15] 0\n",
      "P_NewCap[0,0,3,16] 0\n",
      "P_NewCap[0,0,3,17] 0\n",
      "P_NewCap[0,0,3,18] 0\n",
      "P_NewCap[0,0,3,19] 0\n",
      "P_NewCap[0,0,3,20] 0\n",
      "P_NewCap[0,0,3,21] 0\n",
      "P_NewCap[0,0,3,22] 0\n",
      "P_NewCap[0,0,3,23] 0\n",
      "P_NewCap[0,0,4,0] 0\n",
      "P_NewCap[0,0,4,1] 0\n",
      "P_NewCap[0,0,4,2] 0\n",
      "P_NewCap[0,0,4,3] 0\n",
      "P_NewCap[0,0,4,4] 0\n",
      "P_NewCap[0,0,4,5] 0\n",
      "P_NewCap[0,0,4,6] 0\n",
      "P_NewCap[0,0,4,7] 0\n",
      "P_NewCap[0,0,4,8] 0\n",
      "P_NewCap[0,0,4,9] 0\n",
      "P_NewCap[0,0,4,10] 0\n",
      "P_NewCap[0,0,4,11] 0\n",
      "P_NewCap[0,0,4,12] 0\n",
      "P_NewCap[0,0,4,13] 0\n",
      "P_NewCap[0,0,4,14] 0\n",
      "P_NewCap[0,0,4,15] 0\n",
      "P_NewCap[0,0,4,16] 0\n",
      "P_NewCap[0,0,4,17] 0\n",
      "P_NewCap[0,0,4,18] 0\n",
      "P_NewCap[0,0,4,19] 0\n",
      "P_NewCap[0,0,4,20] 0\n",
      "P_NewCap[0,0,4,21] 0\n",
      "P_NewCap[0,0,4,22] 0\n",
      "P_NewCap[0,0,4,23] 0\n",
      "P_NewCap[0,1,0,0] 0\n",
      "P_NewCap[0,1,0,1] 0\n",
      "P_NewCap[0,1,0,2] 0\n",
      "P_NewCap[0,1,0,3] 0\n",
      "P_NewCap[0,1,0,4] 0\n",
      "P_NewCap[0,1,0,5] 0\n",
      "P_NewCap[0,1,0,6] 0\n",
      "P_NewCap[0,1,0,7] 0\n",
      "P_NewCap[0,1,0,8] 0\n",
      "P_NewCap[0,1,0,9] 0\n",
      "P_NewCap[0,1,0,10] 0\n",
      "P_NewCap[0,1,0,11] 0\n",
      "P_NewCap[0,1,0,12] 0\n",
      "P_NewCap[0,1,0,13] 0\n",
      "P_NewCap[0,1,0,14] 0\n",
      "P_NewCap[0,1,0,15] 0\n",
      "P_NewCap[0,1,0,16] 0\n",
      "P_NewCap[0,1,0,17] 0\n",
      "P_NewCap[0,1,0,18] 0\n",
      "P_NewCap[0,1,0,19] 0\n",
      "P_NewCap[0,1,0,20] 0\n",
      "P_NewCap[0,1,0,21] 0\n",
      "P_NewCap[0,1,0,22] 0\n",
      "P_NewCap[0,1,0,23] 0\n",
      "P_NewCap[0,1,1,0] 0\n",
      "P_NewCap[0,1,1,1] 0\n",
      "P_NewCap[0,1,1,2] 0\n",
      "P_NewCap[0,1,1,3] 0\n",
      "P_NewCap[0,1,1,4] 0\n",
      "P_NewCap[0,1,1,5] 0\n",
      "P_NewCap[0,1,1,6] 0\n",
      "P_NewCap[0,1,1,7] 0\n",
      "P_NewCap[0,1,1,8] 0\n",
      "P_NewCap[0,1,1,9] 0\n",
      "P_NewCap[0,1,1,10] 0\n",
      "P_NewCap[0,1,1,11] 0\n",
      "P_NewCap[0,1,1,12] 0\n",
      "P_NewCap[0,1,1,13] 0\n",
      "P_NewCap[0,1,1,14] 0\n",
      "P_NewCap[0,1,1,15] 0\n",
      "P_NewCap[0,1,1,16] 0\n",
      "P_NewCap[0,1,1,17] 0\n",
      "P_NewCap[0,1,1,18] 0\n",
      "P_NewCap[0,1,1,19] 0\n",
      "P_NewCap[0,1,1,20] 0\n",
      "P_NewCap[0,1,1,21] 0\n",
      "P_NewCap[0,1,1,22] 0\n",
      "P_NewCap[0,1,1,23] 0\n",
      "P_NewCap[0,1,2,0] 0\n",
      "P_NewCap[0,1,2,1] 0\n",
      "P_NewCap[0,1,2,2] 0\n",
      "P_NewCap[0,1,2,3] 0\n",
      "P_NewCap[0,1,2,4] 0\n",
      "P_NewCap[0,1,2,5] 0\n",
      "P_NewCap[0,1,2,6] 0\n",
      "P_NewCap[0,1,2,7] 0\n",
      "P_NewCap[0,1,2,8] 0\n",
      "P_NewCap[0,1,2,9] 0\n",
      "P_NewCap[0,1,2,10] 0\n",
      "P_NewCap[0,1,2,11] 0\n",
      "P_NewCap[0,1,2,12] 0\n",
      "P_NewCap[0,1,2,13] 0\n",
      "P_NewCap[0,1,2,14] 0\n",
      "P_NewCap[0,1,2,15] 0\n",
      "P_NewCap[0,1,2,16] 0\n",
      "P_NewCap[0,1,2,17] 0\n",
      "P_NewCap[0,1,2,18] 0\n",
      "P_NewCap[0,1,2,19] 0\n",
      "P_NewCap[0,1,2,20] 0\n",
      "P_NewCap[0,1,2,21] 0\n",
      "P_NewCap[0,1,2,22] 0\n",
      "P_NewCap[0,1,2,23] 0\n",
      "P_NewCap[0,1,3,0] 0\n",
      "P_NewCap[0,1,3,1] 0\n",
      "P_NewCap[0,1,3,2] 0\n",
      "P_NewCap[0,1,3,3] 0\n",
      "P_NewCap[0,1,3,4] 0\n",
      "P_NewCap[0,1,3,5] 0\n",
      "P_NewCap[0,1,3,6] 0\n",
      "P_NewCap[0,1,3,7] 0\n",
      "P_NewCap[0,1,3,8] 0\n",
      "P_NewCap[0,1,3,9] 0\n",
      "P_NewCap[0,1,3,10] 0\n",
      "P_NewCap[0,1,3,11] 0\n",
      "P_NewCap[0,1,3,12] 0\n",
      "P_NewCap[0,1,3,13] 0\n",
      "P_NewCap[0,1,3,14] 0\n",
      "P_NewCap[0,1,3,15] 0\n",
      "P_NewCap[0,1,3,16] 0\n",
      "P_NewCap[0,1,3,17] 0\n",
      "P_NewCap[0,1,3,18] 0\n",
      "P_NewCap[0,1,3,19] 0\n",
      "P_NewCap[0,1,3,20] 0\n",
      "P_NewCap[0,1,3,21] 0\n",
      "P_NewCap[0,1,3,22] 0\n",
      "P_NewCap[0,1,3,23] 0\n",
      "P_NewCap[0,1,4,0] 0\n",
      "P_NewCap[0,1,4,1] 0\n",
      "P_NewCap[0,1,4,2] 0\n",
      "P_NewCap[0,1,4,3] 0\n",
      "P_NewCap[0,1,4,4] 0\n",
      "P_NewCap[0,1,4,5] 0\n",
      "P_NewCap[0,1,4,6] 0\n",
      "P_NewCap[0,1,4,7] 0\n",
      "P_NewCap[0,1,4,8] 0\n",
      "P_NewCap[0,1,4,9] 0\n",
      "P_NewCap[0,1,4,10] 0\n",
      "P_NewCap[0,1,4,11] 0\n",
      "P_NewCap[0,1,4,12] 0\n",
      "P_NewCap[0,1,4,13] 0\n",
      "P_NewCap[0,1,4,14] 0\n",
      "P_NewCap[0,1,4,15] 0\n",
      "P_NewCap[0,1,4,16] 0\n",
      "P_NewCap[0,1,4,17] 0\n",
      "P_NewCap[0,1,4,18] 0\n",
      "P_NewCap[0,1,4,19] 0\n",
      "P_NewCap[0,1,4,20] 0\n",
      "P_NewCap[0,1,4,21] 0\n",
      "P_NewCap[0,1,4,22] 0\n",
      "P_NewCap[0,1,4,23] 0\n",
      "P_NewCap[1,0,0,0] 0\n",
      "P_NewCap[1,0,0,1] 0\n",
      "P_NewCap[1,0,0,2] 0\n",
      "P_NewCap[1,0,0,3] 0\n",
      "P_NewCap[1,0,0,4] 0\n",
      "P_NewCap[1,0,0,5] 0\n",
      "P_NewCap[1,0,0,6] 0\n",
      "P_NewCap[1,0,0,7] 0\n",
      "P_NewCap[1,0,0,8] 0\n",
      "P_NewCap[1,0,0,9] 0\n",
      "P_NewCap[1,0,0,10] 0\n",
      "P_NewCap[1,0,0,11] 0\n",
      "P_NewCap[1,0,0,12] 0\n",
      "P_NewCap[1,0,0,13] 0\n",
      "P_NewCap[1,0,0,14] 0\n",
      "P_NewCap[1,0,0,15] 0\n",
      "P_NewCap[1,0,0,16] 0\n",
      "P_NewCap[1,0,0,17] 0\n",
      "P_NewCap[1,0,0,18] 0\n",
      "P_NewCap[1,0,0,19] 0\n",
      "P_NewCap[1,0,0,20] 0\n",
      "P_NewCap[1,0,0,21] 0\n",
      "P_NewCap[1,0,0,22] 0\n",
      "P_NewCap[1,0,0,23] 0\n",
      "P_NewCap[1,0,1,0] 0\n",
      "P_NewCap[1,0,1,1] 0\n",
      "P_NewCap[1,0,1,2] 0\n",
      "P_NewCap[1,0,1,3] 0\n",
      "P_NewCap[1,0,1,4] 0\n",
      "P_NewCap[1,0,1,5] 0\n",
      "P_NewCap[1,0,1,6] 0\n",
      "P_NewCap[1,0,1,7] 0\n",
      "P_NewCap[1,0,1,8] 0\n",
      "P_NewCap[1,0,1,9] 0\n",
      "P_NewCap[1,0,1,10] 0\n",
      "P_NewCap[1,0,1,11] 0\n",
      "P_NewCap[1,0,1,12] 0\n",
      "P_NewCap[1,0,1,13] 0\n",
      "P_NewCap[1,0,1,14] 0\n",
      "P_NewCap[1,0,1,15] 0\n",
      "P_NewCap[1,0,1,16] 0\n",
      "P_NewCap[1,0,1,17] 0\n",
      "P_NewCap[1,0,1,18] 0\n",
      "P_NewCap[1,0,1,19] 0\n",
      "P_NewCap[1,0,1,20] 0\n",
      "P_NewCap[1,0,1,21] 0\n",
      "P_NewCap[1,0,1,22] 0\n",
      "P_NewCap[1,0,1,23] 0\n",
      "P_NewCap[1,0,2,0] 0\n",
      "P_NewCap[1,0,2,1] 0\n",
      "P_NewCap[1,0,2,2] 0\n",
      "P_NewCap[1,0,2,3] 0\n",
      "P_NewCap[1,0,2,4] 0\n",
      "P_NewCap[1,0,2,5] 0\n",
      "P_NewCap[1,0,2,6] 0\n",
      "P_NewCap[1,0,2,7] 0\n",
      "P_NewCap[1,0,2,8] 0\n",
      "P_NewCap[1,0,2,9] 0\n",
      "P_NewCap[1,0,2,10] 0\n",
      "P_NewCap[1,0,2,11] 0\n",
      "P_NewCap[1,0,2,12] 0\n",
      "P_NewCap[1,0,2,13] 0\n",
      "P_NewCap[1,0,2,14] 0\n",
      "P_NewCap[1,0,2,15] 0\n",
      "P_NewCap[1,0,2,16] 0\n",
      "P_NewCap[1,0,2,17] 0\n",
      "P_NewCap[1,0,2,18] 0\n",
      "P_NewCap[1,0,2,19] 0\n",
      "P_NewCap[1,0,2,20] 0\n",
      "P_NewCap[1,0,2,21] 0\n",
      "P_NewCap[1,0,2,22] 0\n",
      "P_NewCap[1,0,2,23] 0\n",
      "P_NewCap[1,0,3,0] 0\n",
      "P_NewCap[1,0,3,1] 0\n",
      "P_NewCap[1,0,3,2] 0\n",
      "P_NewCap[1,0,3,3] 0\n",
      "P_NewCap[1,0,3,4] 0\n",
      "P_NewCap[1,0,3,5] 0\n",
      "P_NewCap[1,0,3,6] 0\n",
      "P_NewCap[1,0,3,7] 0\n",
      "P_NewCap[1,0,3,8] 0\n",
      "P_NewCap[1,0,3,9] 0\n",
      "P_NewCap[1,0,3,10] 0\n",
      "P_NewCap[1,0,3,11] 0\n",
      "P_NewCap[1,0,3,12] 0\n",
      "P_NewCap[1,0,3,13] 0\n",
      "P_NewCap[1,0,3,14] 0\n",
      "P_NewCap[1,0,3,15] 0\n",
      "P_NewCap[1,0,3,16] 0\n",
      "P_NewCap[1,0,3,17] 0\n",
      "P_NewCap[1,0,3,18] 0\n",
      "P_NewCap[1,0,3,19] 0\n",
      "P_NewCap[1,0,3,20] 0\n",
      "P_NewCap[1,0,3,21] 0\n",
      "P_NewCap[1,0,3,22] 0\n",
      "P_NewCap[1,0,3,23] 0\n",
      "P_NewCap[1,0,4,0] 0\n",
      "P_NewCap[1,0,4,1] 0\n",
      "P_NewCap[1,0,4,2] 0\n",
      "P_NewCap[1,0,4,3] 0\n",
      "P_NewCap[1,0,4,4] 0\n",
      "P_NewCap[1,0,4,5] 0\n",
      "P_NewCap[1,0,4,6] 0\n",
      "P_NewCap[1,0,4,7] 0\n",
      "P_NewCap[1,0,4,8] 0\n",
      "P_NewCap[1,0,4,9] 0\n",
      "P_NewCap[1,0,4,10] 0\n",
      "P_NewCap[1,0,4,11] 0\n",
      "P_NewCap[1,0,4,12] 0\n",
      "P_NewCap[1,0,4,13] 0\n",
      "P_NewCap[1,0,4,14] 0\n",
      "P_NewCap[1,0,4,15] 0\n",
      "P_NewCap[1,0,4,16] 0\n",
      "P_NewCap[1,0,4,17] 0\n",
      "P_NewCap[1,0,4,18] 0\n",
      "P_NewCap[1,0,4,19] 0\n",
      "P_NewCap[1,0,4,20] 0\n",
      "P_NewCap[1,0,4,21] 0\n",
      "P_NewCap[1,0,4,22] 0\n",
      "P_NewCap[1,0,4,23] 0\n",
      "P_NewCap[1,1,0,0] 0\n",
      "P_NewCap[1,1,0,1] 0\n",
      "P_NewCap[1,1,0,2] 0\n",
      "P_NewCap[1,1,0,3] 0\n",
      "P_NewCap[1,1,0,4] 0\n",
      "P_NewCap[1,1,0,5] 0\n",
      "P_NewCap[1,1,0,6] 0\n",
      "P_NewCap[1,1,0,7] 0\n",
      "P_NewCap[1,1,0,8] 0\n",
      "P_NewCap[1,1,0,9] 0\n",
      "P_NewCap[1,1,0,10] 0\n",
      "P_NewCap[1,1,0,11] 0\n",
      "P_NewCap[1,1,0,12] 0\n",
      "P_NewCap[1,1,0,13] 0\n",
      "P_NewCap[1,1,0,14] 0\n",
      "P_NewCap[1,1,0,15] 0\n",
      "P_NewCap[1,1,0,16] 0\n",
      "P_NewCap[1,1,0,17] 0\n",
      "P_NewCap[1,1,0,18] 0\n",
      "P_NewCap[1,1,0,19] 0\n",
      "P_NewCap[1,1,0,20] 0\n",
      "P_NewCap[1,1,0,21] 0\n",
      "P_NewCap[1,1,0,22] 0\n",
      "P_NewCap[1,1,0,23] 0\n",
      "P_NewCap[1,1,1,0] 0\n",
      "P_NewCap[1,1,1,1] 0\n",
      "P_NewCap[1,1,1,2] 0\n",
      "P_NewCap[1,1,1,3] 0\n",
      "P_NewCap[1,1,1,4] 0\n",
      "P_NewCap[1,1,1,5] 0\n",
      "P_NewCap[1,1,1,6] 0\n",
      "P_NewCap[1,1,1,7] 0\n",
      "P_NewCap[1,1,1,8] 0\n",
      "P_NewCap[1,1,1,9] 0\n",
      "P_NewCap[1,1,1,10] 0\n",
      "P_NewCap[1,1,1,11] 0\n",
      "P_NewCap[1,1,1,12] 0\n",
      "P_NewCap[1,1,1,13] 0\n",
      "P_NewCap[1,1,1,14] 0\n",
      "P_NewCap[1,1,1,15] 0\n",
      "P_NewCap[1,1,1,16] 0\n",
      "P_NewCap[1,1,1,17] 0\n",
      "P_NewCap[1,1,1,18] 0\n",
      "P_NewCap[1,1,1,19] 0\n",
      "P_NewCap[1,1,1,20] 0\n",
      "P_NewCap[1,1,1,21] 0\n",
      "P_NewCap[1,1,1,22] 0\n",
      "P_NewCap[1,1,1,23] 0\n",
      "P_NewCap[1,1,2,0] 0\n",
      "P_NewCap[1,1,2,1] 0\n",
      "P_NewCap[1,1,2,2] 0\n",
      "P_NewCap[1,1,2,3] 0\n",
      "P_NewCap[1,1,2,4] 0\n",
      "P_NewCap[1,1,2,5] 0\n",
      "P_NewCap[1,1,2,6] 0\n",
      "P_NewCap[1,1,2,7] 0\n",
      "P_NewCap[1,1,2,8] 0\n",
      "P_NewCap[1,1,2,9] 0\n",
      "P_NewCap[1,1,2,10] 0\n",
      "P_NewCap[1,1,2,11] 0\n",
      "P_NewCap[1,1,2,12] 0\n",
      "P_NewCap[1,1,2,13] 0\n",
      "P_NewCap[1,1,2,14] 0\n",
      "P_NewCap[1,1,2,15] 0\n",
      "P_NewCap[1,1,2,16] 0\n",
      "P_NewCap[1,1,2,17] 0\n",
      "P_NewCap[1,1,2,18] 0\n",
      "P_NewCap[1,1,2,19] 0\n",
      "P_NewCap[1,1,2,20] 0\n",
      "P_NewCap[1,1,2,21] 0\n",
      "P_NewCap[1,1,2,22] 0\n",
      "P_NewCap[1,1,2,23] 0\n",
      "P_NewCap[1,1,3,0] 0\n",
      "P_NewCap[1,1,3,1] 0\n",
      "P_NewCap[1,1,3,2] 0\n",
      "P_NewCap[1,1,3,3] 0\n",
      "P_NewCap[1,1,3,4] 0\n",
      "P_NewCap[1,1,3,5] 0\n",
      "P_NewCap[1,1,3,6] 0\n",
      "P_NewCap[1,1,3,7] 0\n",
      "P_NewCap[1,1,3,8] 0\n",
      "P_NewCap[1,1,3,9] 0\n",
      "P_NewCap[1,1,3,10] 0\n",
      "P_NewCap[1,1,3,11] 0\n",
      "P_NewCap[1,1,3,12] 0\n",
      "P_NewCap[1,1,3,13] 0\n",
      "P_NewCap[1,1,3,14] 0\n",
      "P_NewCap[1,1,3,15] 0\n",
      "P_NewCap[1,1,3,16] 0\n",
      "P_NewCap[1,1,3,17] 0\n",
      "P_NewCap[1,1,3,18] 0\n",
      "P_NewCap[1,1,3,19] 0\n",
      "P_NewCap[1,1,3,20] 0\n",
      "P_NewCap[1,1,3,21] 0\n",
      "P_NewCap[1,1,3,22] 0\n",
      "P_NewCap[1,1,3,23] 0\n",
      "P_NewCap[1,1,4,0] 0\n",
      "P_NewCap[1,1,4,1] 0\n",
      "P_NewCap[1,1,4,2] 0\n",
      "P_NewCap[1,1,4,3] 0\n",
      "P_NewCap[1,1,4,4] 0\n",
      "P_NewCap[1,1,4,5] 0\n",
      "P_NewCap[1,1,4,6] 0\n",
      "P_NewCap[1,1,4,7] 0\n",
      "P_NewCap[1,1,4,8] 0\n",
      "P_NewCap[1,1,4,9] 0\n",
      "P_NewCap[1,1,4,10] 0\n",
      "P_NewCap[1,1,4,11] 0\n",
      "P_NewCap[1,1,4,12] 0\n",
      "P_NewCap[1,1,4,13] 0\n",
      "P_NewCap[1,1,4,14] 0\n",
      "P_NewCap[1,1,4,15] 0\n",
      "P_NewCap[1,1,4,16] 0\n",
      "P_NewCap[1,1,4,17] 0\n",
      "P_NewCap[1,1,4,18] 0\n",
      "P_NewCap[1,1,4,19] 0\n",
      "P_NewCap[1,1,4,20] 0\n",
      "P_NewCap[1,1,4,21] 0\n",
      "P_NewCap[1,1,4,22] 0\n",
      "P_NewCap[1,1,4,23] 0\n",
      "P_NewCap[2,0,0,0] 0\n",
      "P_NewCap[2,0,0,1] 0\n",
      "P_NewCap[2,0,0,2] 0\n",
      "P_NewCap[2,0,0,3] 0\n",
      "P_NewCap[2,0,0,4] 0\n",
      "P_NewCap[2,0,0,5] 0\n",
      "P_NewCap[2,0,0,6] 0\n",
      "P_NewCap[2,0,0,7] 0\n",
      "P_NewCap[2,0,0,8] 0\n",
      "P_NewCap[2,0,0,9] 0\n",
      "P_NewCap[2,0,0,10] 0\n",
      "P_NewCap[2,0,0,11] 0\n",
      "P_NewCap[2,0,0,12] 0\n",
      "P_NewCap[2,0,0,13] 0\n",
      "P_NewCap[2,0,0,14] 0\n",
      "P_NewCap[2,0,0,15] 0\n",
      "P_NewCap[2,0,0,16] 0\n",
      "P_NewCap[2,0,0,17] 0\n",
      "P_NewCap[2,0,0,18] 0\n",
      "P_NewCap[2,0,0,19] 0\n",
      "P_NewCap[2,0,0,20] 0\n",
      "P_NewCap[2,0,0,21] 0\n",
      "P_NewCap[2,0,0,22] 0\n",
      "P_NewCap[2,0,0,23] 0\n",
      "P_NewCap[2,0,1,0] 0\n",
      "P_NewCap[2,0,1,1] 0\n",
      "P_NewCap[2,0,1,2] 0\n",
      "P_NewCap[2,0,1,3] 0\n",
      "P_NewCap[2,0,1,4] 0\n",
      "P_NewCap[2,0,1,5] 0\n",
      "P_NewCap[2,0,1,6] 0\n",
      "P_NewCap[2,0,1,7] 0\n",
      "P_NewCap[2,0,1,8] 0\n",
      "P_NewCap[2,0,1,9] 0\n",
      "P_NewCap[2,0,1,10] 0\n",
      "P_NewCap[2,0,1,11] 0\n",
      "P_NewCap[2,0,1,12] 0\n",
      "P_NewCap[2,0,1,13] 0\n",
      "P_NewCap[2,0,1,14] 0\n",
      "P_NewCap[2,0,1,15] 0\n",
      "P_NewCap[2,0,1,16] 0\n",
      "P_NewCap[2,0,1,17] 0\n",
      "P_NewCap[2,0,1,18] 0\n",
      "P_NewCap[2,0,1,19] 0\n",
      "P_NewCap[2,0,1,20] 0\n",
      "P_NewCap[2,0,1,21] 0\n",
      "P_NewCap[2,0,1,22] 0\n",
      "P_NewCap[2,0,1,23] 0\n",
      "P_NewCap[2,0,2,0] 0\n",
      "P_NewCap[2,0,2,1] 0\n",
      "P_NewCap[2,0,2,2] 0\n",
      "P_NewCap[2,0,2,3] 0\n",
      "P_NewCap[2,0,2,4] 0\n",
      "P_NewCap[2,0,2,5] 0\n",
      "P_NewCap[2,0,2,6] 0\n",
      "P_NewCap[2,0,2,7] 0\n",
      "P_NewCap[2,0,2,8] 0\n",
      "P_NewCap[2,0,2,9] 0\n",
      "P_NewCap[2,0,2,10] 0\n",
      "P_NewCap[2,0,2,11] 0\n",
      "P_NewCap[2,0,2,12] 0\n",
      "P_NewCap[2,0,2,13] 0\n",
      "P_NewCap[2,0,2,14] 0\n",
      "P_NewCap[2,0,2,15] 0\n",
      "P_NewCap[2,0,2,16] 0\n",
      "P_NewCap[2,0,2,17] 0\n",
      "P_NewCap[2,0,2,18] 0\n",
      "P_NewCap[2,0,2,19] 0\n",
      "P_NewCap[2,0,2,20] 0\n",
      "P_NewCap[2,0,2,21] 0\n",
      "P_NewCap[2,0,2,22] 0\n",
      "P_NewCap[2,0,2,23] 0\n",
      "P_NewCap[2,0,3,0] 0\n",
      "P_NewCap[2,0,3,1] 0\n",
      "P_NewCap[2,0,3,2] 0\n",
      "P_NewCap[2,0,3,3] 0\n",
      "P_NewCap[2,0,3,4] 0\n",
      "P_NewCap[2,0,3,5] 0\n",
      "P_NewCap[2,0,3,6] 0\n",
      "P_NewCap[2,0,3,7] 0\n",
      "P_NewCap[2,0,3,8] 0\n",
      "P_NewCap[2,0,3,9] 0\n",
      "P_NewCap[2,0,3,10] 0\n",
      "P_NewCap[2,0,3,11] 0\n",
      "P_NewCap[2,0,3,12] 0\n",
      "P_NewCap[2,0,3,13] 0\n",
      "P_NewCap[2,0,3,14] 0\n",
      "P_NewCap[2,0,3,15] 0\n",
      "P_NewCap[2,0,3,16] 0\n",
      "P_NewCap[2,0,3,17] 0\n",
      "P_NewCap[2,0,3,18] 0\n",
      "P_NewCap[2,0,3,19] 0\n",
      "P_NewCap[2,0,3,20] 0\n",
      "P_NewCap[2,0,3,21] 0\n",
      "P_NewCap[2,0,3,22] 0\n",
      "P_NewCap[2,0,3,23] 0\n",
      "P_NewCap[2,0,4,0] 0\n",
      "P_NewCap[2,0,4,1] 0\n",
      "P_NewCap[2,0,4,2] 0\n",
      "P_NewCap[2,0,4,3] 0\n",
      "P_NewCap[2,0,4,4] 0\n",
      "P_NewCap[2,0,4,5] 0\n",
      "P_NewCap[2,0,4,6] 0\n",
      "P_NewCap[2,0,4,7] 0\n",
      "P_NewCap[2,0,4,8] 0\n",
      "P_NewCap[2,0,4,9] 0\n",
      "P_NewCap[2,0,4,10] 0\n",
      "P_NewCap[2,0,4,11] 0\n",
      "P_NewCap[2,0,4,12] 0\n",
      "P_NewCap[2,0,4,13] 0\n",
      "P_NewCap[2,0,4,14] 0\n",
      "P_NewCap[2,0,4,15] 0\n",
      "P_NewCap[2,0,4,16] 0\n",
      "P_NewCap[2,0,4,17] 0\n",
      "P_NewCap[2,0,4,18] 0\n",
      "P_NewCap[2,0,4,19] 0\n",
      "P_NewCap[2,0,4,20] 0\n",
      "P_NewCap[2,0,4,21] 0\n",
      "P_NewCap[2,0,4,22] 0\n",
      "P_NewCap[2,0,4,23] 0\n",
      "P_NewCap[2,1,0,0] 0\n",
      "P_NewCap[2,1,0,1] 0\n",
      "P_NewCap[2,1,0,2] 0\n",
      "P_NewCap[2,1,0,3] 0\n",
      "P_NewCap[2,1,0,4] 0\n",
      "P_NewCap[2,1,0,5] 0\n",
      "P_NewCap[2,1,0,6] 0\n",
      "P_NewCap[2,1,0,7] 0\n",
      "P_NewCap[2,1,0,8] 0\n",
      "P_NewCap[2,1,0,9] 0\n",
      "P_NewCap[2,1,0,10] 0\n",
      "P_NewCap[2,1,0,11] 0\n",
      "P_NewCap[2,1,0,12] 0\n",
      "P_NewCap[2,1,0,13] 0\n",
      "P_NewCap[2,1,0,14] 0\n",
      "P_NewCap[2,1,0,15] 0\n",
      "P_NewCap[2,1,0,16] 0\n",
      "P_NewCap[2,1,0,17] 0\n",
      "P_NewCap[2,1,0,18] 0\n",
      "P_NewCap[2,1,0,19] 0\n",
      "P_NewCap[2,1,0,20] 0\n",
      "P_NewCap[2,1,0,21] 0\n",
      "P_NewCap[2,1,0,22] 0\n",
      "P_NewCap[2,1,0,23] 0\n",
      "P_NewCap[2,1,1,0] 0\n",
      "P_NewCap[2,1,1,1] 0\n",
      "P_NewCap[2,1,1,2] 0\n",
      "P_NewCap[2,1,1,3] 0\n",
      "P_NewCap[2,1,1,4] 0\n",
      "P_NewCap[2,1,1,5] 0\n",
      "P_NewCap[2,1,1,6] 0\n",
      "P_NewCap[2,1,1,7] 0\n",
      "P_NewCap[2,1,1,8] 0\n",
      "P_NewCap[2,1,1,9] 0\n",
      "P_NewCap[2,1,1,10] 0\n",
      "P_NewCap[2,1,1,11] 0\n",
      "P_NewCap[2,1,1,12] 0\n",
      "P_NewCap[2,1,1,13] 0\n",
      "P_NewCap[2,1,1,14] 0\n",
      "P_NewCap[2,1,1,15] 0\n",
      "P_NewCap[2,1,1,16] 0\n",
      "P_NewCap[2,1,1,17] 0\n",
      "P_NewCap[2,1,1,18] 0\n",
      "P_NewCap[2,1,1,19] 0\n",
      "P_NewCap[2,1,1,20] 0\n",
      "P_NewCap[2,1,1,21] 0\n",
      "P_NewCap[2,1,1,22] 0\n",
      "P_NewCap[2,1,1,23] 0\n",
      "P_NewCap[2,1,2,0] 0\n",
      "P_NewCap[2,1,2,1] 0\n",
      "P_NewCap[2,1,2,2] 0\n",
      "P_NewCap[2,1,2,3] 0\n",
      "P_NewCap[2,1,2,4] 0\n",
      "P_NewCap[2,1,2,5] 0\n",
      "P_NewCap[2,1,2,6] 0\n",
      "P_NewCap[2,1,2,7] 0\n",
      "P_NewCap[2,1,2,8] 0\n",
      "P_NewCap[2,1,2,9] 0\n",
      "P_NewCap[2,1,2,10] 0\n",
      "P_NewCap[2,1,2,11] 0\n",
      "P_NewCap[2,1,2,12] 0\n",
      "P_NewCap[2,1,2,13] 0\n",
      "P_NewCap[2,1,2,14] 0\n",
      "P_NewCap[2,1,2,15] 0\n",
      "P_NewCap[2,1,2,16] 0\n",
      "P_NewCap[2,1,2,17] 0\n",
      "P_NewCap[2,1,2,18] 0\n",
      "P_NewCap[2,1,2,19] 0\n",
      "P_NewCap[2,1,2,20] 0\n",
      "P_NewCap[2,1,2,21] 0\n",
      "P_NewCap[2,1,2,22] 0\n",
      "P_NewCap[2,1,2,23] 0\n",
      "P_NewCap[2,1,3,0] 0\n",
      "P_NewCap[2,1,3,1] 0\n",
      "P_NewCap[2,1,3,2] 0\n",
      "P_NewCap[2,1,3,3] 0\n",
      "P_NewCap[2,1,3,4] 0\n",
      "P_NewCap[2,1,3,5] 0\n",
      "P_NewCap[2,1,3,6] 0\n",
      "P_NewCap[2,1,3,7] 0\n",
      "P_NewCap[2,1,3,8] 0\n",
      "P_NewCap[2,1,3,9] 0\n",
      "P_NewCap[2,1,3,10] 0\n",
      "P_NewCap[2,1,3,11] 0\n",
      "P_NewCap[2,1,3,12] 0\n",
      "P_NewCap[2,1,3,13] 0\n",
      "P_NewCap[2,1,3,14] 0\n",
      "P_NewCap[2,1,3,15] 0\n",
      "P_NewCap[2,1,3,16] 0\n",
      "P_NewCap[2,1,3,17] 0\n",
      "P_NewCap[2,1,3,18] 0\n",
      "P_NewCap[2,1,3,19] 0\n",
      "P_NewCap[2,1,3,20] 0\n",
      "P_NewCap[2,1,3,21] 0\n",
      "P_NewCap[2,1,3,22] 0\n",
      "P_NewCap[2,1,3,23] 0\n",
      "P_NewCap[2,1,4,0] 0\n",
      "P_NewCap[2,1,4,1] 0\n",
      "P_NewCap[2,1,4,2] 0\n",
      "P_NewCap[2,1,4,3] 0\n",
      "P_NewCap[2,1,4,4] 0\n",
      "P_NewCap[2,1,4,5] 0\n",
      "P_NewCap[2,1,4,6] 0\n",
      "P_NewCap[2,1,4,7] 0\n",
      "P_NewCap[2,1,4,8] 0\n",
      "P_NewCap[2,1,4,9] 0\n",
      "P_NewCap[2,1,4,10] 0\n",
      "P_NewCap[2,1,4,11] 0\n",
      "P_NewCap[2,1,4,12] 0\n",
      "P_NewCap[2,1,4,13] 0\n",
      "P_NewCap[2,1,4,14] 0\n",
      "P_NewCap[2,1,4,15] 0\n",
      "P_NewCap[2,1,4,16] 0\n",
      "P_NewCap[2,1,4,17] 0\n",
      "P_NewCap[2,1,4,18] 0\n",
      "P_NewCap[2,1,4,19] 0\n",
      "P_NewCap[2,1,4,20] 0\n",
      "P_NewCap[2,1,4,21] 0\n",
      "P_NewCap[2,1,4,22] 0\n",
      "P_NewCap[2,1,4,23] 0\n",
      "P_NewCap[3,0,0,0] 0\n",
      "P_NewCap[3,0,0,1] 0\n",
      "P_NewCap[3,0,0,2] 0\n",
      "P_NewCap[3,0,0,3] 0\n",
      "P_NewCap[3,0,0,4] 0\n",
      "P_NewCap[3,0,0,5] 0\n",
      "P_NewCap[3,0,0,6] 0\n",
      "P_NewCap[3,0,0,7] 0\n",
      "P_NewCap[3,0,0,8] 0\n",
      "P_NewCap[3,0,0,9] 0\n",
      "P_NewCap[3,0,0,10] 0\n",
      "P_NewCap[3,0,0,11] 0\n",
      "P_NewCap[3,0,0,12] 0\n",
      "P_NewCap[3,0,0,13] 0\n",
      "P_NewCap[3,0,0,14] 0\n",
      "P_NewCap[3,0,0,15] 0\n",
      "P_NewCap[3,0,0,16] 0\n",
      "P_NewCap[3,0,0,17] 0\n",
      "P_NewCap[3,0,0,18] 0\n",
      "P_NewCap[3,0,0,19] 0\n",
      "P_NewCap[3,0,0,20] 0\n",
      "P_NewCap[3,0,0,21] 0\n",
      "P_NewCap[3,0,0,22] 0\n",
      "P_NewCap[3,0,0,23] 0\n",
      "P_NewCap[3,0,1,0] 0\n",
      "P_NewCap[3,0,1,1] 0\n",
      "P_NewCap[3,0,1,2] 0\n",
      "P_NewCap[3,0,1,3] 0\n",
      "P_NewCap[3,0,1,4] 0\n",
      "P_NewCap[3,0,1,5] 0\n",
      "P_NewCap[3,0,1,6] 0\n",
      "P_NewCap[3,0,1,7] 0\n",
      "P_NewCap[3,0,1,8] 0\n",
      "P_NewCap[3,0,1,9] 0\n",
      "P_NewCap[3,0,1,10] 0\n",
      "P_NewCap[3,0,1,11] 0\n",
      "P_NewCap[3,0,1,12] 0\n",
      "P_NewCap[3,0,1,13] 0\n",
      "P_NewCap[3,0,1,14] 0\n",
      "P_NewCap[3,0,1,15] 0\n",
      "P_NewCap[3,0,1,16] 0\n",
      "P_NewCap[3,0,1,17] 0\n",
      "P_NewCap[3,0,1,18] 0\n",
      "P_NewCap[3,0,1,19] 0\n",
      "P_NewCap[3,0,1,20] 0\n",
      "P_NewCap[3,0,1,21] 0\n",
      "P_NewCap[3,0,1,22] 0\n",
      "P_NewCap[3,0,1,23] 0\n",
      "P_NewCap[3,0,2,0] 0\n",
      "P_NewCap[3,0,2,1] 0\n",
      "P_NewCap[3,0,2,2] 0\n",
      "P_NewCap[3,0,2,3] 0\n",
      "P_NewCap[3,0,2,4] 0\n",
      "P_NewCap[3,0,2,5] 0\n",
      "P_NewCap[3,0,2,6] 0\n",
      "P_NewCap[3,0,2,7] 0\n",
      "P_NewCap[3,0,2,8] 0\n",
      "P_NewCap[3,0,2,9] 0\n",
      "P_NewCap[3,0,2,10] 0\n",
      "P_NewCap[3,0,2,11] 0\n",
      "P_NewCap[3,0,2,12] 0\n",
      "P_NewCap[3,0,2,13] 0\n",
      "P_NewCap[3,0,2,14] 0\n",
      "P_NewCap[3,0,2,15] 0\n",
      "P_NewCap[3,0,2,16] 0\n",
      "P_NewCap[3,0,2,17] 0\n",
      "P_NewCap[3,0,2,18] 0\n",
      "P_NewCap[3,0,2,19] 0\n",
      "P_NewCap[3,0,2,20] 0\n",
      "P_NewCap[3,0,2,21] 0\n",
      "P_NewCap[3,0,2,22] 0\n",
      "P_NewCap[3,0,2,23] 0\n",
      "P_NewCap[3,0,3,0] 0\n",
      "P_NewCap[3,0,3,1] 0\n",
      "P_NewCap[3,0,3,2] 0\n",
      "P_NewCap[3,0,3,3] 0\n",
      "P_NewCap[3,0,3,4] 0\n",
      "P_NewCap[3,0,3,5] 0\n",
      "P_NewCap[3,0,3,6] 0\n",
      "P_NewCap[3,0,3,7] 0\n",
      "P_NewCap[3,0,3,8] 0\n",
      "P_NewCap[3,0,3,9] 0\n",
      "P_NewCap[3,0,3,10] 0\n",
      "P_NewCap[3,0,3,11] 0\n",
      "P_NewCap[3,0,3,12] 0\n",
      "P_NewCap[3,0,3,13] 0\n",
      "P_NewCap[3,0,3,14] 0\n",
      "P_NewCap[3,0,3,15] 0\n",
      "P_NewCap[3,0,3,16] 0\n",
      "P_NewCap[3,0,3,17] 0\n",
      "P_NewCap[3,0,3,18] 0\n",
      "P_NewCap[3,0,3,19] 0\n",
      "P_NewCap[3,0,3,20] 0\n",
      "P_NewCap[3,0,3,21] 0\n",
      "P_NewCap[3,0,3,22] 0\n",
      "P_NewCap[3,0,3,23] 0\n",
      "P_NewCap[3,0,4,0] 0\n",
      "P_NewCap[3,0,4,1] 0\n",
      "P_NewCap[3,0,4,2] 0\n",
      "P_NewCap[3,0,4,3] 0\n",
      "P_NewCap[3,0,4,4] 0\n",
      "P_NewCap[3,0,4,5] 0\n",
      "P_NewCap[3,0,4,6] 0\n",
      "P_NewCap[3,0,4,7] 0\n",
      "P_NewCap[3,0,4,8] 0\n",
      "P_NewCap[3,0,4,9] 0\n",
      "P_NewCap[3,0,4,10] 0\n",
      "P_NewCap[3,0,4,11] 0\n",
      "P_NewCap[3,0,4,12] 0\n",
      "P_NewCap[3,0,4,13] 0\n",
      "P_NewCap[3,0,4,14] 0\n",
      "P_NewCap[3,0,4,15] 0\n",
      "P_NewCap[3,0,4,16] 0\n",
      "P_NewCap[3,0,4,17] 0\n",
      "P_NewCap[3,0,4,18] 0\n",
      "P_NewCap[3,0,4,19] 0\n",
      "P_NewCap[3,0,4,20] 0\n",
      "P_NewCap[3,0,4,21] 0\n",
      "P_NewCap[3,0,4,22] 0\n",
      "P_NewCap[3,0,4,23] 0\n",
      "P_NewCap[3,1,0,0] 0\n",
      "P_NewCap[3,1,0,1] 0\n",
      "P_NewCap[3,1,0,2] 0\n",
      "P_NewCap[3,1,0,3] 0\n",
      "P_NewCap[3,1,0,4] 0\n",
      "P_NewCap[3,1,0,5] 0\n",
      "P_NewCap[3,1,0,6] 0\n",
      "P_NewCap[3,1,0,7] 0\n",
      "P_NewCap[3,1,0,8] 0\n",
      "P_NewCap[3,1,0,9] 0\n",
      "P_NewCap[3,1,0,10] 0\n",
      "P_NewCap[3,1,0,11] 0\n",
      "P_NewCap[3,1,0,12] 0\n",
      "P_NewCap[3,1,0,13] 0\n",
      "P_NewCap[3,1,0,14] 0\n",
      "P_NewCap[3,1,0,15] 0\n",
      "P_NewCap[3,1,0,16] 0\n",
      "P_NewCap[3,1,0,17] 0\n",
      "P_NewCap[3,1,0,18] 0\n",
      "P_NewCap[3,1,0,19] 0\n",
      "P_NewCap[3,1,0,20] 0\n",
      "P_NewCap[3,1,0,21] 0\n",
      "P_NewCap[3,1,0,22] 0\n",
      "P_NewCap[3,1,0,23] 0\n",
      "P_NewCap[3,1,1,0] 0\n",
      "P_NewCap[3,1,1,1] 0\n",
      "P_NewCap[3,1,1,2] 0\n",
      "P_NewCap[3,1,1,3] 0\n",
      "P_NewCap[3,1,1,4] 0\n",
      "P_NewCap[3,1,1,5] 0\n",
      "P_NewCap[3,1,1,6] 0\n",
      "P_NewCap[3,1,1,7] 0\n",
      "P_NewCap[3,1,1,8] 0\n",
      "P_NewCap[3,1,1,9] 0\n",
      "P_NewCap[3,1,1,10] 0\n",
      "P_NewCap[3,1,1,11] 0\n",
      "P_NewCap[3,1,1,12] 0\n",
      "P_NewCap[3,1,1,13] 0\n",
      "P_NewCap[3,1,1,14] 0\n",
      "P_NewCap[3,1,1,15] 0\n",
      "P_NewCap[3,1,1,16] 0\n",
      "P_NewCap[3,1,1,17] 0\n",
      "P_NewCap[3,1,1,18] 0\n",
      "P_NewCap[3,1,1,19] 0\n",
      "P_NewCap[3,1,1,20] 0\n",
      "P_NewCap[3,1,1,21] 0\n",
      "P_NewCap[3,1,1,22] 0\n",
      "P_NewCap[3,1,1,23] 0\n",
      "P_NewCap[3,1,2,0] 0\n",
      "P_NewCap[3,1,2,1] 0\n",
      "P_NewCap[3,1,2,2] 0\n",
      "P_NewCap[3,1,2,3] 0\n",
      "P_NewCap[3,1,2,4] 0\n",
      "P_NewCap[3,1,2,5] 0\n",
      "P_NewCap[3,1,2,6] 0\n",
      "P_NewCap[3,1,2,7] 0\n",
      "P_NewCap[3,1,2,8] 0\n",
      "P_NewCap[3,1,2,9] 0\n",
      "P_NewCap[3,1,2,10] 0\n",
      "P_NewCap[3,1,2,11] 0\n",
      "P_NewCap[3,1,2,12] 0\n",
      "P_NewCap[3,1,2,13] 0\n",
      "P_NewCap[3,1,2,14] 0\n",
      "P_NewCap[3,1,2,15] 0\n",
      "P_NewCap[3,1,2,16] 0\n",
      "P_NewCap[3,1,2,17] 0\n",
      "P_NewCap[3,1,2,18] 0\n",
      "P_NewCap[3,1,2,19] 0\n",
      "P_NewCap[3,1,2,20] 0\n",
      "P_NewCap[3,1,2,21] 0\n",
      "P_NewCap[3,1,2,22] 0\n",
      "P_NewCap[3,1,2,23] 0\n",
      "P_NewCap[3,1,3,0] 0\n",
      "P_NewCap[3,1,3,1] 0\n",
      "P_NewCap[3,1,3,2] 0\n",
      "P_NewCap[3,1,3,3] 0\n",
      "P_NewCap[3,1,3,4] 0\n",
      "P_NewCap[3,1,3,5] 0\n",
      "P_NewCap[3,1,3,6] 0\n",
      "P_NewCap[3,1,3,7] 0\n",
      "P_NewCap[3,1,3,8] 0\n",
      "P_NewCap[3,1,3,9] 0\n",
      "P_NewCap[3,1,3,10] 0\n",
      "P_NewCap[3,1,3,11] 0\n",
      "P_NewCap[3,1,3,12] 0\n",
      "P_NewCap[3,1,3,13] 0\n",
      "P_NewCap[3,1,3,14] 0\n",
      "P_NewCap[3,1,3,15] 0\n",
      "P_NewCap[3,1,3,16] 0\n",
      "P_NewCap[3,1,3,17] 0\n",
      "P_NewCap[3,1,3,18] 0\n",
      "P_NewCap[3,1,3,19] 0\n",
      "P_NewCap[3,1,3,20] 0\n",
      "P_NewCap[3,1,3,21] 0\n",
      "P_NewCap[3,1,3,22] 0\n",
      "P_NewCap[3,1,3,23] 0\n",
      "P_NewCap[3,1,4,0] 0\n",
      "P_NewCap[3,1,4,1] 0\n",
      "P_NewCap[3,1,4,2] 0\n",
      "P_NewCap[3,1,4,3] 0\n",
      "P_NewCap[3,1,4,4] 0\n",
      "P_NewCap[3,1,4,5] 0\n",
      "P_NewCap[3,1,4,6] 0\n",
      "P_NewCap[3,1,4,7] 0\n",
      "P_NewCap[3,1,4,8] 0\n",
      "P_NewCap[3,1,4,9] 0\n",
      "P_NewCap[3,1,4,10] 0\n",
      "P_NewCap[3,1,4,11] 0\n",
      "P_NewCap[3,1,4,12] 0\n",
      "P_NewCap[3,1,4,13] 0\n",
      "P_NewCap[3,1,4,14] 0\n",
      "P_NewCap[3,1,4,15] 0\n",
      "P_NewCap[3,1,4,16] 0\n",
      "P_NewCap[3,1,4,17] 0\n",
      "P_NewCap[3,1,4,18] 0\n",
      "P_NewCap[3,1,4,19] 0\n",
      "P_NewCap[3,1,4,20] 0\n",
      "P_NewCap[3,1,4,21] 0\n",
      "P_NewCap[3,1,4,22] 0\n",
      "P_NewCap[3,1,4,23] 0\n",
      "P_NewCap[4,0,0,0] 0\n",
      "P_NewCap[4,0,0,1] 0\n",
      "P_NewCap[4,0,0,2] 0\n",
      "P_NewCap[4,0,0,3] 0\n",
      "P_NewCap[4,0,0,4] 0\n",
      "P_NewCap[4,0,0,5] 0\n",
      "P_NewCap[4,0,0,6] 0\n",
      "P_NewCap[4,0,0,7] 0\n",
      "P_NewCap[4,0,0,8] 0\n",
      "P_NewCap[4,0,0,9] 0\n",
      "P_NewCap[4,0,0,10] 0\n",
      "P_NewCap[4,0,0,11] 0\n",
      "P_NewCap[4,0,0,12] 0\n",
      "P_NewCap[4,0,0,13] 0\n",
      "P_NewCap[4,0,0,14] 0\n",
      "P_NewCap[4,0,0,15] 0\n",
      "P_NewCap[4,0,0,16] 0\n",
      "P_NewCap[4,0,0,17] 0\n",
      "P_NewCap[4,0,0,18] 0\n",
      "P_NewCap[4,0,0,19] 0\n",
      "P_NewCap[4,0,0,20] 0\n",
      "P_NewCap[4,0,0,21] 0\n",
      "P_NewCap[4,0,0,22] 0\n",
      "P_NewCap[4,0,0,23] 0\n",
      "P_NewCap[4,0,1,0] 0\n",
      "P_NewCap[4,0,1,1] 0\n",
      "P_NewCap[4,0,1,2] 0\n",
      "P_NewCap[4,0,1,3] 0\n",
      "P_NewCap[4,0,1,4] 0\n",
      "P_NewCap[4,0,1,5] 0\n",
      "P_NewCap[4,0,1,6] 0\n",
      "P_NewCap[4,0,1,7] 0\n",
      "P_NewCap[4,0,1,8] 0\n",
      "P_NewCap[4,0,1,9] 0\n",
      "P_NewCap[4,0,1,10] 0\n",
      "P_NewCap[4,0,1,11] 0\n",
      "P_NewCap[4,0,1,12] 0\n",
      "P_NewCap[4,0,1,13] 0\n",
      "P_NewCap[4,0,1,14] 0\n",
      "P_NewCap[4,0,1,15] 0\n",
      "P_NewCap[4,0,1,16] 0\n",
      "P_NewCap[4,0,1,17] 0\n",
      "P_NewCap[4,0,1,18] 0\n",
      "P_NewCap[4,0,1,19] 0\n",
      "P_NewCap[4,0,1,20] 0\n",
      "P_NewCap[4,0,1,21] 0\n",
      "P_NewCap[4,0,1,22] 0\n",
      "P_NewCap[4,0,1,23] 0\n",
      "P_NewCap[4,0,2,0] 0\n",
      "P_NewCap[4,0,2,1] 0\n",
      "P_NewCap[4,0,2,2] 0\n",
      "P_NewCap[4,0,2,3] 0\n",
      "P_NewCap[4,0,2,4] 0\n",
      "P_NewCap[4,0,2,5] 0\n",
      "P_NewCap[4,0,2,6] 0\n",
      "P_NewCap[4,0,2,7] 0\n",
      "P_NewCap[4,0,2,8] 0\n",
      "P_NewCap[4,0,2,9] 0\n",
      "P_NewCap[4,0,2,10] 0\n",
      "P_NewCap[4,0,2,11] 0\n",
      "P_NewCap[4,0,2,12] 0\n",
      "P_NewCap[4,0,2,13] 0\n",
      "P_NewCap[4,0,2,14] 0\n",
      "P_NewCap[4,0,2,15] 0\n",
      "P_NewCap[4,0,2,16] 0\n",
      "P_NewCap[4,0,2,17] 0\n",
      "P_NewCap[4,0,2,18] 0\n",
      "P_NewCap[4,0,2,19] 0\n",
      "P_NewCap[4,0,2,20] 0\n",
      "P_NewCap[4,0,2,21] 0\n",
      "P_NewCap[4,0,2,22] 0\n",
      "P_NewCap[4,0,2,23] 0\n",
      "P_NewCap[4,0,3,0] 0\n",
      "P_NewCap[4,0,3,1] 0\n",
      "P_NewCap[4,0,3,2] 0\n",
      "P_NewCap[4,0,3,3] 0\n",
      "P_NewCap[4,0,3,4] 0\n",
      "P_NewCap[4,0,3,5] 0\n",
      "P_NewCap[4,0,3,6] 0\n",
      "P_NewCap[4,0,3,7] 0\n",
      "P_NewCap[4,0,3,8] 0\n",
      "P_NewCap[4,0,3,9] 0\n",
      "P_NewCap[4,0,3,10] 0\n",
      "P_NewCap[4,0,3,11] 0\n",
      "P_NewCap[4,0,3,12] 0\n",
      "P_NewCap[4,0,3,13] 0\n",
      "P_NewCap[4,0,3,14] 0\n",
      "P_NewCap[4,0,3,15] 0\n",
      "P_NewCap[4,0,3,16] 0\n",
      "P_NewCap[4,0,3,17] 0\n",
      "P_NewCap[4,0,3,18] 0\n",
      "P_NewCap[4,0,3,19] 0\n",
      "P_NewCap[4,0,3,20] 0\n",
      "P_NewCap[4,0,3,21] 0\n",
      "P_NewCap[4,0,3,22] 0\n",
      "P_NewCap[4,0,3,23] 0\n",
      "P_NewCap[4,0,4,0] 0\n",
      "P_NewCap[4,0,4,1] 0\n",
      "P_NewCap[4,0,4,2] 0\n",
      "P_NewCap[4,0,4,3] 0\n",
      "P_NewCap[4,0,4,4] 0\n",
      "P_NewCap[4,0,4,5] 0\n",
      "P_NewCap[4,0,4,6] 0\n",
      "P_NewCap[4,0,4,7] 0\n",
      "P_NewCap[4,0,4,8] 0\n",
      "P_NewCap[4,0,4,9] 0\n",
      "P_NewCap[4,0,4,10] 0\n",
      "P_NewCap[4,0,4,11] 0\n",
      "P_NewCap[4,0,4,12] 0\n",
      "P_NewCap[4,0,4,13] 0\n",
      "P_NewCap[4,0,4,14] 0\n",
      "P_NewCap[4,0,4,15] 0\n",
      "P_NewCap[4,0,4,16] 0\n",
      "P_NewCap[4,0,4,17] 0\n",
      "P_NewCap[4,0,4,18] 0\n",
      "P_NewCap[4,0,4,19] 0\n",
      "P_NewCap[4,0,4,20] 0\n",
      "P_NewCap[4,0,4,21] 0\n",
      "P_NewCap[4,0,4,22] 0\n",
      "P_NewCap[4,0,4,23] 0\n",
      "P_NewCap[4,1,0,0] 0\n",
      "P_NewCap[4,1,0,1] 0\n",
      "P_NewCap[4,1,0,2] 0\n",
      "P_NewCap[4,1,0,3] 0\n",
      "P_NewCap[4,1,0,4] 0\n",
      "P_NewCap[4,1,0,5] 0\n",
      "P_NewCap[4,1,0,6] 0\n",
      "P_NewCap[4,1,0,7] 0\n",
      "P_NewCap[4,1,0,8] 0\n",
      "P_NewCap[4,1,0,9] 0\n",
      "P_NewCap[4,1,0,10] 0\n",
      "P_NewCap[4,1,0,11] 0\n",
      "P_NewCap[4,1,0,12] 0\n",
      "P_NewCap[4,1,0,13] 0\n",
      "P_NewCap[4,1,0,14] 0\n",
      "P_NewCap[4,1,0,15] 0\n",
      "P_NewCap[4,1,0,16] 0\n",
      "P_NewCap[4,1,0,17] 0\n",
      "P_NewCap[4,1,0,18] 0\n",
      "P_NewCap[4,1,0,19] 0\n",
      "P_NewCap[4,1,0,20] 0\n",
      "P_NewCap[4,1,0,21] 0\n",
      "P_NewCap[4,1,0,22] 0\n",
      "P_NewCap[4,1,0,23] 0\n",
      "P_NewCap[4,1,1,0] 0\n",
      "P_NewCap[4,1,1,1] 0\n",
      "P_NewCap[4,1,1,2] 0\n",
      "P_NewCap[4,1,1,3] 0\n",
      "P_NewCap[4,1,1,4] 0\n",
      "P_NewCap[4,1,1,5] 0\n",
      "P_NewCap[4,1,1,6] 0\n",
      "P_NewCap[4,1,1,7] 0\n",
      "P_NewCap[4,1,1,8] 0\n",
      "P_NewCap[4,1,1,9] 0\n",
      "P_NewCap[4,1,1,10] 0\n",
      "P_NewCap[4,1,1,11] 0\n",
      "P_NewCap[4,1,1,12] 0\n",
      "P_NewCap[4,1,1,13] 0\n",
      "P_NewCap[4,1,1,14] 0\n",
      "P_NewCap[4,1,1,15] 0\n",
      "P_NewCap[4,1,1,16] 0\n",
      "P_NewCap[4,1,1,17] 0\n",
      "P_NewCap[4,1,1,18] 0\n",
      "P_NewCap[4,1,1,19] 0\n",
      "P_NewCap[4,1,1,20] 0\n",
      "P_NewCap[4,1,1,21] 0\n",
      "P_NewCap[4,1,1,22] 0\n",
      "P_NewCap[4,1,1,23] 0\n",
      "P_NewCap[4,1,2,0] 0\n",
      "P_NewCap[4,1,2,1] 0\n",
      "P_NewCap[4,1,2,2] 0\n",
      "P_NewCap[4,1,2,3] 0\n",
      "P_NewCap[4,1,2,4] 0\n",
      "P_NewCap[4,1,2,5] 0\n",
      "P_NewCap[4,1,2,6] 0\n",
      "P_NewCap[4,1,2,7] 0\n",
      "P_NewCap[4,1,2,8] 0\n",
      "P_NewCap[4,1,2,9] 0\n",
      "P_NewCap[4,1,2,10] 0\n",
      "P_NewCap[4,1,2,11] 0\n",
      "P_NewCap[4,1,2,12] 0\n",
      "P_NewCap[4,1,2,13] 0\n",
      "P_NewCap[4,1,2,14] 0\n",
      "P_NewCap[4,1,2,15] 0\n",
      "P_NewCap[4,1,2,16] 0\n",
      "P_NewCap[4,1,2,17] 0\n",
      "P_NewCap[4,1,2,18] 0\n",
      "P_NewCap[4,1,2,19] 0\n",
      "P_NewCap[4,1,2,20] 0\n",
      "P_NewCap[4,1,2,21] 0\n",
      "P_NewCap[4,1,2,22] 0\n",
      "P_NewCap[4,1,2,23] 0\n",
      "P_NewCap[4,1,3,0] 0\n",
      "P_NewCap[4,1,3,1] 0\n",
      "P_NewCap[4,1,3,2] 0\n",
      "P_NewCap[4,1,3,3] 0\n",
      "P_NewCap[4,1,3,4] 0\n",
      "P_NewCap[4,1,3,5] 0\n",
      "P_NewCap[4,1,3,6] 0\n",
      "P_NewCap[4,1,3,7] 0\n",
      "P_NewCap[4,1,3,8] 0\n",
      "P_NewCap[4,1,3,9] 0\n",
      "P_NewCap[4,1,3,10] 0\n",
      "P_NewCap[4,1,3,11] 0\n",
      "P_NewCap[4,1,3,12] 0\n",
      "P_NewCap[4,1,3,13] 0\n",
      "P_NewCap[4,1,3,14] 0\n",
      "P_NewCap[4,1,3,15] 0\n",
      "P_NewCap[4,1,3,16] 0\n",
      "P_NewCap[4,1,3,17] 0\n",
      "P_NewCap[4,1,3,18] 0\n",
      "P_NewCap[4,1,3,19] 0\n",
      "P_NewCap[4,1,3,20] 0\n",
      "P_NewCap[4,1,3,21] 0\n",
      "P_NewCap[4,1,3,22] 0\n",
      "P_NewCap[4,1,3,23] 0\n",
      "P_NewCap[4,1,4,0] 0\n",
      "P_NewCap[4,1,4,1] 0\n",
      "P_NewCap[4,1,4,2] 0\n",
      "P_NewCap[4,1,4,3] 0\n",
      "P_NewCap[4,1,4,4] 0\n",
      "P_NewCap[4,1,4,5] 0\n",
      "P_NewCap[4,1,4,6] 0\n",
      "P_NewCap[4,1,4,7] 0\n",
      "P_NewCap[4,1,4,8] 0\n",
      "P_NewCap[4,1,4,9] 0\n",
      "P_NewCap[4,1,4,10] 0\n",
      "P_NewCap[4,1,4,11] 0\n",
      "P_NewCap[4,1,4,12] 0\n",
      "P_NewCap[4,1,4,13] 0\n",
      "P_NewCap[4,1,4,14] 0\n",
      "P_NewCap[4,1,4,15] 0\n",
      "P_NewCap[4,1,4,16] 0\n",
      "P_NewCap[4,1,4,17] 0\n",
      "P_NewCap[4,1,4,18] 0\n",
      "P_NewCap[4,1,4,19] 0\n",
      "P_NewCap[4,1,4,20] 0\n",
      "P_NewCap[4,1,4,21] 0\n",
      "P_NewCap[4,1,4,22] 0\n",
      "P_NewCap[4,1,4,23] 0\n",
      "P_NewCap[5,0,0,0] 0\n",
      "P_NewCap[5,0,0,1] 0\n",
      "P_NewCap[5,0,0,2] 0\n",
      "P_NewCap[5,0,0,3] 0\n",
      "P_NewCap[5,0,0,4] 0\n",
      "P_NewCap[5,0,0,5] 0\n",
      "P_NewCap[5,0,0,6] 0\n",
      "P_NewCap[5,0,0,7] 0\n",
      "P_NewCap[5,0,0,8] 0\n",
      "P_NewCap[5,0,0,9] 0\n",
      "P_NewCap[5,0,0,10] 0\n",
      "P_NewCap[5,0,0,11] 0\n",
      "P_NewCap[5,0,0,12] 0\n",
      "P_NewCap[5,0,0,13] 0\n",
      "P_NewCap[5,0,0,14] 0\n",
      "P_NewCap[5,0,0,15] 0\n",
      "P_NewCap[5,0,0,16] 0\n",
      "P_NewCap[5,0,0,17] 0\n",
      "P_NewCap[5,0,0,18] 0\n",
      "P_NewCap[5,0,0,19] 0\n",
      "P_NewCap[5,0,0,20] 0\n",
      "P_NewCap[5,0,0,21] 0\n",
      "P_NewCap[5,0,0,22] 0\n",
      "P_NewCap[5,0,0,23] 0\n",
      "P_NewCap[5,0,1,0] 0\n",
      "P_NewCap[5,0,1,1] 0\n",
      "P_NewCap[5,0,1,2] 0\n",
      "P_NewCap[5,0,1,3] 0\n",
      "P_NewCap[5,0,1,4] 0\n",
      "P_NewCap[5,0,1,5] 0\n",
      "P_NewCap[5,0,1,6] 0\n",
      "P_NewCap[5,0,1,7] 0\n",
      "P_NewCap[5,0,1,8] 0\n",
      "P_NewCap[5,0,1,9] 0\n",
      "P_NewCap[5,0,1,10] 0\n",
      "P_NewCap[5,0,1,11] 0\n",
      "P_NewCap[5,0,1,12] 0\n",
      "P_NewCap[5,0,1,13] 0\n",
      "P_NewCap[5,0,1,14] 0\n",
      "P_NewCap[5,0,1,15] 0\n",
      "P_NewCap[5,0,1,16] 0\n",
      "P_NewCap[5,0,1,17] 0\n",
      "P_NewCap[5,0,1,18] 0\n",
      "P_NewCap[5,0,1,19] 0\n",
      "P_NewCap[5,0,1,20] 0\n",
      "P_NewCap[5,0,1,21] 0\n",
      "P_NewCap[5,0,1,22] 0\n",
      "P_NewCap[5,0,1,23] 0\n",
      "P_NewCap[5,0,2,0] 0\n",
      "P_NewCap[5,0,2,1] 0\n",
      "P_NewCap[5,0,2,2] 0\n",
      "P_NewCap[5,0,2,3] 0\n",
      "P_NewCap[5,0,2,4] 0\n",
      "P_NewCap[5,0,2,5] 0\n",
      "P_NewCap[5,0,2,6] 0\n",
      "P_NewCap[5,0,2,7] 0\n",
      "P_NewCap[5,0,2,8] 0\n",
      "P_NewCap[5,0,2,9] 0\n",
      "P_NewCap[5,0,2,10] 0\n",
      "P_NewCap[5,0,2,11] 0\n",
      "P_NewCap[5,0,2,12] 0\n",
      "P_NewCap[5,0,2,13] 0\n",
      "P_NewCap[5,0,2,14] 0\n",
      "P_NewCap[5,0,2,15] 0\n",
      "P_NewCap[5,0,2,16] 0\n",
      "P_NewCap[5,0,2,17] 0\n",
      "P_NewCap[5,0,2,18] 0\n",
      "P_NewCap[5,0,2,19] 0\n",
      "P_NewCap[5,0,2,20] 0\n",
      "P_NewCap[5,0,2,21] 0\n",
      "P_NewCap[5,0,2,22] 0\n",
      "P_NewCap[5,0,2,23] 0\n",
      "P_NewCap[5,0,3,0] 0\n",
      "P_NewCap[5,0,3,1] 0\n",
      "P_NewCap[5,0,3,2] 0\n",
      "P_NewCap[5,0,3,3] 0\n",
      "P_NewCap[5,0,3,4] 0\n",
      "P_NewCap[5,0,3,5] 0\n",
      "P_NewCap[5,0,3,6] 0\n",
      "P_NewCap[5,0,3,7] 0\n",
      "P_NewCap[5,0,3,8] 0\n",
      "P_NewCap[5,0,3,9] 0\n",
      "P_NewCap[5,0,3,10] 0\n",
      "P_NewCap[5,0,3,11] 0\n",
      "P_NewCap[5,0,3,12] 0\n",
      "P_NewCap[5,0,3,13] 0\n",
      "P_NewCap[5,0,3,14] 0\n",
      "P_NewCap[5,0,3,15] 0\n",
      "P_NewCap[5,0,3,16] 0\n",
      "P_NewCap[5,0,3,17] 0\n",
      "P_NewCap[5,0,3,18] 0\n",
      "P_NewCap[5,0,3,19] 0\n",
      "P_NewCap[5,0,3,20] 0\n",
      "P_NewCap[5,0,3,21] 0\n",
      "P_NewCap[5,0,3,22] 0\n",
      "P_NewCap[5,0,3,23] 0\n",
      "P_NewCap[5,0,4,0] 0\n",
      "P_NewCap[5,0,4,1] 0\n",
      "P_NewCap[5,0,4,2] 0\n",
      "P_NewCap[5,0,4,3] 0\n",
      "P_NewCap[5,0,4,4] 0\n",
      "P_NewCap[5,0,4,5] 0\n",
      "P_NewCap[5,0,4,6] 0\n",
      "P_NewCap[5,0,4,7] 0\n",
      "P_NewCap[5,0,4,8] 0\n",
      "P_NewCap[5,0,4,9] 0\n",
      "P_NewCap[5,0,4,10] 0\n",
      "P_NewCap[5,0,4,11] 0\n",
      "P_NewCap[5,0,4,12] 0\n",
      "P_NewCap[5,0,4,13] 0\n",
      "P_NewCap[5,0,4,14] 0\n",
      "P_NewCap[5,0,4,15] 0\n",
      "P_NewCap[5,0,4,16] 0\n",
      "P_NewCap[5,0,4,17] 0\n",
      "P_NewCap[5,0,4,18] 0\n",
      "P_NewCap[5,0,4,19] 0\n",
      "P_NewCap[5,0,4,20] 0\n",
      "P_NewCap[5,0,4,21] 0\n",
      "P_NewCap[5,0,4,22] 0\n",
      "P_NewCap[5,0,4,23] 0\n",
      "P_NewCap[5,1,0,0] 0\n",
      "P_NewCap[5,1,0,1] 0\n",
      "P_NewCap[5,1,0,2] 0\n",
      "P_NewCap[5,1,0,3] 0\n",
      "P_NewCap[5,1,0,4] 0\n",
      "P_NewCap[5,1,0,5] 0\n",
      "P_NewCap[5,1,0,6] 0\n",
      "P_NewCap[5,1,0,7] 0\n",
      "P_NewCap[5,1,0,8] 0\n",
      "P_NewCap[5,1,0,9] 0\n",
      "P_NewCap[5,1,0,10] 0\n",
      "P_NewCap[5,1,0,11] 0\n",
      "P_NewCap[5,1,0,12] 0\n",
      "P_NewCap[5,1,0,13] 0\n",
      "P_NewCap[5,1,0,14] 0\n",
      "P_NewCap[5,1,0,15] 0\n",
      "P_NewCap[5,1,0,16] 0\n",
      "P_NewCap[5,1,0,17] 0\n",
      "P_NewCap[5,1,0,18] 0\n",
      "P_NewCap[5,1,0,19] 0\n",
      "P_NewCap[5,1,0,20] 0\n",
      "P_NewCap[5,1,0,21] 0\n",
      "P_NewCap[5,1,0,22] 0\n",
      "P_NewCap[5,1,0,23] 0\n",
      "P_NewCap[5,1,1,0] 0\n",
      "P_NewCap[5,1,1,1] 0\n",
      "P_NewCap[5,1,1,2] 0\n",
      "P_NewCap[5,1,1,3] 0\n",
      "P_NewCap[5,1,1,4] 0\n",
      "P_NewCap[5,1,1,5] 0\n",
      "P_NewCap[5,1,1,6] 0\n",
      "P_NewCap[5,1,1,7] 0\n",
      "P_NewCap[5,1,1,8] 0\n",
      "P_NewCap[5,1,1,9] 0\n",
      "P_NewCap[5,1,1,10] 0\n",
      "P_NewCap[5,1,1,11] 0\n",
      "P_NewCap[5,1,1,12] 0\n",
      "P_NewCap[5,1,1,13] 0\n",
      "P_NewCap[5,1,1,14] 0\n",
      "P_NewCap[5,1,1,15] 0\n",
      "P_NewCap[5,1,1,16] 0\n",
      "P_NewCap[5,1,1,17] 0\n",
      "P_NewCap[5,1,1,18] 0\n",
      "P_NewCap[5,1,1,19] 0\n",
      "P_NewCap[5,1,1,20] 0\n",
      "P_NewCap[5,1,1,21] 0\n",
      "P_NewCap[5,1,1,22] 0\n",
      "P_NewCap[5,1,1,23] 0\n",
      "P_NewCap[5,1,2,0] 0\n",
      "P_NewCap[5,1,2,1] 0\n",
      "P_NewCap[5,1,2,2] 0\n",
      "P_NewCap[5,1,2,3] 0\n",
      "P_NewCap[5,1,2,4] 0\n",
      "P_NewCap[5,1,2,5] 0\n",
      "P_NewCap[5,1,2,6] 0\n",
      "P_NewCap[5,1,2,7] 0\n",
      "P_NewCap[5,1,2,8] 0\n",
      "P_NewCap[5,1,2,9] 0\n",
      "P_NewCap[5,1,2,10] 0\n",
      "P_NewCap[5,1,2,11] 0\n",
      "P_NewCap[5,1,2,12] 0\n",
      "P_NewCap[5,1,2,13] 0\n",
      "P_NewCap[5,1,2,14] 0\n",
      "P_NewCap[5,1,2,15] 0\n",
      "P_NewCap[5,1,2,16] 0\n",
      "P_NewCap[5,1,2,17] 0\n",
      "P_NewCap[5,1,2,18] 0\n",
      "P_NewCap[5,1,2,19] 0\n",
      "P_NewCap[5,1,2,20] 0\n",
      "P_NewCap[5,1,2,21] 0\n",
      "P_NewCap[5,1,2,22] 0\n",
      "P_NewCap[5,1,2,23] 0\n",
      "P_NewCap[5,1,3,0] 0\n",
      "P_NewCap[5,1,3,1] 0\n",
      "P_NewCap[5,1,3,2] 0\n",
      "P_NewCap[5,1,3,3] 0\n",
      "P_NewCap[5,1,3,4] 0\n",
      "P_NewCap[5,1,3,5] 0\n",
      "P_NewCap[5,1,3,6] 0\n",
      "P_NewCap[5,1,3,7] 0\n",
      "P_NewCap[5,1,3,8] 0\n",
      "P_NewCap[5,1,3,9] 0\n",
      "P_NewCap[5,1,3,10] 0\n",
      "P_NewCap[5,1,3,11] 0\n",
      "P_NewCap[5,1,3,12] 0\n",
      "P_NewCap[5,1,3,13] 0\n",
      "P_NewCap[5,1,3,14] 0\n",
      "P_NewCap[5,1,3,15] 0\n",
      "P_NewCap[5,1,3,16] 0\n",
      "P_NewCap[5,1,3,17] 0\n",
      "P_NewCap[5,1,3,18] 0\n",
      "P_NewCap[5,1,3,19] 0\n",
      "P_NewCap[5,1,3,20] 0\n",
      "P_NewCap[5,1,3,21] 0\n",
      "P_NewCap[5,1,3,22] 0\n",
      "P_NewCap[5,1,3,23] 0\n",
      "P_NewCap[5,1,4,0] 0\n",
      "P_NewCap[5,1,4,1] 0\n",
      "P_NewCap[5,1,4,2] 0\n",
      "P_NewCap[5,1,4,3] 0\n",
      "P_NewCap[5,1,4,4] 0\n",
      "P_NewCap[5,1,4,5] 0\n",
      "P_NewCap[5,1,4,6] 0\n",
      "P_NewCap[5,1,4,7] 0\n",
      "P_NewCap[5,1,4,8] 0\n",
      "P_NewCap[5,1,4,9] 0\n",
      "P_NewCap[5,1,4,10] 0\n",
      "P_NewCap[5,1,4,11] 0\n",
      "P_NewCap[5,1,4,12] 0\n",
      "P_NewCap[5,1,4,13] 0\n",
      "P_NewCap[5,1,4,14] 0\n",
      "P_NewCap[5,1,4,15] 0\n",
      "P_NewCap[5,1,4,16] 0\n",
      "P_NewCap[5,1,4,17] 0\n",
      "P_NewCap[5,1,4,18] 0\n",
      "P_NewCap[5,1,4,19] 0\n",
      "P_NewCap[5,1,4,20] 0\n",
      "P_NewCap[5,1,4,21] 0\n",
      "P_NewCap[5,1,4,22] 0\n",
      "P_NewCap[5,1,4,23] 0\n",
      "P_NewCap[6,0,0,0] 0\n",
      "P_NewCap[6,0,0,1] 0\n",
      "P_NewCap[6,0,0,2] 0\n",
      "P_NewCap[6,0,0,3] 0\n",
      "P_NewCap[6,0,0,4] 0\n",
      "P_NewCap[6,0,0,5] 0\n",
      "P_NewCap[6,0,0,6] 0\n",
      "P_NewCap[6,0,0,7] 0\n",
      "P_NewCap[6,0,0,8] 0\n",
      "P_NewCap[6,0,0,9] 0\n",
      "P_NewCap[6,0,0,10] 0\n",
      "P_NewCap[6,0,0,11] 0\n",
      "P_NewCap[6,0,0,12] 0\n",
      "P_NewCap[6,0,0,13] 0\n",
      "P_NewCap[6,0,0,14] 0\n",
      "P_NewCap[6,0,0,15] 0\n",
      "P_NewCap[6,0,0,16] 0\n",
      "P_NewCap[6,0,0,17] 0\n",
      "P_NewCap[6,0,0,18] 0\n",
      "P_NewCap[6,0,0,19] 0\n",
      "P_NewCap[6,0,0,20] 0\n",
      "P_NewCap[6,0,0,21] 0\n",
      "P_NewCap[6,0,0,22] 0\n",
      "P_NewCap[6,0,0,23] 0\n",
      "P_NewCap[6,0,1,0] 0\n",
      "P_NewCap[6,0,1,1] 0\n",
      "P_NewCap[6,0,1,2] 0\n",
      "P_NewCap[6,0,1,3] 0\n",
      "P_NewCap[6,0,1,4] 0\n",
      "P_NewCap[6,0,1,5] 0\n",
      "P_NewCap[6,0,1,6] 0\n",
      "P_NewCap[6,0,1,7] 0\n",
      "P_NewCap[6,0,1,8] 0\n",
      "P_NewCap[6,0,1,9] 0\n",
      "P_NewCap[6,0,1,10] 0\n",
      "P_NewCap[6,0,1,11] 0\n",
      "P_NewCap[6,0,1,12] 0\n",
      "P_NewCap[6,0,1,13] 0\n",
      "P_NewCap[6,0,1,14] 0\n",
      "P_NewCap[6,0,1,15] 0\n",
      "P_NewCap[6,0,1,16] 0\n",
      "P_NewCap[6,0,1,17] 0\n",
      "P_NewCap[6,0,1,18] 0\n",
      "P_NewCap[6,0,1,19] 0\n",
      "P_NewCap[6,0,1,20] 0\n",
      "P_NewCap[6,0,1,21] 0\n",
      "P_NewCap[6,0,1,22] 0\n",
      "P_NewCap[6,0,1,23] 0\n",
      "P_NewCap[6,0,2,0] 0\n",
      "P_NewCap[6,0,2,1] 0\n",
      "P_NewCap[6,0,2,2] 0\n",
      "P_NewCap[6,0,2,3] 0\n",
      "P_NewCap[6,0,2,4] 0\n",
      "P_NewCap[6,0,2,5] 0\n",
      "P_NewCap[6,0,2,6] 0\n",
      "P_NewCap[6,0,2,7] 0\n",
      "P_NewCap[6,0,2,8] 0\n",
      "P_NewCap[6,0,2,9] 0\n",
      "P_NewCap[6,0,2,10] 0\n",
      "P_NewCap[6,0,2,11] 0\n",
      "P_NewCap[6,0,2,12] 0\n",
      "P_NewCap[6,0,2,13] 0\n",
      "P_NewCap[6,0,2,14] 0\n",
      "P_NewCap[6,0,2,15] 0\n",
      "P_NewCap[6,0,2,16] 0\n",
      "P_NewCap[6,0,2,17] 0\n",
      "P_NewCap[6,0,2,18] 0\n",
      "P_NewCap[6,0,2,19] 0\n",
      "P_NewCap[6,0,2,20] 0\n",
      "P_NewCap[6,0,2,21] 0\n",
      "P_NewCap[6,0,2,22] 0\n",
      "P_NewCap[6,0,2,23] 0\n",
      "P_NewCap[6,0,3,0] 0\n",
      "P_NewCap[6,0,3,1] 0\n",
      "P_NewCap[6,0,3,2] 0\n",
      "P_NewCap[6,0,3,3] 0\n",
      "P_NewCap[6,0,3,4] 0\n",
      "P_NewCap[6,0,3,5] 0\n",
      "P_NewCap[6,0,3,6] 0\n",
      "P_NewCap[6,0,3,7] 0\n",
      "P_NewCap[6,0,3,8] 0\n",
      "P_NewCap[6,0,3,9] 0\n",
      "P_NewCap[6,0,3,10] 0\n",
      "P_NewCap[6,0,3,11] 0\n",
      "P_NewCap[6,0,3,12] 0\n",
      "P_NewCap[6,0,3,13] 0\n",
      "P_NewCap[6,0,3,14] 0\n",
      "P_NewCap[6,0,3,15] 0\n",
      "P_NewCap[6,0,3,16] 0\n",
      "P_NewCap[6,0,3,17] 0\n",
      "P_NewCap[6,0,3,18] 0\n",
      "P_NewCap[6,0,3,19] 0\n",
      "P_NewCap[6,0,3,20] 0\n",
      "P_NewCap[6,0,3,21] 0\n",
      "P_NewCap[6,0,3,22] 0\n",
      "P_NewCap[6,0,3,23] 0\n",
      "P_NewCap[6,0,4,0] 0\n",
      "P_NewCap[6,0,4,1] 0\n",
      "P_NewCap[6,0,4,2] 0\n",
      "P_NewCap[6,0,4,3] 0\n",
      "P_NewCap[6,0,4,4] 0\n",
      "P_NewCap[6,0,4,5] 0\n",
      "P_NewCap[6,0,4,6] 0\n",
      "P_NewCap[6,0,4,7] 0\n",
      "P_NewCap[6,0,4,8] 0\n",
      "P_NewCap[6,0,4,9] 0\n",
      "P_NewCap[6,0,4,10] 0\n",
      "P_NewCap[6,0,4,11] 0\n",
      "P_NewCap[6,0,4,12] 0\n",
      "P_NewCap[6,0,4,13] 0\n",
      "P_NewCap[6,0,4,14] 0\n",
      "P_NewCap[6,0,4,15] 0\n",
      "P_NewCap[6,0,4,16] 0\n",
      "P_NewCap[6,0,4,17] 0\n",
      "P_NewCap[6,0,4,18] 0\n",
      "P_NewCap[6,0,4,19] 0\n",
      "P_NewCap[6,0,4,20] 0\n",
      "P_NewCap[6,0,4,21] 0\n",
      "P_NewCap[6,0,4,22] 0\n",
      "P_NewCap[6,0,4,23] 0\n",
      "P_NewCap[6,1,0,0] 0\n",
      "P_NewCap[6,1,0,1] 0\n",
      "P_NewCap[6,1,0,2] 0\n",
      "P_NewCap[6,1,0,3] 0\n",
      "P_NewCap[6,1,0,4] 0\n",
      "P_NewCap[6,1,0,5] 0\n",
      "P_NewCap[6,1,0,6] 0\n",
      "P_NewCap[6,1,0,7] 0\n",
      "P_NewCap[6,1,0,8] 0\n",
      "P_NewCap[6,1,0,9] 0\n",
      "P_NewCap[6,1,0,10] 0\n",
      "P_NewCap[6,1,0,11] 0\n",
      "P_NewCap[6,1,0,12] 0\n",
      "P_NewCap[6,1,0,13] 0\n",
      "P_NewCap[6,1,0,14] 0\n",
      "P_NewCap[6,1,0,15] 0\n",
      "P_NewCap[6,1,0,16] 0\n",
      "P_NewCap[6,1,0,17] 0\n",
      "P_NewCap[6,1,0,18] 0\n",
      "P_NewCap[6,1,0,19] 0\n",
      "P_NewCap[6,1,0,20] 0\n",
      "P_NewCap[6,1,0,21] 0\n",
      "P_NewCap[6,1,0,22] 0\n",
      "P_NewCap[6,1,0,23] 0\n",
      "P_NewCap[6,1,1,0] 0\n",
      "P_NewCap[6,1,1,1] 0\n",
      "P_NewCap[6,1,1,2] 0\n",
      "P_NewCap[6,1,1,3] 0\n",
      "P_NewCap[6,1,1,4] 0\n",
      "P_NewCap[6,1,1,5] 0\n",
      "P_NewCap[6,1,1,6] 0\n",
      "P_NewCap[6,1,1,7] 0\n",
      "P_NewCap[6,1,1,8] 0\n",
      "P_NewCap[6,1,1,9] 0\n",
      "P_NewCap[6,1,1,10] 0\n",
      "P_NewCap[6,1,1,11] 0\n",
      "P_NewCap[6,1,1,12] 0\n",
      "P_NewCap[6,1,1,13] 0\n",
      "P_NewCap[6,1,1,14] 0\n",
      "P_NewCap[6,1,1,15] 0\n",
      "P_NewCap[6,1,1,16] 0\n",
      "P_NewCap[6,1,1,17] 0\n",
      "P_NewCap[6,1,1,18] 0\n",
      "P_NewCap[6,1,1,19] 0\n",
      "P_NewCap[6,1,1,20] 0\n",
      "P_NewCap[6,1,1,21] 0\n",
      "P_NewCap[6,1,1,22] 0\n",
      "P_NewCap[6,1,1,23] 0\n",
      "P_NewCap[6,1,2,0] 0\n",
      "P_NewCap[6,1,2,1] 0\n",
      "P_NewCap[6,1,2,2] 0\n",
      "P_NewCap[6,1,2,3] 0\n",
      "P_NewCap[6,1,2,4] 0\n",
      "P_NewCap[6,1,2,5] 0\n",
      "P_NewCap[6,1,2,6] 0\n",
      "P_NewCap[6,1,2,7] 0\n",
      "P_NewCap[6,1,2,8] 0\n",
      "P_NewCap[6,1,2,9] 0\n",
      "P_NewCap[6,1,2,10] 0\n",
      "P_NewCap[6,1,2,11] 0\n",
      "P_NewCap[6,1,2,12] 0\n",
      "P_NewCap[6,1,2,13] 0\n",
      "P_NewCap[6,1,2,14] 0\n",
      "P_NewCap[6,1,2,15] 0\n",
      "P_NewCap[6,1,2,16] 0\n",
      "P_NewCap[6,1,2,17] 0\n",
      "P_NewCap[6,1,2,18] 0\n",
      "P_NewCap[6,1,2,19] 0\n",
      "P_NewCap[6,1,2,20] 0\n",
      "P_NewCap[6,1,2,21] 0\n",
      "P_NewCap[6,1,2,22] 0\n",
      "P_NewCap[6,1,2,23] 0\n",
      "P_NewCap[6,1,3,0] 0\n",
      "P_NewCap[6,1,3,1] 0\n",
      "P_NewCap[6,1,3,2] 0\n",
      "P_NewCap[6,1,3,3] 0\n",
      "P_NewCap[6,1,3,4] 0\n",
      "P_NewCap[6,1,3,5] 0\n",
      "P_NewCap[6,1,3,6] 0\n",
      "P_NewCap[6,1,3,7] 0\n",
      "P_NewCap[6,1,3,8] 0\n",
      "P_NewCap[6,1,3,9] 0\n",
      "P_NewCap[6,1,3,10] 0\n",
      "P_NewCap[6,1,3,11] 0\n",
      "P_NewCap[6,1,3,12] 0\n",
      "P_NewCap[6,1,3,13] 0\n",
      "P_NewCap[6,1,3,14] 0\n",
      "P_NewCap[6,1,3,15] 0\n",
      "P_NewCap[6,1,3,16] 0\n",
      "P_NewCap[6,1,3,17] 0\n",
      "P_NewCap[6,1,3,18] 0\n",
      "P_NewCap[6,1,3,19] 0\n",
      "P_NewCap[6,1,3,20] 0\n",
      "P_NewCap[6,1,3,21] 0\n",
      "P_NewCap[6,1,3,22] 0\n",
      "P_NewCap[6,1,3,23] 0\n",
      "P_NewCap[6,1,4,0] 0\n",
      "P_NewCap[6,1,4,1] 0\n",
      "P_NewCap[6,1,4,2] 0\n",
      "P_NewCap[6,1,4,3] 0\n",
      "P_NewCap[6,1,4,4] 0\n",
      "P_NewCap[6,1,4,5] 0\n",
      "P_NewCap[6,1,4,6] 0\n",
      "P_NewCap[6,1,4,7] 0\n",
      "P_NewCap[6,1,4,8] 0\n",
      "P_NewCap[6,1,4,9] 0\n",
      "P_NewCap[6,1,4,10] 0\n",
      "P_NewCap[6,1,4,11] 0\n",
      "P_NewCap[6,1,4,12] 0\n",
      "P_NewCap[6,1,4,13] 0\n",
      "P_NewCap[6,1,4,14] 0\n",
      "P_NewCap[6,1,4,15] 0\n",
      "P_NewCap[6,1,4,16] 0\n",
      "P_NewCap[6,1,4,17] 0\n",
      "P_NewCap[6,1,4,18] 0\n",
      "P_NewCap[6,1,4,19] 0\n",
      "P_NewCap[6,1,4,20] 0\n",
      "P_NewCap[6,1,4,21] 0\n",
      "P_NewCap[6,1,4,22] 0\n",
      "P_NewCap[6,1,4,23] 0\n",
      "P_NewCap[7,0,0,0] 0\n",
      "P_NewCap[7,0,0,1] 0\n",
      "P_NewCap[7,0,0,2] 0\n",
      "P_NewCap[7,0,0,3] 0\n",
      "P_NewCap[7,0,0,4] 0\n",
      "P_NewCap[7,0,0,5] 0\n",
      "P_NewCap[7,0,0,6] 0\n",
      "P_NewCap[7,0,0,7] 0\n",
      "P_NewCap[7,0,0,8] 0\n",
      "P_NewCap[7,0,0,9] 0\n",
      "P_NewCap[7,0,0,10] 0\n",
      "P_NewCap[7,0,0,11] 0\n",
      "P_NewCap[7,0,0,12] 0\n",
      "P_NewCap[7,0,0,13] 0\n",
      "P_NewCap[7,0,0,14] 0\n",
      "P_NewCap[7,0,0,15] 0\n",
      "P_NewCap[7,0,0,16] 0\n",
      "P_NewCap[7,0,0,17] 0\n",
      "P_NewCap[7,0,0,18] 0\n",
      "P_NewCap[7,0,0,19] 0\n",
      "P_NewCap[7,0,0,20] 0\n",
      "P_NewCap[7,0,0,21] 0\n",
      "P_NewCap[7,0,0,22] 0\n",
      "P_NewCap[7,0,0,23] 0\n",
      "P_NewCap[7,0,1,0] 0\n",
      "P_NewCap[7,0,1,1] 0\n",
      "P_NewCap[7,0,1,2] 0\n",
      "P_NewCap[7,0,1,3] 0\n",
      "P_NewCap[7,0,1,4] 0\n",
      "P_NewCap[7,0,1,5] 0\n",
      "P_NewCap[7,0,1,6] 0\n",
      "P_NewCap[7,0,1,7] 0\n",
      "P_NewCap[7,0,1,8] 0\n",
      "P_NewCap[7,0,1,9] 0\n",
      "P_NewCap[7,0,1,10] 0\n",
      "P_NewCap[7,0,1,11] 0\n",
      "P_NewCap[7,0,1,12] 0\n",
      "P_NewCap[7,0,1,13] 0\n",
      "P_NewCap[7,0,1,14] 0\n",
      "P_NewCap[7,0,1,15] 0\n",
      "P_NewCap[7,0,1,16] 0\n",
      "P_NewCap[7,0,1,17] 0\n",
      "P_NewCap[7,0,1,18] 0\n",
      "P_NewCap[7,0,1,19] 0\n",
      "P_NewCap[7,0,1,20] 0\n",
      "P_NewCap[7,0,1,21] 0\n",
      "P_NewCap[7,0,1,22] 0\n",
      "P_NewCap[7,0,1,23] 0\n",
      "P_NewCap[7,0,2,0] 0\n",
      "P_NewCap[7,0,2,1] 0\n",
      "P_NewCap[7,0,2,2] 0\n",
      "P_NewCap[7,0,2,3] 0\n",
      "P_NewCap[7,0,2,4] 0\n",
      "P_NewCap[7,0,2,5] 0\n",
      "P_NewCap[7,0,2,6] 0\n",
      "P_NewCap[7,0,2,7] 0\n",
      "P_NewCap[7,0,2,8] 0\n",
      "P_NewCap[7,0,2,9] 0\n",
      "P_NewCap[7,0,2,10] 0\n",
      "P_NewCap[7,0,2,11] 0\n",
      "P_NewCap[7,0,2,12] 0\n",
      "P_NewCap[7,0,2,13] 0\n",
      "P_NewCap[7,0,2,14] 0\n",
      "P_NewCap[7,0,2,15] 0\n",
      "P_NewCap[7,0,2,16] 0\n",
      "P_NewCap[7,0,2,17] 0\n",
      "P_NewCap[7,0,2,18] 0\n",
      "P_NewCap[7,0,2,19] 0\n",
      "P_NewCap[7,0,2,20] 0\n",
      "P_NewCap[7,0,2,21] 0\n",
      "P_NewCap[7,0,2,22] 0\n",
      "P_NewCap[7,0,2,23] 0\n",
      "P_NewCap[7,0,3,0] 0\n",
      "P_NewCap[7,0,3,1] 0\n",
      "P_NewCap[7,0,3,2] 0\n",
      "P_NewCap[7,0,3,3] 0\n",
      "P_NewCap[7,0,3,4] 0\n",
      "P_NewCap[7,0,3,5] 0\n",
      "P_NewCap[7,0,3,6] 0\n",
      "P_NewCap[7,0,3,7] 0\n",
      "P_NewCap[7,0,3,8] 0\n",
      "P_NewCap[7,0,3,9] 0\n",
      "P_NewCap[7,0,3,10] 0\n",
      "P_NewCap[7,0,3,11] 0\n",
      "P_NewCap[7,0,3,12] 0\n",
      "P_NewCap[7,0,3,13] 0\n",
      "P_NewCap[7,0,3,14] 0\n",
      "P_NewCap[7,0,3,15] 0\n",
      "P_NewCap[7,0,3,16] 0\n",
      "P_NewCap[7,0,3,17] 0\n",
      "P_NewCap[7,0,3,18] 0\n",
      "P_NewCap[7,0,3,19] 0\n",
      "P_NewCap[7,0,3,20] 0\n",
      "P_NewCap[7,0,3,21] 0\n",
      "P_NewCap[7,0,3,22] 0\n",
      "P_NewCap[7,0,3,23] 0\n",
      "P_NewCap[7,0,4,0] 0\n",
      "P_NewCap[7,0,4,1] 0\n",
      "P_NewCap[7,0,4,2] 0\n",
      "P_NewCap[7,0,4,3] 0\n",
      "P_NewCap[7,0,4,4] 0\n",
      "P_NewCap[7,0,4,5] 0\n",
      "P_NewCap[7,0,4,6] 0\n",
      "P_NewCap[7,0,4,7] 0\n",
      "P_NewCap[7,0,4,8] 0\n",
      "P_NewCap[7,0,4,9] 0\n",
      "P_NewCap[7,0,4,10] 0\n",
      "P_NewCap[7,0,4,11] 0\n",
      "P_NewCap[7,0,4,12] 0\n",
      "P_NewCap[7,0,4,13] 0\n",
      "P_NewCap[7,0,4,14] 0\n",
      "P_NewCap[7,0,4,15] 0\n",
      "P_NewCap[7,0,4,16] 0\n",
      "P_NewCap[7,0,4,17] 0\n",
      "P_NewCap[7,0,4,18] 0\n",
      "P_NewCap[7,0,4,19] 0\n",
      "P_NewCap[7,0,4,20] 0\n",
      "P_NewCap[7,0,4,21] 0\n",
      "P_NewCap[7,0,4,22] 0\n",
      "P_NewCap[7,0,4,23] 0\n",
      "P_NewCap[7,1,0,0] 0\n",
      "P_NewCap[7,1,0,1] 0\n",
      "P_NewCap[7,1,0,2] 0\n",
      "P_NewCap[7,1,0,3] 0\n",
      "P_NewCap[7,1,0,4] 0\n",
      "P_NewCap[7,1,0,5] 0\n",
      "P_NewCap[7,1,0,6] 0\n",
      "P_NewCap[7,1,0,7] 0\n",
      "P_NewCap[7,1,0,8] 0\n",
      "P_NewCap[7,1,0,9] 0\n",
      "P_NewCap[7,1,0,10] 0\n",
      "P_NewCap[7,1,0,11] 0\n",
      "P_NewCap[7,1,0,12] 0\n",
      "P_NewCap[7,1,0,13] 0\n",
      "P_NewCap[7,1,0,14] 0\n",
      "P_NewCap[7,1,0,15] 0\n",
      "P_NewCap[7,1,0,16] 0\n",
      "P_NewCap[7,1,0,17] 0\n",
      "P_NewCap[7,1,0,18] 0\n",
      "P_NewCap[7,1,0,19] 0\n",
      "P_NewCap[7,1,0,20] 0\n",
      "P_NewCap[7,1,0,21] 0\n",
      "P_NewCap[7,1,0,22] 0\n",
      "P_NewCap[7,1,0,23] 0\n",
      "P_NewCap[7,1,1,0] 0\n",
      "P_NewCap[7,1,1,1] 0\n",
      "P_NewCap[7,1,1,2] 0\n",
      "P_NewCap[7,1,1,3] 0\n",
      "P_NewCap[7,1,1,4] 0\n",
      "P_NewCap[7,1,1,5] 0\n",
      "P_NewCap[7,1,1,6] 0\n",
      "P_NewCap[7,1,1,7] 0\n",
      "P_NewCap[7,1,1,8] 0\n",
      "P_NewCap[7,1,1,9] 0\n",
      "P_NewCap[7,1,1,10] 0\n",
      "P_NewCap[7,1,1,11] 0\n",
      "P_NewCap[7,1,1,12] 0\n",
      "P_NewCap[7,1,1,13] 0\n",
      "P_NewCap[7,1,1,14] 0\n",
      "P_NewCap[7,1,1,15] 0\n",
      "P_NewCap[7,1,1,16] 0\n",
      "P_NewCap[7,1,1,17] 0\n",
      "P_NewCap[7,1,1,18] 0\n",
      "P_NewCap[7,1,1,19] 0\n",
      "P_NewCap[7,1,1,20] 0\n",
      "P_NewCap[7,1,1,21] 0\n",
      "P_NewCap[7,1,1,22] 0\n",
      "P_NewCap[7,1,1,23] 0\n",
      "P_NewCap[7,1,2,0] 0\n",
      "P_NewCap[7,1,2,1] 0\n",
      "P_NewCap[7,1,2,2] 0\n",
      "P_NewCap[7,1,2,3] 0\n",
      "P_NewCap[7,1,2,4] 0\n",
      "P_NewCap[7,1,2,5] 0\n",
      "P_NewCap[7,1,2,6] 0\n",
      "P_NewCap[7,1,2,7] 0\n",
      "P_NewCap[7,1,2,8] 0\n",
      "P_NewCap[7,1,2,9] 0\n",
      "P_NewCap[7,1,2,10] 0\n",
      "P_NewCap[7,1,2,11] 0\n",
      "P_NewCap[7,1,2,12] 0\n",
      "P_NewCap[7,1,2,13] 0\n",
      "P_NewCap[7,1,2,14] 0\n",
      "P_NewCap[7,1,2,15] 0\n",
      "P_NewCap[7,1,2,16] 0\n",
      "P_NewCap[7,1,2,17] 0\n",
      "P_NewCap[7,1,2,18] 0\n",
      "P_NewCap[7,1,2,19] 0\n",
      "P_NewCap[7,1,2,20] 0\n",
      "P_NewCap[7,1,2,21] 0\n",
      "P_NewCap[7,1,2,22] 0\n",
      "P_NewCap[7,1,2,23] 0\n",
      "P_NewCap[7,1,3,0] 0\n",
      "P_NewCap[7,1,3,1] 0\n",
      "P_NewCap[7,1,3,2] 0\n",
      "P_NewCap[7,1,3,3] 0\n",
      "P_NewCap[7,1,3,4] 0\n",
      "P_NewCap[7,1,3,5] 0\n",
      "P_NewCap[7,1,3,6] 0\n",
      "P_NewCap[7,1,3,7] 0\n",
      "P_NewCap[7,1,3,8] 0\n",
      "P_NewCap[7,1,3,9] 0\n",
      "P_NewCap[7,1,3,10] 0\n",
      "P_NewCap[7,1,3,11] 0\n",
      "P_NewCap[7,1,3,12] 0\n",
      "P_NewCap[7,1,3,13] 0\n",
      "P_NewCap[7,1,3,14] 0\n",
      "P_NewCap[7,1,3,15] 0\n",
      "P_NewCap[7,1,3,16] 0\n",
      "P_NewCap[7,1,3,17] 0\n",
      "P_NewCap[7,1,3,18] 0\n",
      "P_NewCap[7,1,3,19] 0\n",
      "P_NewCap[7,1,3,20] 0\n",
      "P_NewCap[7,1,3,21] 0\n",
      "P_NewCap[7,1,3,22] 0\n",
      "P_NewCap[7,1,3,23] 0\n",
      "P_NewCap[7,1,4,0] 0\n",
      "P_NewCap[7,1,4,1] 0\n",
      "P_NewCap[7,1,4,2] 0\n",
      "P_NewCap[7,1,4,3] 0\n",
      "P_NewCap[7,1,4,4] 0\n",
      "P_NewCap[7,1,4,5] 0\n",
      "P_NewCap[7,1,4,6] 0\n",
      "P_NewCap[7,1,4,7] 0\n",
      "P_NewCap[7,1,4,8] 0\n",
      "P_NewCap[7,1,4,9] 0\n",
      "P_NewCap[7,1,4,10] 0\n",
      "P_NewCap[7,1,4,11] 0\n",
      "P_NewCap[7,1,4,12] 0\n",
      "P_NewCap[7,1,4,13] 0\n",
      "P_NewCap[7,1,4,14] 0\n",
      "P_NewCap[7,1,4,15] 0\n",
      "P_NewCap[7,1,4,16] 0\n",
      "P_NewCap[7,1,4,17] 0\n",
      "P_NewCap[7,1,4,18] 0\n",
      "P_NewCap[7,1,4,19] 0\n",
      "P_NewCap[7,1,4,20] 0\n",
      "P_NewCap[7,1,4,21] 0\n",
      "P_NewCap[7,1,4,22] 0\n",
      "P_NewCap[7,1,4,23] 0\n",
      "P_NewCap[8,0,0,0] 0\n",
      "P_NewCap[8,0,0,1] 0\n",
      "P_NewCap[8,0,0,2] 0\n",
      "P_NewCap[8,0,0,3] 0\n",
      "P_NewCap[8,0,0,4] 0\n",
      "P_NewCap[8,0,0,5] 0\n",
      "P_NewCap[8,0,0,6] 0\n",
      "P_NewCap[8,0,0,7] 0\n",
      "P_NewCap[8,0,0,8] 0\n",
      "P_NewCap[8,0,0,9] 0\n",
      "P_NewCap[8,0,0,10] 0\n",
      "P_NewCap[8,0,0,11] 0\n",
      "P_NewCap[8,0,0,12] 0\n",
      "P_NewCap[8,0,0,13] 0\n",
      "P_NewCap[8,0,0,14] 0\n",
      "P_NewCap[8,0,0,15] 0\n",
      "P_NewCap[8,0,0,16] 0\n",
      "P_NewCap[8,0,0,17] 0\n",
      "P_NewCap[8,0,0,18] 0\n",
      "P_NewCap[8,0,0,19] 0\n",
      "P_NewCap[8,0,0,20] 0\n",
      "P_NewCap[8,0,0,21] 0\n",
      "P_NewCap[8,0,0,22] 0\n",
      "P_NewCap[8,0,0,23] 0\n",
      "P_NewCap[8,0,1,0] 0\n",
      "P_NewCap[8,0,1,1] 0\n",
      "P_NewCap[8,0,1,2] 0\n",
      "P_NewCap[8,0,1,3] 0\n",
      "P_NewCap[8,0,1,4] 0\n",
      "P_NewCap[8,0,1,5] 0\n",
      "P_NewCap[8,0,1,6] 0\n",
      "P_NewCap[8,0,1,7] 0\n",
      "P_NewCap[8,0,1,8] 0\n",
      "P_NewCap[8,0,1,9] 0\n",
      "P_NewCap[8,0,1,10] 0\n",
      "P_NewCap[8,0,1,11] 0\n",
      "P_NewCap[8,0,1,12] 0\n",
      "P_NewCap[8,0,1,13] 0\n",
      "P_NewCap[8,0,1,14] 0\n",
      "P_NewCap[8,0,1,15] 0\n",
      "P_NewCap[8,0,1,16] 0\n",
      "P_NewCap[8,0,1,17] 0\n",
      "P_NewCap[8,0,1,18] 0\n",
      "P_NewCap[8,0,1,19] 0\n",
      "P_NewCap[8,0,1,20] 0\n",
      "P_NewCap[8,0,1,21] 0\n",
      "P_NewCap[8,0,1,22] 0\n",
      "P_NewCap[8,0,1,23] 0\n",
      "P_NewCap[8,0,2,0] 0\n",
      "P_NewCap[8,0,2,1] 0\n",
      "P_NewCap[8,0,2,2] 0\n",
      "P_NewCap[8,0,2,3] 0\n",
      "P_NewCap[8,0,2,4] 0\n",
      "P_NewCap[8,0,2,5] 0\n",
      "P_NewCap[8,0,2,6] 0\n",
      "P_NewCap[8,0,2,7] 0\n",
      "P_NewCap[8,0,2,8] 0\n",
      "P_NewCap[8,0,2,9] 0\n",
      "P_NewCap[8,0,2,10] 0\n",
      "P_NewCap[8,0,2,11] 0\n",
      "P_NewCap[8,0,2,12] 0\n",
      "P_NewCap[8,0,2,13] 0\n",
      "P_NewCap[8,0,2,14] 0\n",
      "P_NewCap[8,0,2,15] 0\n",
      "P_NewCap[8,0,2,16] 0\n",
      "P_NewCap[8,0,2,17] 0\n",
      "P_NewCap[8,0,2,18] 0\n",
      "P_NewCap[8,0,2,19] 0\n",
      "P_NewCap[8,0,2,20] 0\n",
      "P_NewCap[8,0,2,21] 0\n",
      "P_NewCap[8,0,2,22] 0\n",
      "P_NewCap[8,0,2,23] 0\n",
      "P_NewCap[8,0,3,0] 0\n",
      "P_NewCap[8,0,3,1] 0\n",
      "P_NewCap[8,0,3,2] 0\n",
      "P_NewCap[8,0,3,3] 0\n",
      "P_NewCap[8,0,3,4] 0\n",
      "P_NewCap[8,0,3,5] 0\n",
      "P_NewCap[8,0,3,6] 0\n",
      "P_NewCap[8,0,3,7] 0\n",
      "P_NewCap[8,0,3,8] 0\n",
      "P_NewCap[8,0,3,9] 0\n",
      "P_NewCap[8,0,3,10] 0\n",
      "P_NewCap[8,0,3,11] 0\n",
      "P_NewCap[8,0,3,12] 0\n",
      "P_NewCap[8,0,3,13] 0\n",
      "P_NewCap[8,0,3,14] 0\n",
      "P_NewCap[8,0,3,15] 0\n",
      "P_NewCap[8,0,3,16] 0\n",
      "P_NewCap[8,0,3,17] 0\n",
      "P_NewCap[8,0,3,18] 0\n",
      "P_NewCap[8,0,3,19] 0\n",
      "P_NewCap[8,0,3,20] 0\n",
      "P_NewCap[8,0,3,21] 0\n",
      "P_NewCap[8,0,3,22] 0\n",
      "P_NewCap[8,0,3,23] 0\n",
      "P_NewCap[8,0,4,0] 0\n",
      "P_NewCap[8,0,4,1] 0\n",
      "P_NewCap[8,0,4,2] 0\n",
      "P_NewCap[8,0,4,3] 0\n",
      "P_NewCap[8,0,4,4] 0\n",
      "P_NewCap[8,0,4,5] 0\n",
      "P_NewCap[8,0,4,6] 0\n",
      "P_NewCap[8,0,4,7] 0\n",
      "P_NewCap[8,0,4,8] 0\n",
      "P_NewCap[8,0,4,9] 0\n",
      "P_NewCap[8,0,4,10] 0\n",
      "P_NewCap[8,0,4,11] 0\n",
      "P_NewCap[8,0,4,12] 0\n",
      "P_NewCap[8,0,4,13] 0\n",
      "P_NewCap[8,0,4,14] 0\n",
      "P_NewCap[8,0,4,15] 0\n",
      "P_NewCap[8,0,4,16] 0\n",
      "P_NewCap[8,0,4,17] 0\n",
      "P_NewCap[8,0,4,18] 0\n",
      "P_NewCap[8,0,4,19] 0\n",
      "P_NewCap[8,0,4,20] 0\n",
      "P_NewCap[8,0,4,21] 0\n",
      "P_NewCap[8,0,4,22] 0\n",
      "P_NewCap[8,0,4,23] 0\n",
      "P_NewCap[8,1,0,0] 0\n",
      "P_NewCap[8,1,0,1] 0\n",
      "P_NewCap[8,1,0,2] 0\n",
      "P_NewCap[8,1,0,3] 0\n",
      "P_NewCap[8,1,0,4] 0\n",
      "P_NewCap[8,1,0,5] 0\n",
      "P_NewCap[8,1,0,6] 0\n",
      "P_NewCap[8,1,0,7] 0\n",
      "P_NewCap[8,1,0,8] 0\n",
      "P_NewCap[8,1,0,9] 0\n",
      "P_NewCap[8,1,0,10] 0\n",
      "P_NewCap[8,1,0,11] 0\n",
      "P_NewCap[8,1,0,12] 0\n",
      "P_NewCap[8,1,0,13] 0\n",
      "P_NewCap[8,1,0,14] 0\n",
      "P_NewCap[8,1,0,15] 0\n",
      "P_NewCap[8,1,0,16] 0\n",
      "P_NewCap[8,1,0,17] 0\n",
      "P_NewCap[8,1,0,18] 0\n",
      "P_NewCap[8,1,0,19] 0\n",
      "P_NewCap[8,1,0,20] 0\n",
      "P_NewCap[8,1,0,21] 0\n",
      "P_NewCap[8,1,0,22] 0\n",
      "P_NewCap[8,1,0,23] 0\n",
      "P_NewCap[8,1,1,0] 0\n",
      "P_NewCap[8,1,1,1] 0\n",
      "P_NewCap[8,1,1,2] 0\n",
      "P_NewCap[8,1,1,3] 0\n",
      "P_NewCap[8,1,1,4] 0\n",
      "P_NewCap[8,1,1,5] 0\n",
      "P_NewCap[8,1,1,6] 0\n",
      "P_NewCap[8,1,1,7] 0\n",
      "P_NewCap[8,1,1,8] 0\n",
      "P_NewCap[8,1,1,9] 0\n",
      "P_NewCap[8,1,1,10] 0\n",
      "P_NewCap[8,1,1,11] 0\n",
      "P_NewCap[8,1,1,12] 0\n",
      "P_NewCap[8,1,1,13] 0\n",
      "P_NewCap[8,1,1,14] 0\n",
      "P_NewCap[8,1,1,15] 0\n",
      "P_NewCap[8,1,1,16] 0\n",
      "P_NewCap[8,1,1,17] 0\n",
      "P_NewCap[8,1,1,18] 0\n",
      "P_NewCap[8,1,1,19] 0\n",
      "P_NewCap[8,1,1,20] 0\n",
      "P_NewCap[8,1,1,21] 0\n",
      "P_NewCap[8,1,1,22] 0\n",
      "P_NewCap[8,1,1,23] 0\n",
      "P_NewCap[8,1,2,0] 0\n",
      "P_NewCap[8,1,2,1] 0\n",
      "P_NewCap[8,1,2,2] 0\n",
      "P_NewCap[8,1,2,3] 0\n",
      "P_NewCap[8,1,2,4] 0\n",
      "P_NewCap[8,1,2,5] 0\n",
      "P_NewCap[8,1,2,6] 0\n",
      "P_NewCap[8,1,2,7] 0\n",
      "P_NewCap[8,1,2,8] 0\n",
      "P_NewCap[8,1,2,9] 0\n",
      "P_NewCap[8,1,2,10] 0\n",
      "P_NewCap[8,1,2,11] 0\n",
      "P_NewCap[8,1,2,12] 0\n",
      "P_NewCap[8,1,2,13] 0\n",
      "P_NewCap[8,1,2,14] 0\n",
      "P_NewCap[8,1,2,15] 0\n",
      "P_NewCap[8,1,2,16] 0\n",
      "P_NewCap[8,1,2,17] 0\n",
      "P_NewCap[8,1,2,18] 0\n",
      "P_NewCap[8,1,2,19] 0\n",
      "P_NewCap[8,1,2,20] 0\n",
      "P_NewCap[8,1,2,21] 0\n",
      "P_NewCap[8,1,2,22] 0\n",
      "P_NewCap[8,1,2,23] 0\n",
      "P_NewCap[8,1,3,0] 0\n",
      "P_NewCap[8,1,3,1] 0\n",
      "P_NewCap[8,1,3,2] 0\n",
      "P_NewCap[8,1,3,3] 0\n",
      "P_NewCap[8,1,3,4] 0\n",
      "P_NewCap[8,1,3,5] 0\n",
      "P_NewCap[8,1,3,6] 0\n",
      "P_NewCap[8,1,3,7] 0\n",
      "P_NewCap[8,1,3,8] 0\n",
      "P_NewCap[8,1,3,9] 0\n",
      "P_NewCap[8,1,3,10] 0\n",
      "P_NewCap[8,1,3,11] 0\n",
      "P_NewCap[8,1,3,12] 0\n",
      "P_NewCap[8,1,3,13] 0\n",
      "P_NewCap[8,1,3,14] 0\n",
      "P_NewCap[8,1,3,15] 0\n",
      "P_NewCap[8,1,3,16] 0\n",
      "P_NewCap[8,1,3,17] 0\n",
      "P_NewCap[8,1,3,18] 0\n",
      "P_NewCap[8,1,3,19] 0\n",
      "P_NewCap[8,1,3,20] 0\n",
      "P_NewCap[8,1,3,21] 0\n",
      "P_NewCap[8,1,3,22] 0\n",
      "P_NewCap[8,1,3,23] 0\n",
      "P_NewCap[8,1,4,0] 0\n",
      "P_NewCap[8,1,4,1] 0\n",
      "P_NewCap[8,1,4,2] 0\n",
      "P_NewCap[8,1,4,3] 0\n",
      "P_NewCap[8,1,4,4] 0\n",
      "P_NewCap[8,1,4,5] 0\n",
      "P_NewCap[8,1,4,6] 0\n",
      "P_NewCap[8,1,4,7] 0\n",
      "P_NewCap[8,1,4,8] 0\n",
      "P_NewCap[8,1,4,9] 0\n",
      "P_NewCap[8,1,4,10] 0\n",
      "P_NewCap[8,1,4,11] 0\n",
      "P_NewCap[8,1,4,12] 0\n",
      "P_NewCap[8,1,4,13] 0\n",
      "P_NewCap[8,1,4,14] 0\n",
      "P_NewCap[8,1,4,15] 0\n",
      "P_NewCap[8,1,4,16] 0\n",
      "P_NewCap[8,1,4,17] 0\n",
      "P_NewCap[8,1,4,18] 0\n",
      "P_NewCap[8,1,4,19] 0\n",
      "P_NewCap[8,1,4,20] 0\n",
      "P_NewCap[8,1,4,21] 0\n",
      "P_NewCap[8,1,4,22] 0\n",
      "P_NewCap[8,1,4,23] 0\n",
      "P_NewCap[9,0,0,0] 0\n",
      "P_NewCap[9,0,0,1] 0\n",
      "P_NewCap[9,0,0,2] 0\n",
      "P_NewCap[9,0,0,3] 0\n",
      "P_NewCap[9,0,0,4] 0\n",
      "P_NewCap[9,0,0,5] 0\n",
      "P_NewCap[9,0,0,6] 0\n",
      "P_NewCap[9,0,0,7] 0\n",
      "P_NewCap[9,0,0,8] 0\n",
      "P_NewCap[9,0,0,9] 0\n",
      "P_NewCap[9,0,0,10] 0\n",
      "P_NewCap[9,0,0,11] 0\n",
      "P_NewCap[9,0,0,12] 0\n",
      "P_NewCap[9,0,0,13] 0\n",
      "P_NewCap[9,0,0,14] 0\n",
      "P_NewCap[9,0,0,15] 0\n",
      "P_NewCap[9,0,0,16] 0\n",
      "P_NewCap[9,0,0,17] 0\n",
      "P_NewCap[9,0,0,18] 0\n",
      "P_NewCap[9,0,0,19] 0\n",
      "P_NewCap[9,0,0,20] 0\n",
      "P_NewCap[9,0,0,21] 0\n",
      "P_NewCap[9,0,0,22] 0\n",
      "P_NewCap[9,0,0,23] 0\n",
      "P_NewCap[9,0,1,0] 0\n",
      "P_NewCap[9,0,1,1] 0\n",
      "P_NewCap[9,0,1,2] 0\n",
      "P_NewCap[9,0,1,3] 0\n",
      "P_NewCap[9,0,1,4] 0\n",
      "P_NewCap[9,0,1,5] 0\n",
      "P_NewCap[9,0,1,6] 0\n",
      "P_NewCap[9,0,1,7] 0\n",
      "P_NewCap[9,0,1,8] 0\n",
      "P_NewCap[9,0,1,9] 0\n",
      "P_NewCap[9,0,1,10] 0\n",
      "P_NewCap[9,0,1,11] 0\n",
      "P_NewCap[9,0,1,12] 0\n",
      "P_NewCap[9,0,1,13] 0\n",
      "P_NewCap[9,0,1,14] 0\n",
      "P_NewCap[9,0,1,15] 0\n",
      "P_NewCap[9,0,1,16] 0\n",
      "P_NewCap[9,0,1,17] 0\n",
      "P_NewCap[9,0,1,18] 0\n",
      "P_NewCap[9,0,1,19] 0\n",
      "P_NewCap[9,0,1,20] 0\n",
      "P_NewCap[9,0,1,21] 0\n",
      "P_NewCap[9,0,1,22] 0\n",
      "P_NewCap[9,0,1,23] 0\n",
      "P_NewCap[9,0,2,0] 0\n",
      "P_NewCap[9,0,2,1] 0\n",
      "P_NewCap[9,0,2,2] 0\n",
      "P_NewCap[9,0,2,3] 0\n",
      "P_NewCap[9,0,2,4] 0\n",
      "P_NewCap[9,0,2,5] 0\n",
      "P_NewCap[9,0,2,6] 0\n",
      "P_NewCap[9,0,2,7] 0\n",
      "P_NewCap[9,0,2,8] 0\n",
      "P_NewCap[9,0,2,9] 0\n",
      "P_NewCap[9,0,2,10] 0\n",
      "P_NewCap[9,0,2,11] 0\n",
      "P_NewCap[9,0,2,12] 0\n",
      "P_NewCap[9,0,2,13] 0\n",
      "P_NewCap[9,0,2,14] 0\n",
      "P_NewCap[9,0,2,15] 0\n",
      "P_NewCap[9,0,2,16] 0\n",
      "P_NewCap[9,0,2,17] 0\n",
      "P_NewCap[9,0,2,18] 0\n",
      "P_NewCap[9,0,2,19] 0\n",
      "P_NewCap[9,0,2,20] 0\n",
      "P_NewCap[9,0,2,21] 0\n",
      "P_NewCap[9,0,2,22] 0\n",
      "P_NewCap[9,0,2,23] 0\n",
      "P_NewCap[9,0,3,0] 0\n",
      "P_NewCap[9,0,3,1] 0\n",
      "P_NewCap[9,0,3,2] 0\n",
      "P_NewCap[9,0,3,3] 0\n",
      "P_NewCap[9,0,3,4] 0\n",
      "P_NewCap[9,0,3,5] 0\n",
      "P_NewCap[9,0,3,6] 0\n",
      "P_NewCap[9,0,3,7] 0\n",
      "P_NewCap[9,0,3,8] 0\n",
      "P_NewCap[9,0,3,9] 0\n",
      "P_NewCap[9,0,3,10] 0\n",
      "P_NewCap[9,0,3,11] 0\n",
      "P_NewCap[9,0,3,12] 0\n",
      "P_NewCap[9,0,3,13] 0\n",
      "P_NewCap[9,0,3,14] 0\n",
      "P_NewCap[9,0,3,15] 0\n",
      "P_NewCap[9,0,3,16] 0\n",
      "P_NewCap[9,0,3,17] 0\n",
      "P_NewCap[9,0,3,18] 0\n",
      "P_NewCap[9,0,3,19] 0\n",
      "P_NewCap[9,0,3,20] 0\n",
      "P_NewCap[9,0,3,21] 0\n",
      "P_NewCap[9,0,3,22] 0\n",
      "P_NewCap[9,0,3,23] 0\n",
      "P_NewCap[9,0,4,0] 0\n",
      "P_NewCap[9,0,4,1] 0\n",
      "P_NewCap[9,0,4,2] 0\n",
      "P_NewCap[9,0,4,3] 0\n",
      "P_NewCap[9,0,4,4] 0\n",
      "P_NewCap[9,0,4,5] 0\n",
      "P_NewCap[9,0,4,6] 0\n",
      "P_NewCap[9,0,4,7] 0\n",
      "P_NewCap[9,0,4,8] 0\n",
      "P_NewCap[9,0,4,9] 0\n",
      "P_NewCap[9,0,4,10] 0\n",
      "P_NewCap[9,0,4,11] 0\n",
      "P_NewCap[9,0,4,12] 0\n",
      "P_NewCap[9,0,4,13] 0\n",
      "P_NewCap[9,0,4,14] 0\n",
      "P_NewCap[9,0,4,15] 0\n",
      "P_NewCap[9,0,4,16] 0\n",
      "P_NewCap[9,0,4,17] 0\n",
      "P_NewCap[9,0,4,18] 0\n",
      "P_NewCap[9,0,4,19] 0\n",
      "P_NewCap[9,0,4,20] 0\n",
      "P_NewCap[9,0,4,21] 0\n",
      "P_NewCap[9,0,4,22] 0\n",
      "P_NewCap[9,0,4,23] 0\n",
      "P_NewCap[9,1,0,0] 0\n",
      "P_NewCap[9,1,0,1] 0\n",
      "P_NewCap[9,1,0,2] 0\n",
      "P_NewCap[9,1,0,3] 0\n",
      "P_NewCap[9,1,0,4] 0\n",
      "P_NewCap[9,1,0,5] 0\n",
      "P_NewCap[9,1,0,6] 0\n",
      "P_NewCap[9,1,0,7] 0\n",
      "P_NewCap[9,1,0,8] 0\n",
      "P_NewCap[9,1,0,9] 0\n",
      "P_NewCap[9,1,0,10] 0\n",
      "P_NewCap[9,1,0,11] 0\n",
      "P_NewCap[9,1,0,12] 0\n",
      "P_NewCap[9,1,0,13] 0\n",
      "P_NewCap[9,1,0,14] 0\n",
      "P_NewCap[9,1,0,15] 0\n",
      "P_NewCap[9,1,0,16] 0\n",
      "P_NewCap[9,1,0,17] 0\n",
      "P_NewCap[9,1,0,18] 0\n",
      "P_NewCap[9,1,0,19] 0\n",
      "P_NewCap[9,1,0,20] 0\n",
      "P_NewCap[9,1,0,21] 0\n",
      "P_NewCap[9,1,0,22] 0\n",
      "P_NewCap[9,1,0,23] 0\n",
      "P_NewCap[9,1,1,0] 0\n",
      "P_NewCap[9,1,1,1] 0\n",
      "P_NewCap[9,1,1,2] 0\n",
      "P_NewCap[9,1,1,3] 0\n",
      "P_NewCap[9,1,1,4] 0\n",
      "P_NewCap[9,1,1,5] 0\n",
      "P_NewCap[9,1,1,6] 0\n",
      "P_NewCap[9,1,1,7] 0\n",
      "P_NewCap[9,1,1,8] 0\n",
      "P_NewCap[9,1,1,9] 0\n",
      "P_NewCap[9,1,1,10] 0\n",
      "P_NewCap[9,1,1,11] 0\n",
      "P_NewCap[9,1,1,12] 0\n",
      "P_NewCap[9,1,1,13] 0\n",
      "P_NewCap[9,1,1,14] 0\n",
      "P_NewCap[9,1,1,15] 0\n",
      "P_NewCap[9,1,1,16] 0\n",
      "P_NewCap[9,1,1,17] 0\n",
      "P_NewCap[9,1,1,18] 0\n",
      "P_NewCap[9,1,1,19] 0\n",
      "P_NewCap[9,1,1,20] 0\n",
      "P_NewCap[9,1,1,21] 0\n",
      "P_NewCap[9,1,1,22] 0\n",
      "P_NewCap[9,1,1,23] 0\n",
      "P_NewCap[9,1,2,0] 0\n",
      "P_NewCap[9,1,2,1] 0\n",
      "P_NewCap[9,1,2,2] 0\n",
      "P_NewCap[9,1,2,3] 0\n",
      "P_NewCap[9,1,2,4] 0\n",
      "P_NewCap[9,1,2,5] 0\n",
      "P_NewCap[9,1,2,6] 0\n",
      "P_NewCap[9,1,2,7] 0\n",
      "P_NewCap[9,1,2,8] 0\n",
      "P_NewCap[9,1,2,9] 0\n",
      "P_NewCap[9,1,2,10] 0\n",
      "P_NewCap[9,1,2,11] 0\n",
      "P_NewCap[9,1,2,12] 0\n",
      "P_NewCap[9,1,2,13] 0\n",
      "P_NewCap[9,1,2,14] 0\n",
      "P_NewCap[9,1,2,15] 0\n",
      "P_NewCap[9,1,2,16] 0\n",
      "P_NewCap[9,1,2,17] 0\n",
      "P_NewCap[9,1,2,18] 0\n",
      "P_NewCap[9,1,2,19] 0\n",
      "P_NewCap[9,1,2,20] 0\n",
      "P_NewCap[9,1,2,21] 0\n",
      "P_NewCap[9,1,2,22] 0\n",
      "P_NewCap[9,1,2,23] 0\n",
      "P_NewCap[9,1,3,0] 0\n",
      "P_NewCap[9,1,3,1] 0\n",
      "P_NewCap[9,1,3,2] 0\n",
      "P_NewCap[9,1,3,3] 0\n",
      "P_NewCap[9,1,3,4] 0\n",
      "P_NewCap[9,1,3,5] 0\n",
      "P_NewCap[9,1,3,6] 0\n",
      "P_NewCap[9,1,3,7] 0\n",
      "P_NewCap[9,1,3,8] 0\n",
      "P_NewCap[9,1,3,9] 0\n",
      "P_NewCap[9,1,3,10] 0\n",
      "P_NewCap[9,1,3,11] 0\n",
      "P_NewCap[9,1,3,12] 0\n",
      "P_NewCap[9,1,3,13] 0\n",
      "P_NewCap[9,1,3,14] 0\n",
      "P_NewCap[9,1,3,15] 0\n",
      "P_NewCap[9,1,3,16] 0\n",
      "P_NewCap[9,1,3,17] 0\n",
      "P_NewCap[9,1,3,18] 0\n",
      "P_NewCap[9,1,3,19] 0\n",
      "P_NewCap[9,1,3,20] 0\n",
      "P_NewCap[9,1,3,21] 0\n",
      "P_NewCap[9,1,3,22] 0\n",
      "P_NewCap[9,1,3,23] 0\n",
      "P_NewCap[9,1,4,0] 0\n",
      "P_NewCap[9,1,4,1] 0\n",
      "P_NewCap[9,1,4,2] 0\n",
      "P_NewCap[9,1,4,3] 0\n",
      "P_NewCap[9,1,4,4] 0\n",
      "P_NewCap[9,1,4,5] 0\n",
      "P_NewCap[9,1,4,6] 0\n",
      "P_NewCap[9,1,4,7] 0\n",
      "P_NewCap[9,1,4,8] 0\n",
      "P_NewCap[9,1,4,9] 0\n",
      "P_NewCap[9,1,4,10] 0\n",
      "P_NewCap[9,1,4,11] 0\n",
      "P_NewCap[9,1,4,12] 0\n",
      "P_NewCap[9,1,4,13] 0\n",
      "P_NewCap[9,1,4,14] 0\n",
      "P_NewCap[9,1,4,15] 0\n",
      "P_NewCap[9,1,4,16] 0\n",
      "P_NewCap[9,1,4,17] 0\n",
      "P_NewCap[9,1,4,18] 0\n",
      "P_NewCap[9,1,4,19] 0\n",
      "P_NewCap[9,1,4,20] 0\n",
      "P_NewCap[9,1,4,21] 0\n",
      "P_NewCap[9,1,4,22] 0\n",
      "P_NewCap[9,1,4,23] 0\n",
      "P_NewCap[10,0,0,0] 0\n",
      "P_NewCap[10,0,0,1] 0\n",
      "P_NewCap[10,0,0,2] 0\n",
      "P_NewCap[10,0,0,3] 0\n",
      "P_NewCap[10,0,0,4] 0\n",
      "P_NewCap[10,0,0,5] 0\n",
      "P_NewCap[10,0,0,6] 0\n",
      "P_NewCap[10,0,0,7] 0\n",
      "P_NewCap[10,0,0,8] 0\n",
      "P_NewCap[10,0,0,9] 0\n",
      "P_NewCap[10,0,0,10] 0\n",
      "P_NewCap[10,0,0,11] 0\n",
      "P_NewCap[10,0,0,12] 0\n",
      "P_NewCap[10,0,0,13] 0\n",
      "P_NewCap[10,0,0,14] 0\n",
      "P_NewCap[10,0,0,15] 0\n",
      "P_NewCap[10,0,0,16] 0\n",
      "P_NewCap[10,0,0,17] 0\n",
      "P_NewCap[10,0,0,18] 0\n",
      "P_NewCap[10,0,0,19] 0\n",
      "P_NewCap[10,0,0,20] 0\n",
      "P_NewCap[10,0,0,21] 0\n",
      "P_NewCap[10,0,0,22] 0\n",
      "P_NewCap[10,0,0,23] 0\n",
      "P_NewCap[10,0,1,0] 0\n",
      "P_NewCap[10,0,1,1] 0\n",
      "P_NewCap[10,0,1,2] 0\n",
      "P_NewCap[10,0,1,3] 0\n",
      "P_NewCap[10,0,1,4] 0\n",
      "P_NewCap[10,0,1,5] 0\n",
      "P_NewCap[10,0,1,6] 0\n",
      "P_NewCap[10,0,1,7] 0\n",
      "P_NewCap[10,0,1,8] 0\n",
      "P_NewCap[10,0,1,9] 0\n",
      "P_NewCap[10,0,1,10] 0\n",
      "P_NewCap[10,0,1,11] 0\n",
      "P_NewCap[10,0,1,12] 0\n",
      "P_NewCap[10,0,1,13] 0\n",
      "P_NewCap[10,0,1,14] 0\n",
      "P_NewCap[10,0,1,15] 0\n",
      "P_NewCap[10,0,1,16] 0\n",
      "P_NewCap[10,0,1,17] 0\n",
      "P_NewCap[10,0,1,18] 0\n",
      "P_NewCap[10,0,1,19] 0\n",
      "P_NewCap[10,0,1,20] 0\n",
      "P_NewCap[10,0,1,21] 0\n",
      "P_NewCap[10,0,1,22] 0\n",
      "P_NewCap[10,0,1,23] 0\n",
      "P_NewCap[10,0,2,0] 0\n",
      "P_NewCap[10,0,2,1] 0\n",
      "P_NewCap[10,0,2,2] 0\n",
      "P_NewCap[10,0,2,3] 0\n",
      "P_NewCap[10,0,2,4] 0\n",
      "P_NewCap[10,0,2,5] 0\n",
      "P_NewCap[10,0,2,6] 0\n",
      "P_NewCap[10,0,2,7] 0\n",
      "P_NewCap[10,0,2,8] 0\n",
      "P_NewCap[10,0,2,9] 0\n",
      "P_NewCap[10,0,2,10] 0\n",
      "P_NewCap[10,0,2,11] 0\n",
      "P_NewCap[10,0,2,12] 0\n",
      "P_NewCap[10,0,2,13] 0\n",
      "P_NewCap[10,0,2,14] 0\n",
      "P_NewCap[10,0,2,15] 0\n",
      "P_NewCap[10,0,2,16] 0\n",
      "P_NewCap[10,0,2,17] 0\n",
      "P_NewCap[10,0,2,18] 0\n",
      "P_NewCap[10,0,2,19] 0\n",
      "P_NewCap[10,0,2,20] 0\n",
      "P_NewCap[10,0,2,21] 0\n",
      "P_NewCap[10,0,2,22] 0\n",
      "P_NewCap[10,0,2,23] 0\n",
      "P_NewCap[10,0,3,0] 0\n",
      "P_NewCap[10,0,3,1] 0\n",
      "P_NewCap[10,0,3,2] 0\n",
      "P_NewCap[10,0,3,3] 0\n",
      "P_NewCap[10,0,3,4] 0\n",
      "P_NewCap[10,0,3,5] 0\n",
      "P_NewCap[10,0,3,6] 0\n",
      "P_NewCap[10,0,3,7] 0\n",
      "P_NewCap[10,0,3,8] 0\n",
      "P_NewCap[10,0,3,9] 0\n",
      "P_NewCap[10,0,3,10] 0\n",
      "P_NewCap[10,0,3,11] 0\n",
      "P_NewCap[10,0,3,12] 0\n",
      "P_NewCap[10,0,3,13] 0\n",
      "P_NewCap[10,0,3,14] 0\n",
      "P_NewCap[10,0,3,15] 0\n",
      "P_NewCap[10,0,3,16] 0\n",
      "P_NewCap[10,0,3,17] 0\n",
      "P_NewCap[10,0,3,18] 0\n",
      "P_NewCap[10,0,3,19] 0\n",
      "P_NewCap[10,0,3,20] 0\n",
      "P_NewCap[10,0,3,21] 0\n",
      "P_NewCap[10,0,3,22] 0\n",
      "P_NewCap[10,0,3,23] 0\n",
      "P_NewCap[10,0,4,0] 0\n",
      "P_NewCap[10,0,4,1] 0\n",
      "P_NewCap[10,0,4,2] 0\n",
      "P_NewCap[10,0,4,3] 0\n",
      "P_NewCap[10,0,4,4] 0\n",
      "P_NewCap[10,0,4,5] 0\n",
      "P_NewCap[10,0,4,6] 0\n",
      "P_NewCap[10,0,4,7] 0\n",
      "P_NewCap[10,0,4,8] 0\n",
      "P_NewCap[10,0,4,9] 0\n",
      "P_NewCap[10,0,4,10] 0\n",
      "P_NewCap[10,0,4,11] 0\n",
      "P_NewCap[10,0,4,12] 0\n",
      "P_NewCap[10,0,4,13] 0\n",
      "P_NewCap[10,0,4,14] 0\n",
      "P_NewCap[10,0,4,15] 0\n",
      "P_NewCap[10,0,4,16] 0\n",
      "P_NewCap[10,0,4,17] 0\n",
      "P_NewCap[10,0,4,18] 0\n",
      "P_NewCap[10,0,4,19] 0\n",
      "P_NewCap[10,0,4,20] 0\n",
      "P_NewCap[10,0,4,21] 0\n",
      "P_NewCap[10,0,4,22] 0\n",
      "P_NewCap[10,0,4,23] 0\n",
      "P_NewCap[10,1,0,0] 0\n",
      "P_NewCap[10,1,0,1] 0\n",
      "P_NewCap[10,1,0,2] 0\n",
      "P_NewCap[10,1,0,3] 0\n",
      "P_NewCap[10,1,0,4] 0\n",
      "P_NewCap[10,1,0,5] 0\n",
      "P_NewCap[10,1,0,6] 0\n",
      "P_NewCap[10,1,0,7] 0\n",
      "P_NewCap[10,1,0,8] 0\n",
      "P_NewCap[10,1,0,9] 0\n",
      "P_NewCap[10,1,0,10] 0\n",
      "P_NewCap[10,1,0,11] 0\n",
      "P_NewCap[10,1,0,12] 0\n",
      "P_NewCap[10,1,0,13] 0\n",
      "P_NewCap[10,1,0,14] 0\n",
      "P_NewCap[10,1,0,15] 0\n",
      "P_NewCap[10,1,0,16] 0\n",
      "P_NewCap[10,1,0,17] 0\n",
      "P_NewCap[10,1,0,18] 0\n",
      "P_NewCap[10,1,0,19] 0\n",
      "P_NewCap[10,1,0,20] 0\n",
      "P_NewCap[10,1,0,21] 0\n",
      "P_NewCap[10,1,0,22] 0\n",
      "P_NewCap[10,1,0,23] 0\n",
      "P_NewCap[10,1,1,0] 0\n",
      "P_NewCap[10,1,1,1] 0\n",
      "P_NewCap[10,1,1,2] 0\n",
      "P_NewCap[10,1,1,3] 0\n",
      "P_NewCap[10,1,1,4] 0\n",
      "P_NewCap[10,1,1,5] 0\n",
      "P_NewCap[10,1,1,6] 0\n",
      "P_NewCap[10,1,1,7] 0\n",
      "P_NewCap[10,1,1,8] 0\n",
      "P_NewCap[10,1,1,9] 0\n",
      "P_NewCap[10,1,1,10] 0\n",
      "P_NewCap[10,1,1,11] 0\n",
      "P_NewCap[10,1,1,12] 0\n",
      "P_NewCap[10,1,1,13] 0\n",
      "P_NewCap[10,1,1,14] 0\n",
      "P_NewCap[10,1,1,15] 0\n",
      "P_NewCap[10,1,1,16] 0\n",
      "P_NewCap[10,1,1,17] 0\n",
      "P_NewCap[10,1,1,18] 0\n",
      "P_NewCap[10,1,1,19] 0\n",
      "P_NewCap[10,1,1,20] 0\n",
      "P_NewCap[10,1,1,21] 0\n",
      "P_NewCap[10,1,1,22] 0\n",
      "P_NewCap[10,1,1,23] 0\n",
      "P_NewCap[10,1,2,0] 0\n",
      "P_NewCap[10,1,2,1] 0\n",
      "P_NewCap[10,1,2,2] 0\n",
      "P_NewCap[10,1,2,3] 0\n",
      "P_NewCap[10,1,2,4] 0\n",
      "P_NewCap[10,1,2,5] 0\n",
      "P_NewCap[10,1,2,6] 0\n",
      "P_NewCap[10,1,2,7] 0\n",
      "P_NewCap[10,1,2,8] 0\n",
      "P_NewCap[10,1,2,9] 0\n",
      "P_NewCap[10,1,2,10] 0\n",
      "P_NewCap[10,1,2,11] 0\n",
      "P_NewCap[10,1,2,12] 0\n",
      "P_NewCap[10,1,2,13] 0\n",
      "P_NewCap[10,1,2,14] 0\n",
      "P_NewCap[10,1,2,15] 0\n",
      "P_NewCap[10,1,2,16] 0\n",
      "P_NewCap[10,1,2,17] 0\n",
      "P_NewCap[10,1,2,18] 0\n",
      "P_NewCap[10,1,2,19] 0\n",
      "P_NewCap[10,1,2,20] 0\n",
      "P_NewCap[10,1,2,21] 0\n",
      "P_NewCap[10,1,2,22] 0\n",
      "P_NewCap[10,1,2,23] 0\n",
      "P_NewCap[10,1,3,0] 0\n",
      "P_NewCap[10,1,3,1] 0\n",
      "P_NewCap[10,1,3,2] 0\n",
      "P_NewCap[10,1,3,3] 0\n",
      "P_NewCap[10,1,3,4] 0\n",
      "P_NewCap[10,1,3,5] 0\n",
      "P_NewCap[10,1,3,6] 0\n",
      "P_NewCap[10,1,3,7] 0\n",
      "P_NewCap[10,1,3,8] 0\n",
      "P_NewCap[10,1,3,9] 0\n",
      "P_NewCap[10,1,3,10] 0\n",
      "P_NewCap[10,1,3,11] 0\n",
      "P_NewCap[10,1,3,12] 0\n",
      "P_NewCap[10,1,3,13] 0\n",
      "P_NewCap[10,1,3,14] 0\n",
      "P_NewCap[10,1,3,15] 0\n",
      "P_NewCap[10,1,3,16] 0\n",
      "P_NewCap[10,1,3,17] 0\n",
      "P_NewCap[10,1,3,18] 0\n",
      "P_NewCap[10,1,3,19] 0\n",
      "P_NewCap[10,1,3,20] 0\n",
      "P_NewCap[10,1,3,21] 0\n",
      "P_NewCap[10,1,3,22] 0\n",
      "P_NewCap[10,1,3,23] 0\n",
      "P_NewCap[10,1,4,0] 0\n",
      "P_NewCap[10,1,4,1] 0\n",
      "P_NewCap[10,1,4,2] 0\n",
      "P_NewCap[10,1,4,3] 0\n",
      "P_NewCap[10,1,4,4] 0\n",
      "P_NewCap[10,1,4,5] 0\n",
      "P_NewCap[10,1,4,6] 0\n",
      "P_NewCap[10,1,4,7] 0\n",
      "P_NewCap[10,1,4,8] 0\n",
      "P_NewCap[10,1,4,9] 0\n",
      "P_NewCap[10,1,4,10] 0\n",
      "P_NewCap[10,1,4,11] 0\n",
      "P_NewCap[10,1,4,12] 0\n",
      "P_NewCap[10,1,4,13] 0\n",
      "P_NewCap[10,1,4,14] 0\n",
      "P_NewCap[10,1,4,15] 0\n",
      "P_NewCap[10,1,4,16] 0\n",
      "P_NewCap[10,1,4,17] 0\n",
      "P_NewCap[10,1,4,18] 0\n",
      "P_NewCap[10,1,4,19] 0\n",
      "P_NewCap[10,1,4,20] 0\n",
      "P_NewCap[10,1,4,21] 0\n",
      "P_NewCap[10,1,4,22] 0\n",
      "P_NewCap[10,1,4,23] 0\n",
      "P_NewCap[11,0,0,0] 0\n",
      "P_NewCap[11,0,0,1] 0\n",
      "P_NewCap[11,0,0,2] 0\n",
      "P_NewCap[11,0,0,3] 0\n",
      "P_NewCap[11,0,0,4] 0\n",
      "P_NewCap[11,0,0,5] 0\n",
      "P_NewCap[11,0,0,6] 0\n",
      "P_NewCap[11,0,0,7] 0\n",
      "P_NewCap[11,0,0,8] 0\n",
      "P_NewCap[11,0,0,9] 0\n",
      "P_NewCap[11,0,0,10] 0\n",
      "P_NewCap[11,0,0,11] 0\n",
      "P_NewCap[11,0,0,12] 0\n",
      "P_NewCap[11,0,0,13] 0\n",
      "P_NewCap[11,0,0,14] 0\n",
      "P_NewCap[11,0,0,15] 0\n",
      "P_NewCap[11,0,0,16] 0\n",
      "P_NewCap[11,0,0,17] 0\n",
      "P_NewCap[11,0,0,18] 0\n",
      "P_NewCap[11,0,0,19] 0\n",
      "P_NewCap[11,0,0,20] 0\n",
      "P_NewCap[11,0,0,21] 0\n",
      "P_NewCap[11,0,0,22] 0\n",
      "P_NewCap[11,0,0,23] 0\n",
      "P_NewCap[11,0,1,0] 0\n",
      "P_NewCap[11,0,1,1] 0\n",
      "P_NewCap[11,0,1,2] 0\n",
      "P_NewCap[11,0,1,3] 0\n",
      "P_NewCap[11,0,1,4] 0\n",
      "P_NewCap[11,0,1,5] 0\n",
      "P_NewCap[11,0,1,6] 0\n",
      "P_NewCap[11,0,1,7] 0\n",
      "P_NewCap[11,0,1,8] 0\n",
      "P_NewCap[11,0,1,9] 0\n",
      "P_NewCap[11,0,1,10] 0\n",
      "P_NewCap[11,0,1,11] 0\n",
      "P_NewCap[11,0,1,12] 0\n",
      "P_NewCap[11,0,1,13] 0\n",
      "P_NewCap[11,0,1,14] 0\n",
      "P_NewCap[11,0,1,15] 0\n",
      "P_NewCap[11,0,1,16] 0\n",
      "P_NewCap[11,0,1,17] 0\n",
      "P_NewCap[11,0,1,18] 0\n",
      "P_NewCap[11,0,1,19] 0\n",
      "P_NewCap[11,0,1,20] 0\n",
      "P_NewCap[11,0,1,21] 0\n",
      "P_NewCap[11,0,1,22] 0\n",
      "P_NewCap[11,0,1,23] 0\n",
      "P_NewCap[11,0,2,0] 0\n",
      "P_NewCap[11,0,2,1] 0\n",
      "P_NewCap[11,0,2,2] 0\n",
      "P_NewCap[11,0,2,3] 0\n",
      "P_NewCap[11,0,2,4] 0\n",
      "P_NewCap[11,0,2,5] 0\n",
      "P_NewCap[11,0,2,6] 0\n",
      "P_NewCap[11,0,2,7] 0\n",
      "P_NewCap[11,0,2,8] 0\n",
      "P_NewCap[11,0,2,9] 0\n",
      "P_NewCap[11,0,2,10] 0\n",
      "P_NewCap[11,0,2,11] 0\n",
      "P_NewCap[11,0,2,12] 0\n",
      "P_NewCap[11,0,2,13] 0\n",
      "P_NewCap[11,0,2,14] 0\n",
      "P_NewCap[11,0,2,15] 0\n",
      "P_NewCap[11,0,2,16] 0\n",
      "P_NewCap[11,0,2,17] 0\n",
      "P_NewCap[11,0,2,18] 0\n",
      "P_NewCap[11,0,2,19] 0\n",
      "P_NewCap[11,0,2,20] 0\n",
      "P_NewCap[11,0,2,21] 0\n",
      "P_NewCap[11,0,2,22] 0\n",
      "P_NewCap[11,0,2,23] 0\n",
      "P_NewCap[11,0,3,0] 0\n",
      "P_NewCap[11,0,3,1] 0\n",
      "P_NewCap[11,0,3,2] 0\n",
      "P_NewCap[11,0,3,3] 0\n",
      "P_NewCap[11,0,3,4] 0\n",
      "P_NewCap[11,0,3,5] 0\n",
      "P_NewCap[11,0,3,6] 0\n",
      "P_NewCap[11,0,3,7] 0\n",
      "P_NewCap[11,0,3,8] 0\n",
      "P_NewCap[11,0,3,9] 0\n",
      "P_NewCap[11,0,3,10] 0\n",
      "P_NewCap[11,0,3,11] 0\n",
      "P_NewCap[11,0,3,12] 0\n",
      "P_NewCap[11,0,3,13] 0\n",
      "P_NewCap[11,0,3,14] 0\n",
      "P_NewCap[11,0,3,15] 0\n",
      "P_NewCap[11,0,3,16] 0\n",
      "P_NewCap[11,0,3,17] 0\n",
      "P_NewCap[11,0,3,18] 0\n",
      "P_NewCap[11,0,3,19] 0\n",
      "P_NewCap[11,0,3,20] 0\n",
      "P_NewCap[11,0,3,21] 0\n",
      "P_NewCap[11,0,3,22] 0\n",
      "P_NewCap[11,0,3,23] 0\n",
      "P_NewCap[11,0,4,0] 0\n",
      "P_NewCap[11,0,4,1] 0\n",
      "P_NewCap[11,0,4,2] 0\n",
      "P_NewCap[11,0,4,3] 0\n",
      "P_NewCap[11,0,4,4] 0\n",
      "P_NewCap[11,0,4,5] 0\n",
      "P_NewCap[11,0,4,6] 0\n",
      "P_NewCap[11,0,4,7] 0\n",
      "P_NewCap[11,0,4,8] 0\n",
      "P_NewCap[11,0,4,9] 0\n",
      "P_NewCap[11,0,4,10] 0\n",
      "P_NewCap[11,0,4,11] 0\n",
      "P_NewCap[11,0,4,12] 0\n",
      "P_NewCap[11,0,4,13] 0\n",
      "P_NewCap[11,0,4,14] 0\n",
      "P_NewCap[11,0,4,15] 0\n",
      "P_NewCap[11,0,4,16] 0\n",
      "P_NewCap[11,0,4,17] 0\n",
      "P_NewCap[11,0,4,18] 0\n",
      "P_NewCap[11,0,4,19] 0\n",
      "P_NewCap[11,0,4,20] 0\n",
      "P_NewCap[11,0,4,21] 0\n",
      "P_NewCap[11,0,4,22] 0\n",
      "P_NewCap[11,0,4,23] 0\n",
      "P_NewCap[11,1,0,0] 0\n",
      "P_NewCap[11,1,0,1] 0\n",
      "P_NewCap[11,1,0,2] 0\n",
      "P_NewCap[11,1,0,3] 0\n",
      "P_NewCap[11,1,0,4] 0\n",
      "P_NewCap[11,1,0,5] 0\n",
      "P_NewCap[11,1,0,6] 0\n",
      "P_NewCap[11,1,0,7] 0\n",
      "P_NewCap[11,1,0,8] 0\n",
      "P_NewCap[11,1,0,9] 0\n",
      "P_NewCap[11,1,0,10] 0\n",
      "P_NewCap[11,1,0,11] 0\n",
      "P_NewCap[11,1,0,12] 0\n",
      "P_NewCap[11,1,0,13] 0\n",
      "P_NewCap[11,1,0,14] 0\n",
      "P_NewCap[11,1,0,15] 0\n",
      "P_NewCap[11,1,0,16] 0\n",
      "P_NewCap[11,1,0,17] 0\n",
      "P_NewCap[11,1,0,18] 0\n",
      "P_NewCap[11,1,0,19] 0\n",
      "P_NewCap[11,1,0,20] 0\n",
      "P_NewCap[11,1,0,21] 0\n",
      "P_NewCap[11,1,0,22] 0\n",
      "P_NewCap[11,1,0,23] 0\n",
      "P_NewCap[11,1,1,0] 0\n",
      "P_NewCap[11,1,1,1] 0\n",
      "P_NewCap[11,1,1,2] 0\n",
      "P_NewCap[11,1,1,3] 0\n",
      "P_NewCap[11,1,1,4] 0\n",
      "P_NewCap[11,1,1,5] 0\n",
      "P_NewCap[11,1,1,6] 0\n",
      "P_NewCap[11,1,1,7] 0\n",
      "P_NewCap[11,1,1,8] 0\n",
      "P_NewCap[11,1,1,9] 0\n",
      "P_NewCap[11,1,1,10] 0\n",
      "P_NewCap[11,1,1,11] 0\n",
      "P_NewCap[11,1,1,12] 0\n",
      "P_NewCap[11,1,1,13] 0\n",
      "P_NewCap[11,1,1,14] 0\n",
      "P_NewCap[11,1,1,15] 0\n",
      "P_NewCap[11,1,1,16] 0\n",
      "P_NewCap[11,1,1,17] 0\n",
      "P_NewCap[11,1,1,18] 0\n",
      "P_NewCap[11,1,1,19] 0\n",
      "P_NewCap[11,1,1,20] 0\n",
      "P_NewCap[11,1,1,21] 0\n",
      "P_NewCap[11,1,1,22] 0\n",
      "P_NewCap[11,1,1,23] 0\n",
      "P_NewCap[11,1,2,0] 0\n",
      "P_NewCap[11,1,2,1] 0\n",
      "P_NewCap[11,1,2,2] 0\n",
      "P_NewCap[11,1,2,3] 0\n",
      "P_NewCap[11,1,2,4] 0\n",
      "P_NewCap[11,1,2,5] 0\n",
      "P_NewCap[11,1,2,6] 0\n",
      "P_NewCap[11,1,2,7] 0\n",
      "P_NewCap[11,1,2,8] 0\n",
      "P_NewCap[11,1,2,9] 0\n",
      "P_NewCap[11,1,2,10] 0\n",
      "P_NewCap[11,1,2,11] 0\n",
      "P_NewCap[11,1,2,12] 0\n",
      "P_NewCap[11,1,2,13] 0\n",
      "P_NewCap[11,1,2,14] 0\n",
      "P_NewCap[11,1,2,15] 0\n",
      "P_NewCap[11,1,2,16] 0\n",
      "P_NewCap[11,1,2,17] 0\n",
      "P_NewCap[11,1,2,18] 0\n",
      "P_NewCap[11,1,2,19] 0\n",
      "P_NewCap[11,1,2,20] 0\n",
      "P_NewCap[11,1,2,21] 0\n",
      "P_NewCap[11,1,2,22] 0\n",
      "P_NewCap[11,1,2,23] 0\n",
      "P_NewCap[11,1,3,0] 0\n",
      "P_NewCap[11,1,3,1] 0\n",
      "P_NewCap[11,1,3,2] 0\n",
      "P_NewCap[11,1,3,3] 0\n",
      "P_NewCap[11,1,3,4] 0\n",
      "P_NewCap[11,1,3,5] 0\n",
      "P_NewCap[11,1,3,6] 0\n",
      "P_NewCap[11,1,3,7] 0\n",
      "P_NewCap[11,1,3,8] 0\n",
      "P_NewCap[11,1,3,9] 0\n",
      "P_NewCap[11,1,3,10] 0\n",
      "P_NewCap[11,1,3,11] 0\n",
      "P_NewCap[11,1,3,12] 0\n",
      "P_NewCap[11,1,3,13] 0\n",
      "P_NewCap[11,1,3,14] 0\n",
      "P_NewCap[11,1,3,15] 0\n",
      "P_NewCap[11,1,3,16] 0\n",
      "P_NewCap[11,1,3,17] 0\n",
      "P_NewCap[11,1,3,18] 0\n",
      "P_NewCap[11,1,3,19] 0\n",
      "P_NewCap[11,1,3,20] 0\n",
      "P_NewCap[11,1,3,21] 0\n",
      "P_NewCap[11,1,3,22] 0\n",
      "P_NewCap[11,1,3,23] 0\n",
      "P_NewCap[11,1,4,0] 0\n",
      "P_NewCap[11,1,4,1] 0\n",
      "P_NewCap[11,1,4,2] 0\n",
      "P_NewCap[11,1,4,3] 0\n",
      "P_NewCap[11,1,4,4] 0\n",
      "P_NewCap[11,1,4,5] 0\n",
      "P_NewCap[11,1,4,6] 0\n",
      "P_NewCap[11,1,4,7] 0\n",
      "P_NewCap[11,1,4,8] 0\n",
      "P_NewCap[11,1,4,9] 0\n",
      "P_NewCap[11,1,4,10] 0\n",
      "P_NewCap[11,1,4,11] 0\n",
      "P_NewCap[11,1,4,12] 0\n",
      "P_NewCap[11,1,4,13] 0\n",
      "P_NewCap[11,1,4,14] 0\n",
      "P_NewCap[11,1,4,15] 0\n",
      "P_NewCap[11,1,4,16] 0\n",
      "P_NewCap[11,1,4,17] 0\n",
      "P_NewCap[11,1,4,18] 0\n",
      "P_NewCap[11,1,4,19] 0\n",
      "P_NewCap[11,1,4,20] 0\n",
      "P_NewCap[11,1,4,21] 0\n",
      "P_NewCap[11,1,4,22] 0\n",
      "P_NewCap[11,1,4,23] 0\n",
      "P_NewCap[12,0,0,0] 0\n",
      "P_NewCap[12,0,0,1] 0\n",
      "P_NewCap[12,0,0,2] 0\n",
      "P_NewCap[12,0,0,3] 0\n",
      "P_NewCap[12,0,0,4] 0\n",
      "P_NewCap[12,0,0,5] 0\n",
      "P_NewCap[12,0,0,6] 0\n",
      "P_NewCap[12,0,0,7] 0\n",
      "P_NewCap[12,0,0,8] 0\n",
      "P_NewCap[12,0,0,9] 0\n",
      "P_NewCap[12,0,0,10] 0\n",
      "P_NewCap[12,0,0,11] 0\n",
      "P_NewCap[12,0,0,12] 0\n",
      "P_NewCap[12,0,0,13] 0\n",
      "P_NewCap[12,0,0,14] 0\n",
      "P_NewCap[12,0,0,15] 0\n",
      "P_NewCap[12,0,0,16] 0\n",
      "P_NewCap[12,0,0,17] 0\n",
      "P_NewCap[12,0,0,18] 0\n",
      "P_NewCap[12,0,0,19] 0\n",
      "P_NewCap[12,0,0,20] 0\n",
      "P_NewCap[12,0,0,21] 0\n",
      "P_NewCap[12,0,0,22] 0\n",
      "P_NewCap[12,0,0,23] 0\n",
      "P_NewCap[12,0,1,0] 0\n",
      "P_NewCap[12,0,1,1] 0\n",
      "P_NewCap[12,0,1,2] 0\n",
      "P_NewCap[12,0,1,3] 0\n",
      "P_NewCap[12,0,1,4] 0\n",
      "P_NewCap[12,0,1,5] 0\n",
      "P_NewCap[12,0,1,6] 0\n",
      "P_NewCap[12,0,1,7] 0\n",
      "P_NewCap[12,0,1,8] 0\n",
      "P_NewCap[12,0,1,9] 0\n",
      "P_NewCap[12,0,1,10] 0\n",
      "P_NewCap[12,0,1,11] 0\n",
      "P_NewCap[12,0,1,12] 0\n",
      "P_NewCap[12,0,1,13] 0\n",
      "P_NewCap[12,0,1,14] 0\n",
      "P_NewCap[12,0,1,15] 0\n",
      "P_NewCap[12,0,1,16] 0\n",
      "P_NewCap[12,0,1,17] 0\n",
      "P_NewCap[12,0,1,18] 0\n",
      "P_NewCap[12,0,1,19] 0\n",
      "P_NewCap[12,0,1,20] 0\n",
      "P_NewCap[12,0,1,21] 0\n",
      "P_NewCap[12,0,1,22] 0\n",
      "P_NewCap[12,0,1,23] 0\n",
      "P_NewCap[12,0,2,0] 0\n",
      "P_NewCap[12,0,2,1] 0\n",
      "P_NewCap[12,0,2,2] 0\n",
      "P_NewCap[12,0,2,3] 0\n",
      "P_NewCap[12,0,2,4] 0\n",
      "P_NewCap[12,0,2,5] 0\n",
      "P_NewCap[12,0,2,6] 0\n",
      "P_NewCap[12,0,2,7] 0\n",
      "P_NewCap[12,0,2,8] 0\n",
      "P_NewCap[12,0,2,9] 0\n",
      "P_NewCap[12,0,2,10] 0\n",
      "P_NewCap[12,0,2,11] 0\n",
      "P_NewCap[12,0,2,12] 0\n",
      "P_NewCap[12,0,2,13] 0\n",
      "P_NewCap[12,0,2,14] 0\n",
      "P_NewCap[12,0,2,15] 0\n",
      "P_NewCap[12,0,2,16] 0\n",
      "P_NewCap[12,0,2,17] 0\n",
      "P_NewCap[12,0,2,18] 0\n",
      "P_NewCap[12,0,2,19] 0\n",
      "P_NewCap[12,0,2,20] 0\n",
      "P_NewCap[12,0,2,21] 0\n",
      "P_NewCap[12,0,2,22] 0\n",
      "P_NewCap[12,0,2,23] 0\n",
      "P_NewCap[12,0,3,0] 0\n",
      "P_NewCap[12,0,3,1] 0\n",
      "P_NewCap[12,0,3,2] 0\n",
      "P_NewCap[12,0,3,3] 0\n",
      "P_NewCap[12,0,3,4] 0\n",
      "P_NewCap[12,0,3,5] 0\n",
      "P_NewCap[12,0,3,6] 0\n",
      "P_NewCap[12,0,3,7] 0\n",
      "P_NewCap[12,0,3,8] 0\n",
      "P_NewCap[12,0,3,9] 0\n",
      "P_NewCap[12,0,3,10] 0\n",
      "P_NewCap[12,0,3,11] 0\n",
      "P_NewCap[12,0,3,12] 0\n",
      "P_NewCap[12,0,3,13] 0\n",
      "P_NewCap[12,0,3,14] 0\n",
      "P_NewCap[12,0,3,15] 0\n",
      "P_NewCap[12,0,3,16] 0\n",
      "P_NewCap[12,0,3,17] 0\n",
      "P_NewCap[12,0,3,18] 0\n",
      "P_NewCap[12,0,3,19] 0\n",
      "P_NewCap[12,0,3,20] 0\n",
      "P_NewCap[12,0,3,21] 0\n",
      "P_NewCap[12,0,3,22] 0\n",
      "P_NewCap[12,0,3,23] 0\n",
      "P_NewCap[12,0,4,0] 0\n",
      "P_NewCap[12,0,4,1] 0\n",
      "P_NewCap[12,0,4,2] 0\n",
      "P_NewCap[12,0,4,3] 0\n",
      "P_NewCap[12,0,4,4] 0\n",
      "P_NewCap[12,0,4,5] 0\n",
      "P_NewCap[12,0,4,6] 0\n",
      "P_NewCap[12,0,4,7] 0\n",
      "P_NewCap[12,0,4,8] 0\n",
      "P_NewCap[12,0,4,9] 0\n",
      "P_NewCap[12,0,4,10] 0\n",
      "P_NewCap[12,0,4,11] 0\n",
      "P_NewCap[12,0,4,12] 0\n",
      "P_NewCap[12,0,4,13] 0\n",
      "P_NewCap[12,0,4,14] 0\n",
      "P_NewCap[12,0,4,15] 0\n",
      "P_NewCap[12,0,4,16] 0\n",
      "P_NewCap[12,0,4,17] 0\n",
      "P_NewCap[12,0,4,18] 0\n",
      "P_NewCap[12,0,4,19] 0\n",
      "P_NewCap[12,0,4,20] 0\n",
      "P_NewCap[12,0,4,21] 0\n",
      "P_NewCap[12,0,4,22] 0\n",
      "P_NewCap[12,0,4,23] 0\n",
      "P_NewCap[12,1,0,0] 0\n",
      "P_NewCap[12,1,0,1] 0\n",
      "P_NewCap[12,1,0,2] 0\n",
      "P_NewCap[12,1,0,3] 0\n",
      "P_NewCap[12,1,0,4] 0\n",
      "P_NewCap[12,1,0,5] 0\n",
      "P_NewCap[12,1,0,6] 0\n",
      "P_NewCap[12,1,0,7] 0\n",
      "P_NewCap[12,1,0,8] 0\n",
      "P_NewCap[12,1,0,9] 0\n",
      "P_NewCap[12,1,0,10] 0\n",
      "P_NewCap[12,1,0,11] 0\n",
      "P_NewCap[12,1,0,12] 0\n",
      "P_NewCap[12,1,0,13] 0\n",
      "P_NewCap[12,1,0,14] 0\n",
      "P_NewCap[12,1,0,15] 0\n",
      "P_NewCap[12,1,0,16] 0\n",
      "P_NewCap[12,1,0,17] 0\n",
      "P_NewCap[12,1,0,18] 0\n",
      "P_NewCap[12,1,0,19] 0\n",
      "P_NewCap[12,1,0,20] 0\n",
      "P_NewCap[12,1,0,21] 0\n",
      "P_NewCap[12,1,0,22] 0\n",
      "P_NewCap[12,1,0,23] 0\n",
      "P_NewCap[12,1,1,0] 0\n",
      "P_NewCap[12,1,1,1] 0\n",
      "P_NewCap[12,1,1,2] 0\n",
      "P_NewCap[12,1,1,3] 0\n",
      "P_NewCap[12,1,1,4] 0\n",
      "P_NewCap[12,1,1,5] 0\n",
      "P_NewCap[12,1,1,6] 0\n",
      "P_NewCap[12,1,1,7] 0\n",
      "P_NewCap[12,1,1,8] 0\n",
      "P_NewCap[12,1,1,9] 0\n",
      "P_NewCap[12,1,1,10] 0\n",
      "P_NewCap[12,1,1,11] 0\n",
      "P_NewCap[12,1,1,12] 0\n",
      "P_NewCap[12,1,1,13] 0\n",
      "P_NewCap[12,1,1,14] 0\n",
      "P_NewCap[12,1,1,15] 0\n",
      "P_NewCap[12,1,1,16] 0\n",
      "P_NewCap[12,1,1,17] 0\n",
      "P_NewCap[12,1,1,18] 0\n",
      "P_NewCap[12,1,1,19] 0\n",
      "P_NewCap[12,1,1,20] 0\n",
      "P_NewCap[12,1,1,21] 0\n",
      "P_NewCap[12,1,1,22] 0\n",
      "P_NewCap[12,1,1,23] 0\n",
      "P_NewCap[12,1,2,0] 0\n",
      "P_NewCap[12,1,2,1] 0\n",
      "P_NewCap[12,1,2,2] 0\n",
      "P_NewCap[12,1,2,3] 0\n",
      "P_NewCap[12,1,2,4] 0\n",
      "P_NewCap[12,1,2,5] 0\n",
      "P_NewCap[12,1,2,6] 0\n",
      "P_NewCap[12,1,2,7] 0\n",
      "P_NewCap[12,1,2,8] 0\n",
      "P_NewCap[12,1,2,9] 0\n",
      "P_NewCap[12,1,2,10] 0\n",
      "P_NewCap[12,1,2,11] 0\n",
      "P_NewCap[12,1,2,12] 0\n",
      "P_NewCap[12,1,2,13] 0\n",
      "P_NewCap[12,1,2,14] 0\n",
      "P_NewCap[12,1,2,15] 0\n",
      "P_NewCap[12,1,2,16] 0\n",
      "P_NewCap[12,1,2,17] 0\n",
      "P_NewCap[12,1,2,18] 0\n",
      "P_NewCap[12,1,2,19] 0\n",
      "P_NewCap[12,1,2,20] 0\n",
      "P_NewCap[12,1,2,21] 0\n",
      "P_NewCap[12,1,2,22] 0\n",
      "P_NewCap[12,1,2,23] 0\n",
      "P_NewCap[12,1,3,0] 0\n",
      "P_NewCap[12,1,3,1] 0\n",
      "P_NewCap[12,1,3,2] 0\n",
      "P_NewCap[12,1,3,3] 0\n",
      "P_NewCap[12,1,3,4] 0\n",
      "P_NewCap[12,1,3,5] 0\n",
      "P_NewCap[12,1,3,6] 0\n",
      "P_NewCap[12,1,3,7] 0\n",
      "P_NewCap[12,1,3,8] 0\n",
      "P_NewCap[12,1,3,9] 0\n",
      "P_NewCap[12,1,3,10] 0\n",
      "P_NewCap[12,1,3,11] 0\n",
      "P_NewCap[12,1,3,12] 0\n",
      "P_NewCap[12,1,3,13] 0\n",
      "P_NewCap[12,1,3,14] 0\n",
      "P_NewCap[12,1,3,15] 0\n",
      "P_NewCap[12,1,3,16] 0\n",
      "P_NewCap[12,1,3,17] 0\n",
      "P_NewCap[12,1,3,18] 0\n",
      "P_NewCap[12,1,3,19] 0\n",
      "P_NewCap[12,1,3,20] 0\n",
      "P_NewCap[12,1,3,21] 0\n",
      "P_NewCap[12,1,3,22] 0\n",
      "P_NewCap[12,1,3,23] 0\n",
      "P_NewCap[12,1,4,0] 0\n",
      "P_NewCap[12,1,4,1] 0\n",
      "P_NewCap[12,1,4,2] 0\n",
      "P_NewCap[12,1,4,3] 0\n",
      "P_NewCap[12,1,4,4] 0\n",
      "P_NewCap[12,1,4,5] 0\n",
      "P_NewCap[12,1,4,6] 0\n",
      "P_NewCap[12,1,4,7] 0\n",
      "P_NewCap[12,1,4,8] 0\n",
      "P_NewCap[12,1,4,9] 0\n",
      "P_NewCap[12,1,4,10] 0\n",
      "P_NewCap[12,1,4,11] 0\n",
      "P_NewCap[12,1,4,12] 0\n",
      "P_NewCap[12,1,4,13] 0\n",
      "P_NewCap[12,1,4,14] 0\n",
      "P_NewCap[12,1,4,15] 0\n",
      "P_NewCap[12,1,4,16] 0\n",
      "P_NewCap[12,1,4,17] 0\n",
      "P_NewCap[12,1,4,18] 0\n",
      "P_NewCap[12,1,4,19] 0\n",
      "P_NewCap[12,1,4,20] 0\n",
      "P_NewCap[12,1,4,21] 0\n",
      "P_NewCap[12,1,4,22] 0\n",
      "P_NewCap[12,1,4,23] 0\n",
      "P_NewCap[13,0,0,0] 0\n",
      "P_NewCap[13,0,0,1] 0\n",
      "P_NewCap[13,0,0,2] 0\n",
      "P_NewCap[13,0,0,3] 0\n",
      "P_NewCap[13,0,0,4] 0\n",
      "P_NewCap[13,0,0,5] 0\n",
      "P_NewCap[13,0,0,6] 0\n",
      "P_NewCap[13,0,0,7] 0\n",
      "P_NewCap[13,0,0,8] 0\n",
      "P_NewCap[13,0,0,9] 0\n",
      "P_NewCap[13,0,0,10] 0\n",
      "P_NewCap[13,0,0,11] 0\n",
      "P_NewCap[13,0,0,12] 0\n",
      "P_NewCap[13,0,0,13] 0\n",
      "P_NewCap[13,0,0,14] 0\n",
      "P_NewCap[13,0,0,15] 0\n",
      "P_NewCap[13,0,0,16] 0\n",
      "P_NewCap[13,0,0,17] 0\n",
      "P_NewCap[13,0,0,18] 0\n",
      "P_NewCap[13,0,0,19] 0\n",
      "P_NewCap[13,0,0,20] 0\n",
      "P_NewCap[13,0,0,21] 0\n",
      "P_NewCap[13,0,0,22] 0\n",
      "P_NewCap[13,0,0,23] 0\n",
      "P_NewCap[13,0,1,0] 0\n",
      "P_NewCap[13,0,1,1] 0\n",
      "P_NewCap[13,0,1,2] 0\n",
      "P_NewCap[13,0,1,3] 0\n",
      "P_NewCap[13,0,1,4] 0\n",
      "P_NewCap[13,0,1,5] 0\n",
      "P_NewCap[13,0,1,6] 0\n",
      "P_NewCap[13,0,1,7] 0\n",
      "P_NewCap[13,0,1,8] 0\n",
      "P_NewCap[13,0,1,9] 0\n",
      "P_NewCap[13,0,1,10] 0\n",
      "P_NewCap[13,0,1,11] 0\n",
      "P_NewCap[13,0,1,12] 0\n",
      "P_NewCap[13,0,1,13] 0\n",
      "P_NewCap[13,0,1,14] 0\n",
      "P_NewCap[13,0,1,15] 0\n",
      "P_NewCap[13,0,1,16] 0\n",
      "P_NewCap[13,0,1,17] 0\n",
      "P_NewCap[13,0,1,18] 0\n",
      "P_NewCap[13,0,1,19] 0\n",
      "P_NewCap[13,0,1,20] 0\n",
      "P_NewCap[13,0,1,21] 0\n",
      "P_NewCap[13,0,1,22] 0\n",
      "P_NewCap[13,0,1,23] 0\n",
      "P_NewCap[13,0,2,0] 0\n",
      "P_NewCap[13,0,2,1] 0\n",
      "P_NewCap[13,0,2,2] 0\n",
      "P_NewCap[13,0,2,3] 0\n",
      "P_NewCap[13,0,2,4] 0\n",
      "P_NewCap[13,0,2,5] 0\n",
      "P_NewCap[13,0,2,6] 0\n",
      "P_NewCap[13,0,2,7] 0\n",
      "P_NewCap[13,0,2,8] 0\n",
      "P_NewCap[13,0,2,9] 0\n",
      "P_NewCap[13,0,2,10] 0\n",
      "P_NewCap[13,0,2,11] 0\n",
      "P_NewCap[13,0,2,12] 0\n",
      "P_NewCap[13,0,2,13] 0\n",
      "P_NewCap[13,0,2,14] 0\n",
      "P_NewCap[13,0,2,15] 0\n",
      "P_NewCap[13,0,2,16] 0\n",
      "P_NewCap[13,0,2,17] 0\n",
      "P_NewCap[13,0,2,18] 0\n",
      "P_NewCap[13,0,2,19] 0\n",
      "P_NewCap[13,0,2,20] 0\n",
      "P_NewCap[13,0,2,21] 0\n",
      "P_NewCap[13,0,2,22] 0\n",
      "P_NewCap[13,0,2,23] 0\n",
      "P_NewCap[13,0,3,0] 0\n",
      "P_NewCap[13,0,3,1] 0\n",
      "P_NewCap[13,0,3,2] 0\n",
      "P_NewCap[13,0,3,3] 0\n",
      "P_NewCap[13,0,3,4] 0\n",
      "P_NewCap[13,0,3,5] 0\n",
      "P_NewCap[13,0,3,6] 0\n",
      "P_NewCap[13,0,3,7] 0\n",
      "P_NewCap[13,0,3,8] 0\n",
      "P_NewCap[13,0,3,9] 0\n",
      "P_NewCap[13,0,3,10] 0\n",
      "P_NewCap[13,0,3,11] 0\n",
      "P_NewCap[13,0,3,12] 0\n",
      "P_NewCap[13,0,3,13] 0\n",
      "P_NewCap[13,0,3,14] 0\n",
      "P_NewCap[13,0,3,15] 0\n",
      "P_NewCap[13,0,3,16] 0\n",
      "P_NewCap[13,0,3,17] 0\n",
      "P_NewCap[13,0,3,18] 0\n",
      "P_NewCap[13,0,3,19] 0\n",
      "P_NewCap[13,0,3,20] 0\n",
      "P_NewCap[13,0,3,21] 0\n",
      "P_NewCap[13,0,3,22] 0\n",
      "P_NewCap[13,0,3,23] 0\n",
      "P_NewCap[13,0,4,0] 0\n",
      "P_NewCap[13,0,4,1] 0\n",
      "P_NewCap[13,0,4,2] 0\n",
      "P_NewCap[13,0,4,3] 0\n",
      "P_NewCap[13,0,4,4] 0\n",
      "P_NewCap[13,0,4,5] 0\n",
      "P_NewCap[13,0,4,6] 0\n",
      "P_NewCap[13,0,4,7] 0\n",
      "P_NewCap[13,0,4,8] 0\n",
      "P_NewCap[13,0,4,9] 0\n",
      "P_NewCap[13,0,4,10] 0\n",
      "P_NewCap[13,0,4,11] 0\n",
      "P_NewCap[13,0,4,12] 0\n",
      "P_NewCap[13,0,4,13] 0\n",
      "P_NewCap[13,0,4,14] 0\n",
      "P_NewCap[13,0,4,15] 0\n",
      "P_NewCap[13,0,4,16] 0\n",
      "P_NewCap[13,0,4,17] 0\n",
      "P_NewCap[13,0,4,18] 0\n",
      "P_NewCap[13,0,4,19] 0\n",
      "P_NewCap[13,0,4,20] 0\n",
      "P_NewCap[13,0,4,21] 0\n",
      "P_NewCap[13,0,4,22] 0\n",
      "P_NewCap[13,0,4,23] 0\n",
      "P_NewCap[13,1,0,0] 0\n",
      "P_NewCap[13,1,0,1] 0\n",
      "P_NewCap[13,1,0,2] 0\n",
      "P_NewCap[13,1,0,3] 0\n",
      "P_NewCap[13,1,0,4] 0\n",
      "P_NewCap[13,1,0,5] 0\n",
      "P_NewCap[13,1,0,6] 0\n",
      "P_NewCap[13,1,0,7] 0\n",
      "P_NewCap[13,1,0,8] 0\n",
      "P_NewCap[13,1,0,9] 0\n",
      "P_NewCap[13,1,0,10] 0\n",
      "P_NewCap[13,1,0,11] 0\n",
      "P_NewCap[13,1,0,12] 0\n",
      "P_NewCap[13,1,0,13] 0\n",
      "P_NewCap[13,1,0,14] 0\n",
      "P_NewCap[13,1,0,15] 0\n",
      "P_NewCap[13,1,0,16] 0\n",
      "P_NewCap[13,1,0,17] 0\n",
      "P_NewCap[13,1,0,18] 0\n",
      "P_NewCap[13,1,0,19] 0\n",
      "P_NewCap[13,1,0,20] 0\n",
      "P_NewCap[13,1,0,21] 0\n",
      "P_NewCap[13,1,0,22] 0\n",
      "P_NewCap[13,1,0,23] 0\n",
      "P_NewCap[13,1,1,0] 0\n",
      "P_NewCap[13,1,1,1] 0\n",
      "P_NewCap[13,1,1,2] 0\n",
      "P_NewCap[13,1,1,3] 0\n",
      "P_NewCap[13,1,1,4] 0\n",
      "P_NewCap[13,1,1,5] 0\n",
      "P_NewCap[13,1,1,6] 0\n",
      "P_NewCap[13,1,1,7] 0\n",
      "P_NewCap[13,1,1,8] 0\n",
      "P_NewCap[13,1,1,9] 0\n",
      "P_NewCap[13,1,1,10] 0\n",
      "P_NewCap[13,1,1,11] 0\n",
      "P_NewCap[13,1,1,12] 0\n",
      "P_NewCap[13,1,1,13] 0\n",
      "P_NewCap[13,1,1,14] 0\n",
      "P_NewCap[13,1,1,15] 0\n",
      "P_NewCap[13,1,1,16] 0\n",
      "P_NewCap[13,1,1,17] 0\n",
      "P_NewCap[13,1,1,18] 0\n",
      "P_NewCap[13,1,1,19] 0\n",
      "P_NewCap[13,1,1,20] 0\n",
      "P_NewCap[13,1,1,21] 0\n",
      "P_NewCap[13,1,1,22] 0\n",
      "P_NewCap[13,1,1,23] 0\n",
      "P_NewCap[13,1,2,0] 0\n",
      "P_NewCap[13,1,2,1] 0\n",
      "P_NewCap[13,1,2,2] 0\n",
      "P_NewCap[13,1,2,3] 0\n",
      "P_NewCap[13,1,2,4] 0\n",
      "P_NewCap[13,1,2,5] 0\n",
      "P_NewCap[13,1,2,6] 0\n",
      "P_NewCap[13,1,2,7] 0\n",
      "P_NewCap[13,1,2,8] 0\n",
      "P_NewCap[13,1,2,9] 0\n",
      "P_NewCap[13,1,2,10] 0\n",
      "P_NewCap[13,1,2,11] 0\n",
      "P_NewCap[13,1,2,12] 0\n",
      "P_NewCap[13,1,2,13] 0\n",
      "P_NewCap[13,1,2,14] 0\n",
      "P_NewCap[13,1,2,15] 0\n",
      "P_NewCap[13,1,2,16] 0\n",
      "P_NewCap[13,1,2,17] 0\n",
      "P_NewCap[13,1,2,18] 0\n",
      "P_NewCap[13,1,2,19] 0\n",
      "P_NewCap[13,1,2,20] 0\n",
      "P_NewCap[13,1,2,21] 0\n",
      "P_NewCap[13,1,2,22] 0\n",
      "P_NewCap[13,1,2,23] 0\n",
      "P_NewCap[13,1,3,0] 0\n",
      "P_NewCap[13,1,3,1] 0\n",
      "P_NewCap[13,1,3,2] 0\n",
      "P_NewCap[13,1,3,3] 0\n",
      "P_NewCap[13,1,3,4] 0\n",
      "P_NewCap[13,1,3,5] 0\n",
      "P_NewCap[13,1,3,6] 0\n",
      "P_NewCap[13,1,3,7] 0\n",
      "P_NewCap[13,1,3,8] 0\n",
      "P_NewCap[13,1,3,9] 0\n",
      "P_NewCap[13,1,3,10] 0\n",
      "P_NewCap[13,1,3,11] 0\n",
      "P_NewCap[13,1,3,12] 0\n",
      "P_NewCap[13,1,3,13] 0\n",
      "P_NewCap[13,1,3,14] 0\n",
      "P_NewCap[13,1,3,15] 0\n",
      "P_NewCap[13,1,3,16] 0\n",
      "P_NewCap[13,1,3,17] 0\n",
      "P_NewCap[13,1,3,18] 0\n",
      "P_NewCap[13,1,3,19] 0\n",
      "P_NewCap[13,1,3,20] 0\n",
      "P_NewCap[13,1,3,21] 0\n",
      "P_NewCap[13,1,3,22] 0\n",
      "P_NewCap[13,1,3,23] 0\n",
      "P_NewCap[13,1,4,0] 0\n",
      "P_NewCap[13,1,4,1] 0\n",
      "P_NewCap[13,1,4,2] 0\n",
      "P_NewCap[13,1,4,3] 0\n",
      "P_NewCap[13,1,4,4] 0\n",
      "P_NewCap[13,1,4,5] 0\n",
      "P_NewCap[13,1,4,6] 0\n",
      "P_NewCap[13,1,4,7] 0\n",
      "P_NewCap[13,1,4,8] 0\n",
      "P_NewCap[13,1,4,9] 0\n",
      "P_NewCap[13,1,4,10] 0\n",
      "P_NewCap[13,1,4,11] 0\n",
      "P_NewCap[13,1,4,12] 0\n",
      "P_NewCap[13,1,4,13] 0\n",
      "P_NewCap[13,1,4,14] 0\n",
      "P_NewCap[13,1,4,15] 0\n",
      "P_NewCap[13,1,4,16] 0\n",
      "P_NewCap[13,1,4,17] 0\n",
      "P_NewCap[13,1,4,18] 0\n",
      "P_NewCap[13,1,4,19] 0\n",
      "P_NewCap[13,1,4,20] 0\n",
      "P_NewCap[13,1,4,21] 0\n",
      "P_NewCap[13,1,4,22] 0\n",
      "P_NewCap[13,1,4,23] 0\n",
      "P_NewCap[14,0,0,0] 0\n",
      "P_NewCap[14,0,0,1] 0\n",
      "P_NewCap[14,0,0,2] 0\n",
      "P_NewCap[14,0,0,3] 0\n",
      "P_NewCap[14,0,0,4] 0\n",
      "P_NewCap[14,0,0,5] 0\n",
      "P_NewCap[14,0,0,6] 0\n",
      "P_NewCap[14,0,0,7] 0\n",
      "P_NewCap[14,0,0,8] 0\n",
      "P_NewCap[14,0,0,9] 0\n",
      "P_NewCap[14,0,0,10] 0\n",
      "P_NewCap[14,0,0,11] 0\n",
      "P_NewCap[14,0,0,12] 0\n",
      "P_NewCap[14,0,0,13] 0\n",
      "P_NewCap[14,0,0,14] 0\n",
      "P_NewCap[14,0,0,15] 0\n",
      "P_NewCap[14,0,0,16] 0\n",
      "P_NewCap[14,0,0,17] 0\n",
      "P_NewCap[14,0,0,18] 0\n",
      "P_NewCap[14,0,0,19] 0\n",
      "P_NewCap[14,0,0,20] 0\n",
      "P_NewCap[14,0,0,21] 0\n",
      "P_NewCap[14,0,0,22] 0\n",
      "P_NewCap[14,0,0,23] 0\n",
      "P_NewCap[14,0,1,0] 0\n",
      "P_NewCap[14,0,1,1] 0\n",
      "P_NewCap[14,0,1,2] 0\n",
      "P_NewCap[14,0,1,3] 0\n",
      "P_NewCap[14,0,1,4] 0\n",
      "P_NewCap[14,0,1,5] 0\n",
      "P_NewCap[14,0,1,6] 0\n",
      "P_NewCap[14,0,1,7] 0\n",
      "P_NewCap[14,0,1,8] 0\n",
      "P_NewCap[14,0,1,9] 0\n",
      "P_NewCap[14,0,1,10] 0\n",
      "P_NewCap[14,0,1,11] 0\n",
      "P_NewCap[14,0,1,12] 0\n",
      "P_NewCap[14,0,1,13] 0\n",
      "P_NewCap[14,0,1,14] 0\n",
      "P_NewCap[14,0,1,15] 0\n",
      "P_NewCap[14,0,1,16] 0\n",
      "P_NewCap[14,0,1,17] 0\n",
      "P_NewCap[14,0,1,18] 0\n",
      "P_NewCap[14,0,1,19] 0\n",
      "P_NewCap[14,0,1,20] 0\n",
      "P_NewCap[14,0,1,21] 0\n",
      "P_NewCap[14,0,1,22] 0\n",
      "P_NewCap[14,0,1,23] 0\n",
      "P_NewCap[14,0,2,0] 0\n",
      "P_NewCap[14,0,2,1] 0\n",
      "P_NewCap[14,0,2,2] 0\n",
      "P_NewCap[14,0,2,3] 0\n",
      "P_NewCap[14,0,2,4] 0\n",
      "P_NewCap[14,0,2,5] 0\n",
      "P_NewCap[14,0,2,6] 0\n",
      "P_NewCap[14,0,2,7] 0\n",
      "P_NewCap[14,0,2,8] 0\n",
      "P_NewCap[14,0,2,9] 0\n",
      "P_NewCap[14,0,2,10] 0\n",
      "P_NewCap[14,0,2,11] 0\n",
      "P_NewCap[14,0,2,12] 0\n",
      "P_NewCap[14,0,2,13] 0\n",
      "P_NewCap[14,0,2,14] 0\n",
      "P_NewCap[14,0,2,15] 0\n",
      "P_NewCap[14,0,2,16] 0\n",
      "P_NewCap[14,0,2,17] 0\n",
      "P_NewCap[14,0,2,18] 0\n",
      "P_NewCap[14,0,2,19] 0\n",
      "P_NewCap[14,0,2,20] 0\n",
      "P_NewCap[14,0,2,21] 0\n",
      "P_NewCap[14,0,2,22] 0\n",
      "P_NewCap[14,0,2,23] 0\n",
      "P_NewCap[14,0,3,0] 0\n",
      "P_NewCap[14,0,3,1] 0\n",
      "P_NewCap[14,0,3,2] 0\n",
      "P_NewCap[14,0,3,3] 0\n",
      "P_NewCap[14,0,3,4] 0\n",
      "P_NewCap[14,0,3,5] 0\n",
      "P_NewCap[14,0,3,6] 0\n",
      "P_NewCap[14,0,3,7] 0\n",
      "P_NewCap[14,0,3,8] 0\n",
      "P_NewCap[14,0,3,9] 0\n",
      "P_NewCap[14,0,3,10] 0\n",
      "P_NewCap[14,0,3,11] 0\n",
      "P_NewCap[14,0,3,12] 0\n",
      "P_NewCap[14,0,3,13] 0\n",
      "P_NewCap[14,0,3,14] 0\n",
      "P_NewCap[14,0,3,15] 0\n",
      "P_NewCap[14,0,3,16] 0\n",
      "P_NewCap[14,0,3,17] 0\n",
      "P_NewCap[14,0,3,18] 0\n",
      "P_NewCap[14,0,3,19] 0\n",
      "P_NewCap[14,0,3,20] 0\n",
      "P_NewCap[14,0,3,21] 0\n",
      "P_NewCap[14,0,3,22] 0\n",
      "P_NewCap[14,0,3,23] 0\n",
      "P_NewCap[14,0,4,0] 0\n",
      "P_NewCap[14,0,4,1] 0\n",
      "P_NewCap[14,0,4,2] 0\n",
      "P_NewCap[14,0,4,3] 0\n",
      "P_NewCap[14,0,4,4] 0\n",
      "P_NewCap[14,0,4,5] 0\n",
      "P_NewCap[14,0,4,6] 0\n",
      "P_NewCap[14,0,4,7] 0\n",
      "P_NewCap[14,0,4,8] 0\n",
      "P_NewCap[14,0,4,9] 0\n",
      "P_NewCap[14,0,4,10] 0\n",
      "P_NewCap[14,0,4,11] 0\n",
      "P_NewCap[14,0,4,12] 0\n",
      "P_NewCap[14,0,4,13] 0\n",
      "P_NewCap[14,0,4,14] 0\n",
      "P_NewCap[14,0,4,15] 0\n",
      "P_NewCap[14,0,4,16] 0\n",
      "P_NewCap[14,0,4,17] 0\n",
      "P_NewCap[14,0,4,18] 0\n",
      "P_NewCap[14,0,4,19] 0\n",
      "P_NewCap[14,0,4,20] 0\n",
      "P_NewCap[14,0,4,21] 0\n",
      "P_NewCap[14,0,4,22] 0\n",
      "P_NewCap[14,0,4,23] 0\n",
      "P_NewCap[14,1,0,0] 0\n",
      "P_NewCap[14,1,0,1] 0\n",
      "P_NewCap[14,1,0,2] 0\n",
      "P_NewCap[14,1,0,3] 0\n",
      "P_NewCap[14,1,0,4] 0\n",
      "P_NewCap[14,1,0,5] 0\n",
      "P_NewCap[14,1,0,6] 0\n",
      "P_NewCap[14,1,0,7] 0\n",
      "P_NewCap[14,1,0,8] 0\n",
      "P_NewCap[14,1,0,9] 0\n",
      "P_NewCap[14,1,0,10] 0\n",
      "P_NewCap[14,1,0,11] 0\n",
      "P_NewCap[14,1,0,12] 0\n",
      "P_NewCap[14,1,0,13] 0\n",
      "P_NewCap[14,1,0,14] 0\n",
      "P_NewCap[14,1,0,15] 0\n",
      "P_NewCap[14,1,0,16] 0\n",
      "P_NewCap[14,1,0,17] 0\n",
      "P_NewCap[14,1,0,18] 0\n",
      "P_NewCap[14,1,0,19] 0\n",
      "P_NewCap[14,1,0,20] 0\n",
      "P_NewCap[14,1,0,21] 0\n",
      "P_NewCap[14,1,0,22] 0\n",
      "P_NewCap[14,1,0,23] 0\n",
      "P_NewCap[14,1,1,0] 0\n",
      "P_NewCap[14,1,1,1] 0\n",
      "P_NewCap[14,1,1,2] 0\n",
      "P_NewCap[14,1,1,3] 0\n",
      "P_NewCap[14,1,1,4] 0\n",
      "P_NewCap[14,1,1,5] 0\n",
      "P_NewCap[14,1,1,6] 0\n",
      "P_NewCap[14,1,1,7] 0\n",
      "P_NewCap[14,1,1,8] 0\n",
      "P_NewCap[14,1,1,9] 0\n",
      "P_NewCap[14,1,1,10] 0\n",
      "P_NewCap[14,1,1,11] 0\n",
      "P_NewCap[14,1,1,12] 0\n",
      "P_NewCap[14,1,1,13] 0\n",
      "P_NewCap[14,1,1,14] 0\n",
      "P_NewCap[14,1,1,15] 0\n",
      "P_NewCap[14,1,1,16] 0\n",
      "P_NewCap[14,1,1,17] 0\n",
      "P_NewCap[14,1,1,18] 0\n",
      "P_NewCap[14,1,1,19] 0\n",
      "P_NewCap[14,1,1,20] 0\n",
      "P_NewCap[14,1,1,21] 0\n",
      "P_NewCap[14,1,1,22] 0\n",
      "P_NewCap[14,1,1,23] 0\n",
      "P_NewCap[14,1,2,0] 0\n",
      "P_NewCap[14,1,2,1] 0\n",
      "P_NewCap[14,1,2,2] 0\n",
      "P_NewCap[14,1,2,3] 0\n",
      "P_NewCap[14,1,2,4] 0\n",
      "P_NewCap[14,1,2,5] 0\n",
      "P_NewCap[14,1,2,6] 0\n",
      "P_NewCap[14,1,2,7] 0\n",
      "P_NewCap[14,1,2,8] 0\n",
      "P_NewCap[14,1,2,9] 0\n",
      "P_NewCap[14,1,2,10] 0\n",
      "P_NewCap[14,1,2,11] 0\n",
      "P_NewCap[14,1,2,12] 0\n",
      "P_NewCap[14,1,2,13] 0\n",
      "P_NewCap[14,1,2,14] 0\n",
      "P_NewCap[14,1,2,15] 0\n",
      "P_NewCap[14,1,2,16] 0\n",
      "P_NewCap[14,1,2,17] 0\n",
      "P_NewCap[14,1,2,18] 0\n",
      "P_NewCap[14,1,2,19] 0\n",
      "P_NewCap[14,1,2,20] 0\n",
      "P_NewCap[14,1,2,21] 0\n",
      "P_NewCap[14,1,2,22] 0\n",
      "P_NewCap[14,1,2,23] 0\n",
      "P_NewCap[14,1,3,0] 0\n",
      "P_NewCap[14,1,3,1] 0\n",
      "P_NewCap[14,1,3,2] 0\n",
      "P_NewCap[14,1,3,3] 0\n",
      "P_NewCap[14,1,3,4] 0\n",
      "P_NewCap[14,1,3,5] 0\n",
      "P_NewCap[14,1,3,6] 0\n",
      "P_NewCap[14,1,3,7] 0\n",
      "P_NewCap[14,1,3,8] 0\n",
      "P_NewCap[14,1,3,9] 0\n",
      "P_NewCap[14,1,3,10] 0\n",
      "P_NewCap[14,1,3,11] 0\n",
      "P_NewCap[14,1,3,12] 0\n",
      "P_NewCap[14,1,3,13] 0\n",
      "P_NewCap[14,1,3,14] 0\n",
      "P_NewCap[14,1,3,15] 0\n",
      "P_NewCap[14,1,3,16] 0\n",
      "P_NewCap[14,1,3,17] 0\n",
      "P_NewCap[14,1,3,18] 0\n",
      "P_NewCap[14,1,3,19] 0\n",
      "P_NewCap[14,1,3,20] 0\n",
      "P_NewCap[14,1,3,21] 0\n",
      "P_NewCap[14,1,3,22] 0\n",
      "P_NewCap[14,1,3,23] 0\n",
      "P_NewCap[14,1,4,0] 0\n",
      "P_NewCap[14,1,4,1] 0\n",
      "P_NewCap[14,1,4,2] 0\n",
      "P_NewCap[14,1,4,3] 0\n",
      "P_NewCap[14,1,4,4] 0\n",
      "P_NewCap[14,1,4,5] 0\n",
      "P_NewCap[14,1,4,6] 0\n",
      "P_NewCap[14,1,4,7] 0\n",
      "P_NewCap[14,1,4,8] 0\n",
      "P_NewCap[14,1,4,9] 0\n",
      "P_NewCap[14,1,4,10] 0\n",
      "P_NewCap[14,1,4,11] 0\n",
      "P_NewCap[14,1,4,12] 0\n",
      "P_NewCap[14,1,4,13] 0\n",
      "P_NewCap[14,1,4,14] 0\n",
      "P_NewCap[14,1,4,15] 0\n",
      "P_NewCap[14,1,4,16] 0\n",
      "P_NewCap[14,1,4,17] 0\n",
      "P_NewCap[14,1,4,18] 0\n",
      "P_NewCap[14,1,4,19] 0\n",
      "P_NewCap[14,1,4,20] 0\n",
      "P_NewCap[14,1,4,21] 0\n",
      "P_NewCap[14,1,4,22] 0\n",
      "P_NewCap[14,1,4,23] 0\n",
      "P_NewCap[15,0,0,0] 0\n",
      "P_NewCap[15,0,0,1] 0\n",
      "P_NewCap[15,0,0,2] 0\n",
      "P_NewCap[15,0,0,3] 0\n",
      "P_NewCap[15,0,0,4] 0\n",
      "P_NewCap[15,0,0,5] 0\n",
      "P_NewCap[15,0,0,6] 0\n",
      "P_NewCap[15,0,0,7] 0\n",
      "P_NewCap[15,0,0,8] 0\n",
      "P_NewCap[15,0,0,9] 0\n",
      "P_NewCap[15,0,0,10] 0\n",
      "P_NewCap[15,0,0,11] 0\n",
      "P_NewCap[15,0,0,12] 0\n",
      "P_NewCap[15,0,0,13] 0\n",
      "P_NewCap[15,0,0,14] 0\n",
      "P_NewCap[15,0,0,15] 0\n",
      "P_NewCap[15,0,0,16] 0\n",
      "P_NewCap[15,0,0,17] 0\n",
      "P_NewCap[15,0,0,18] 0\n",
      "P_NewCap[15,0,0,19] 0\n",
      "P_NewCap[15,0,0,20] 0\n",
      "P_NewCap[15,0,0,21] 0\n",
      "P_NewCap[15,0,0,22] 0\n",
      "P_NewCap[15,0,0,23] 0\n",
      "P_NewCap[15,0,1,0] 0\n",
      "P_NewCap[15,0,1,1] 0\n",
      "P_NewCap[15,0,1,2] 0\n",
      "P_NewCap[15,0,1,3] 0\n",
      "P_NewCap[15,0,1,4] 0\n",
      "P_NewCap[15,0,1,5] 0\n",
      "P_NewCap[15,0,1,6] 0\n",
      "P_NewCap[15,0,1,7] 0\n",
      "P_NewCap[15,0,1,8] 0\n",
      "P_NewCap[15,0,1,9] 0\n",
      "P_NewCap[15,0,1,10] 0\n",
      "P_NewCap[15,0,1,11] 0\n",
      "P_NewCap[15,0,1,12] 0\n",
      "P_NewCap[15,0,1,13] 0\n",
      "P_NewCap[15,0,1,14] 0\n",
      "P_NewCap[15,0,1,15] 0\n",
      "P_NewCap[15,0,1,16] 0\n",
      "P_NewCap[15,0,1,17] 0\n",
      "P_NewCap[15,0,1,18] 0\n",
      "P_NewCap[15,0,1,19] 0\n",
      "P_NewCap[15,0,1,20] 0\n",
      "P_NewCap[15,0,1,21] 0\n",
      "P_NewCap[15,0,1,22] 0\n",
      "P_NewCap[15,0,1,23] 0\n",
      "P_NewCap[15,0,2,0] 0\n",
      "P_NewCap[15,0,2,1] 0\n",
      "P_NewCap[15,0,2,2] 0\n",
      "P_NewCap[15,0,2,3] 0\n",
      "P_NewCap[15,0,2,4] 0\n",
      "P_NewCap[15,0,2,5] 0\n",
      "P_NewCap[15,0,2,6] 0\n",
      "P_NewCap[15,0,2,7] 0\n",
      "P_NewCap[15,0,2,8] 0\n",
      "P_NewCap[15,0,2,9] 0\n",
      "P_NewCap[15,0,2,10] 0\n",
      "P_NewCap[15,0,2,11] 0\n",
      "P_NewCap[15,0,2,12] 0\n",
      "P_NewCap[15,0,2,13] 0\n",
      "P_NewCap[15,0,2,14] 0\n",
      "P_NewCap[15,0,2,15] 0\n",
      "P_NewCap[15,0,2,16] 0\n",
      "P_NewCap[15,0,2,17] 0\n",
      "P_NewCap[15,0,2,18] 0\n",
      "P_NewCap[15,0,2,19] 0\n",
      "P_NewCap[15,0,2,20] 0\n",
      "P_NewCap[15,0,2,21] 0\n",
      "P_NewCap[15,0,2,22] 0\n",
      "P_NewCap[15,0,2,23] 0\n",
      "P_NewCap[15,0,3,0] 0\n",
      "P_NewCap[15,0,3,1] 0\n",
      "P_NewCap[15,0,3,2] 0\n",
      "P_NewCap[15,0,3,3] 0\n",
      "P_NewCap[15,0,3,4] 0\n",
      "P_NewCap[15,0,3,5] 0\n",
      "P_NewCap[15,0,3,6] 0\n",
      "P_NewCap[15,0,3,7] 0\n",
      "P_NewCap[15,0,3,8] 0\n",
      "P_NewCap[15,0,3,9] 0\n",
      "P_NewCap[15,0,3,10] 0\n",
      "P_NewCap[15,0,3,11] 0\n",
      "P_NewCap[15,0,3,12] 0\n",
      "P_NewCap[15,0,3,13] 0\n",
      "P_NewCap[15,0,3,14] 0\n",
      "P_NewCap[15,0,3,15] 0\n",
      "P_NewCap[15,0,3,16] 0\n",
      "P_NewCap[15,0,3,17] 0\n",
      "P_NewCap[15,0,3,18] 0\n",
      "P_NewCap[15,0,3,19] 0\n",
      "P_NewCap[15,0,3,20] 0\n",
      "P_NewCap[15,0,3,21] 0\n",
      "P_NewCap[15,0,3,22] 0\n",
      "P_NewCap[15,0,3,23] 0\n",
      "P_NewCap[15,0,4,0] 0\n",
      "P_NewCap[15,0,4,1] 0\n",
      "P_NewCap[15,0,4,2] 0\n",
      "P_NewCap[15,0,4,3] 0\n",
      "P_NewCap[15,0,4,4] 0\n",
      "P_NewCap[15,0,4,5] 0\n",
      "P_NewCap[15,0,4,6] 0\n",
      "P_NewCap[15,0,4,7] 0\n",
      "P_NewCap[15,0,4,8] 0\n",
      "P_NewCap[15,0,4,9] 0\n",
      "P_NewCap[15,0,4,10] 0\n",
      "P_NewCap[15,0,4,11] 0\n",
      "P_NewCap[15,0,4,12] 0\n",
      "P_NewCap[15,0,4,13] 0\n",
      "P_NewCap[15,0,4,14] 0\n",
      "P_NewCap[15,0,4,15] 0\n",
      "P_NewCap[15,0,4,16] 0\n",
      "P_NewCap[15,0,4,17] 0\n",
      "P_NewCap[15,0,4,18] 0\n",
      "P_NewCap[15,0,4,19] 0\n",
      "P_NewCap[15,0,4,20] 0\n",
      "P_NewCap[15,0,4,21] 0\n",
      "P_NewCap[15,0,4,22] 0\n",
      "P_NewCap[15,0,4,23] 0\n",
      "P_NewCap[15,1,0,0] 0\n",
      "P_NewCap[15,1,0,1] 0\n",
      "P_NewCap[15,1,0,2] 0\n",
      "P_NewCap[15,1,0,3] 0\n",
      "P_NewCap[15,1,0,4] 0\n",
      "P_NewCap[15,1,0,5] 0\n",
      "P_NewCap[15,1,0,6] 0\n",
      "P_NewCap[15,1,0,7] 0\n",
      "P_NewCap[15,1,0,8] 0\n",
      "P_NewCap[15,1,0,9] 0\n",
      "P_NewCap[15,1,0,10] 0\n",
      "P_NewCap[15,1,0,11] 0\n",
      "P_NewCap[15,1,0,12] 0\n",
      "P_NewCap[15,1,0,13] 0\n",
      "P_NewCap[15,1,0,14] 0\n",
      "P_NewCap[15,1,0,15] 0\n",
      "P_NewCap[15,1,0,16] 0\n",
      "P_NewCap[15,1,0,17] 0\n",
      "P_NewCap[15,1,0,18] 0\n",
      "P_NewCap[15,1,0,19] 0\n",
      "P_NewCap[15,1,0,20] 0\n",
      "P_NewCap[15,1,0,21] 0\n",
      "P_NewCap[15,1,0,22] 0\n",
      "P_NewCap[15,1,0,23] 0\n",
      "P_NewCap[15,1,1,0] 0\n",
      "P_NewCap[15,1,1,1] 0\n",
      "P_NewCap[15,1,1,2] 0\n",
      "P_NewCap[15,1,1,3] 0\n",
      "P_NewCap[15,1,1,4] 0\n",
      "P_NewCap[15,1,1,5] 0\n",
      "P_NewCap[15,1,1,6] 0\n",
      "P_NewCap[15,1,1,7] 0\n",
      "P_NewCap[15,1,1,8] 0\n",
      "P_NewCap[15,1,1,9] 0\n",
      "P_NewCap[15,1,1,10] 0\n",
      "P_NewCap[15,1,1,11] 0\n",
      "P_NewCap[15,1,1,12] 0\n",
      "P_NewCap[15,1,1,13] 0\n",
      "P_NewCap[15,1,1,14] 0\n",
      "P_NewCap[15,1,1,15] 0\n",
      "P_NewCap[15,1,1,16] 0\n",
      "P_NewCap[15,1,1,17] 0\n",
      "P_NewCap[15,1,1,18] 0\n",
      "P_NewCap[15,1,1,19] 0\n",
      "P_NewCap[15,1,1,20] 0\n",
      "P_NewCap[15,1,1,21] 0\n",
      "P_NewCap[15,1,1,22] 0\n",
      "P_NewCap[15,1,1,23] 0\n",
      "P_NewCap[15,1,2,0] 0\n",
      "P_NewCap[15,1,2,1] 0\n",
      "P_NewCap[15,1,2,2] 0\n",
      "P_NewCap[15,1,2,3] 0\n",
      "P_NewCap[15,1,2,4] 0\n",
      "P_NewCap[15,1,2,5] 0\n",
      "P_NewCap[15,1,2,6] 0\n",
      "P_NewCap[15,1,2,7] 0\n",
      "P_NewCap[15,1,2,8] 0\n",
      "P_NewCap[15,1,2,9] 0\n",
      "P_NewCap[15,1,2,10] 0\n",
      "P_NewCap[15,1,2,11] 0\n",
      "P_NewCap[15,1,2,12] 0\n",
      "P_NewCap[15,1,2,13] 0\n",
      "P_NewCap[15,1,2,14] 0\n",
      "P_NewCap[15,1,2,15] 0\n",
      "P_NewCap[15,1,2,16] 0\n",
      "P_NewCap[15,1,2,17] 0\n",
      "P_NewCap[15,1,2,18] 0\n",
      "P_NewCap[15,1,2,19] 0\n",
      "P_NewCap[15,1,2,20] 0\n",
      "P_NewCap[15,1,2,21] 0\n",
      "P_NewCap[15,1,2,22] 0\n",
      "P_NewCap[15,1,2,23] 0\n",
      "P_NewCap[15,1,3,0] 0\n",
      "P_NewCap[15,1,3,1] 0\n",
      "P_NewCap[15,1,3,2] 0\n",
      "P_NewCap[15,1,3,3] 0\n",
      "P_NewCap[15,1,3,4] 0\n",
      "P_NewCap[15,1,3,5] 0\n",
      "P_NewCap[15,1,3,6] 0\n",
      "P_NewCap[15,1,3,7] 0\n",
      "P_NewCap[15,1,3,8] 0\n",
      "P_NewCap[15,1,3,9] 0\n",
      "P_NewCap[15,1,3,10] 0\n",
      "P_NewCap[15,1,3,11] 0\n",
      "P_NewCap[15,1,3,12] 0\n",
      "P_NewCap[15,1,3,13] 0\n",
      "P_NewCap[15,1,3,14] 0\n",
      "P_NewCap[15,1,3,15] 0\n",
      "P_NewCap[15,1,3,16] 0\n",
      "P_NewCap[15,1,3,17] 0\n",
      "P_NewCap[15,1,3,18] 0\n",
      "P_NewCap[15,1,3,19] 0\n",
      "P_NewCap[15,1,3,20] 0\n",
      "P_NewCap[15,1,3,21] 0\n",
      "P_NewCap[15,1,3,22] 0\n",
      "P_NewCap[15,1,3,23] 0\n",
      "P_NewCap[15,1,4,0] 0\n",
      "P_NewCap[15,1,4,1] 0\n",
      "P_NewCap[15,1,4,2] 0\n",
      "P_NewCap[15,1,4,3] 0\n",
      "P_NewCap[15,1,4,4] 0\n",
      "P_NewCap[15,1,4,5] 0\n",
      "P_NewCap[15,1,4,6] 0\n",
      "P_NewCap[15,1,4,7] 0\n",
      "P_NewCap[15,1,4,8] 0\n",
      "P_NewCap[15,1,4,9] 0\n",
      "P_NewCap[15,1,4,10] 0\n",
      "P_NewCap[15,1,4,11] 0\n",
      "P_NewCap[15,1,4,12] 0\n",
      "P_NewCap[15,1,4,13] 0\n",
      "P_NewCap[15,1,4,14] 0\n",
      "P_NewCap[15,1,4,15] 0\n",
      "P_NewCap[15,1,4,16] 0\n",
      "P_NewCap[15,1,4,17] 0\n",
      "P_NewCap[15,1,4,18] 0\n",
      "P_NewCap[15,1,4,19] 0\n",
      "P_NewCap[15,1,4,20] 0\n",
      "P_NewCap[15,1,4,21] 0\n",
      "P_NewCap[15,1,4,22] 0\n",
      "P_NewCap[15,1,4,23] 0\n",
      "Obj: -0.0\n",
      "    Unit #  Investment\n",
      "0        0         0.0\n",
      "1        1         0.0\n",
      "2        2         0.0\n",
      "3        3         0.0\n",
      "4        4         0.0\n",
      "5        5         0.0\n",
      "6        6         0.0\n",
      "7        7         0.0\n",
      "8        8         0.0\n",
      "9        9         0.0\n",
      "10      10         0.0\n",
      "11      11         0.0\n",
      "12      12         0.0\n",
      "13      13         0.0\n",
      "14      14         0.0\n",
      "15      15         0.0\n",
      "      Unit #  Year  Season  Hour  Generation\n",
      "0          0     0       0     0         0.0\n",
      "1          0     0       0     1         0.0\n",
      "2          0     0       0     2         0.0\n",
      "3          0     0       0     3         0.0\n",
      "4          0     0       0     4         0.0\n",
      "...      ...   ...     ...   ...         ...\n",
      "3835      15     1       4    19         0.0\n",
      "3836      15     1       4    20         0.0\n",
      "3837      15     1       4    21         0.0\n",
      "3838      15     1       4    22         0.0\n",
      "3839      15     1       4    23         0.0\n",
      "\n",
      "[3840 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/4AAAImCAYAAADqhlE7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfSUlEQVR4nO3deVhUdf//8dewg0ouCXhr5hbgLigouaRmtqjl0l13ZZn7GrmXWeZWZmqamWmp5b6UpdWtZbZbpqKW3omaG2mKaIpm4LDM+f3hj/k2gcbAwIyH5+O6uGQ+53POeZ/pnfWas4zFMAxDAAAAAADAlLzcXQAAAAAAACg6BH8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxAj+AAAAAACYGMEfAAAAAAATI/gDAAAHhmG4uwSYCP0EAO5H8AcAFLkxY8YoIiJCW7ZsyXP5t99+q4iICE2fPr1I63j//fcVERGhEydOFHpbqampmjt3rrp06aKYmBg1bNhQHTp00MyZM5Wamlr4Yt1k7ty5Wrhwof31a6+9poiICDdWlNs777yj5s2bq0GDBpo7d26ec9q2bauIiIir/gwbNsylNRX2fSop/QQAcA8fdxcAADC/MWPGaMuWLRo3bpw+/vhjBQUF2ZddunRJ48aNU0REhOLj491YZf4dPHhQ/fv3V2Zmprp376769evL29tbP/74oxYvXqwNGzZo1apVqlChgrtLddqrr76qIUOG2F//+9//VsuWLd1YkaNLly5p6tSpat26tXr16qUqVapcde5tt92mQYMG5bmsXLlyRVWi00pSPwEA3IPgDwAocsHBwZowYYIGDhyomTNnauzYsfZlM2bM0JkzZ/TGG2/Iz8/PjVXmj9Vq1dChQ+Xt7a21a9eqfPny9mXNmjVThw4ddN9992n27NmaMGGCGyt1jbCwMIWFhbm7DLsLFy7IZrOpXbt2iomJuebc8uXLq1GjRsVTWAGVtH4CALgHl/oDAIpF27Zt1alTJy1btkw//fSTJGnnzp1auXKl4uPjFRkZKUk6efKkhg8frtjYWDVs2FA9evTQvn37HLZ14sQJjR49Wi1atFDdunUVFxen0aNH6/z58w77e/HFF9WjRw81aNDA4cMGSfrqq6/yvP0gISFBERER2rlzZ57HsXHjRh0+fFjPPfecQ0jLcdNNN2ngwIG5lm3evFldu3ZV/fr11bx5c02ePFlpaWn25a+99pruuOMOffXVV+rUqZPq1aunO++8U+vWrXPYTmpqqsaNG6dbb71V9evX1wMPPKCtW7c6zImIiNCcOXPUtWtXNWjQQHPmzJEk7dixQ71791ZMTIzq1auntm3b6rXXXpPNZrOvJ0lz5syx/57XJewbNmxQ165dFRUVpebNm2vcuHG6cOGC08eSl++++04PP/ywGjdurKZNm2rEiBE6deqUpCu3arRt21aS9Mwzz7jsFoRz585pwoQJatOmjerVq6fY2FgNHjw41y0h69atU5cuXdSwYUO1bt1aM2bMUEZGhsOcr776Svfee6/q16+fr2Muaf0kSXv37lXv3r3VtGlTRUdHa8CAAfrll1/sy7dt26aIiAitWrVKbdq0UXR0tL777rtrvo8AgH9gAABQTM6fP2/ceuutRrdu3Qyr1Wp07NjRePDBB42srCzDMAzj999/N1q2bGm0b9/e+PDDD43PPvvM6N69u9GoUSPj0KFDhmEYRlpamtGmTRuja9euxqZNm4ytW7cac+fONerUqWM899xz9n21adPGqFOnjjFt2jTj22+/NXbt2mWsXbvWCA8PN44fP25kZWUZLVq0MEaOHOlQ49ixY4327dtf9RgGDx5sxMTEGNnZ2fk+7g8//NAIDw83RowYYXz99dfGihUrjJiYGKNHjx6GzWYzDMMwZs+ebTRs2NBo06aNsWbNGuO7774zevXqZYSHh9uP/fLly8a9995r3HrrrcaaNWuMr776ynjiiSeMOnXqGN9//719f+Hh4UbdunWNRYsWGV9++aVx8OBBIzEx0ahTp44xfPhw49tvvzW++eYbY9SoUUZ4eLjx8ccfG4ZhGLt37zbCw8ONZ555xti9e7e9rvDwcPu2X3/9dSMiIsKYMGGC8c033xjLly83YmNjjU6dOhnp6en5Ppa8fPDBB0Z4eLgxfPhw46uvvjI++OADo02bNkbLli2Ns2fPGr///ruxadMmIzw83Jg5c6a9xry0adPGGD16tJGZmZnnTw6bzWbcf//9xh133GF8/PHHxg8//GAsXrzYiIqKMnr16mWft2zZMiM8PNwYO3as/bgbNmxo77mc96lly5bG2rVrjW+//dZ47LHHjIiICCMxMfGqdZa0ftq6datRt25do1evXsbmzZuN//73v8a9995rREdH2+v64YcfjPDwcKN58+bGxo0bjQ8++MD4888/8/3+AAByI/gDAIpVTnB75JFHjEaNGhnHjh2zL3vllVeM+vXrGydOnLCPWa1W4/bbbzeeeOIJwzAMY9++fcZDDz1k/Prrrw7b7d+/v3HnnXfaX7dp08Zo166dw5y/Bn/DMIwZM2YYjRo1Mi5dumQYhmGkp6cb0dHRxrx5865af6dOnYyuXbvmGs/KysozXNpsNqNVq1ZG7969HeZ///33Rnh4uPHll18ahvF/wfGvgeu3334zwsPDjYULFxqGYRirV682wsPDjR9//NE+x2azGY888ohDTeHh4UaPHj0c9vfBBx8Yffr0cQiY2dnZRuPGjR0+MAkPDzdmz55tf/3X4J+ammrUq1fPYb5hGMaOHTuM8PBwY9myZfk+lr/Lzs42mjdv7hC2DcMwkpKSjLp16xpTp041DMMwjh8/boSHhxtr167Nczs52rRpY4SHh1/1Z8+ePYZhGEZycrLx6KOPGjt27HBYf9KkSUa9evXstcXFxRmDBg1ymLNgwQKjS5cuRkZGhv2Yv/76a4faw8PDjcWLF1+1zpLWT/fff79xzz332D/sMwzDuHDhghEbG2vEx8cbhvF/wf/111+/6vsGAHAO9/gDAIrVHXfcoXvuuUcbNmzQuHHjdPPNN9uXbd26VbVr11ZoaKiysrIkSV5eXmrVqpU+/PBDSVLt2rW1YsUK2Ww2HTt2TElJSTp06JCOHDliXydH7dq1r1lLt27dNH/+fH322Wfq3LmzPvvsM6Wlpalz585XXce4yleTtWnTRqdPn3YY+/zzz2W1WpWcnKz+/fs71BcTE6PSpUvru+++U+vWre3jf70nPefe+pxLuLdu3aqKFSuqbt26Dttq06aNXn75ZV24cEE33HBDnsfeuXNnde7cWVarVUePHlVSUpISExOVnZ2tzMzMq79Jf/Hjjz8qIyNDHTt2dBhv0qSJKleurO3bt+uRRx7J17H83dGjR3XmzBmNGDHCYbxq1aqKiorS9u3b81XjX7Vp00aDBw/Oc1mtWrUkSaGhoVqyZIkMw9CJEyeUlJSkI0eOaNeuXfbL+I8eParff/9dd9xxh8M2evfurd69ezuMNWnSxP57zoMHL168eNUaS1I/paWlae/evRoyZIi8vb3t48HBwWrTpo2+/vprh/n/9O8vACD/CP4AgGLXsmVLbdiwQbfddpvDeGpqqpKSklS3bt0810tPT1dgYKDefvttzZs3T6mpqbrxxhtVr149BQYG6o8//nCY/9dvD8jLzTffrNjYWK1bt06dO3fWunXrdOuttyo0NPSq6/zrX//Snj17ZBiGLBaLffzNN9+0B56vvvrKfh90zlexTZgwIc+Hs6WkpDi8DgwMtP/u5XXlUTw54TA1NVVnzpy56vtz5swZe1D7+7FfvnxZkyZN0vr165WVlaUqVaooKipKPj4++f6e9Zz7+G+88cZcy2688cZc7/+1juXvct6nq2377895yI+yZcuqfv36/zjvww8/1CuvvKJTp06pbNmyql27tgICAnLVlp+n6v/1ff+nY5ZKVj/98ccfMgwj3/3zT//+AgDyj+APAPAYZcqUUWxsrEaPHp3ncj8/P3300Ud66aWXNGrUKHXt2tX+0LMnn3xSe/fudXqf3bp10zPPPKPDhw9r69atmj59+jXnt23bVl999ZW2b9+upk2b2sdzHk4oyeFBZcHBwZKk0aNHKzY2Ntf2coJVfpQpU0bVqlW7ao3X+mq7F154QZ9++qlmzZqlW2+91R6q4uLi8r3/nFrPnj2rGjVqOCw7c+aMbrrppnxv6+/Kli1r3/bfnTlzpsi+fi8hIUFPPfWUHn30UfXu3dv+oc/LL79sf8Bjzj/Dc+fOOax7/vx57du3T1FRUQXef0nqpzJlyshisVz1n3FODwAAXI+n+gMAPEZsbKyOHj2q6tWrq379+vaf9evX67333pO3t7d27typ4OBg9enTxx76//zzT+3cudP+NHFn3HnnnQoMDNT48eNVqlQptWvX7przO3XqpGrVqun555/PM8BIjkGtRo0aqlChgk6cOOFwTKGhoZoxY4ZTZ7JjY2N16tQpVahQwWFb3333nRYsWOBw+fTf7dy5U02bNlW7du3sIe1///ufzp075/C+5ZwVzkvDhg3l5+enjz/+2GE8ISFBJ0+eVHR0dL6P5e+qV6+uihUr5tr28ePH9eOPPxZq29eye/du2Ww2PfHEE/bQn52dre+//16SZLPZVKNGDZUrV05ffvmlw7rr169Xv3798n2rRF5KUj8FBQWpXr162rhxo7Kzs+3jf/zxh7766is1btw437UDAJzDGX8AgMd4/PHHtX79ej3++OPq1auXypUrpw0bNmjNmjUaM2aMJKlBgwZauXKlXnrpJbVp00YpKSlauHChzp4969TZzhyBgYHq0KGDVq9erYceekh+fn7XnB8UFKTXX39dgwcPVseOHfXggw8qOjpa/v7++uWXX/TBBx/o559/VqtWrVS+fHl5e3tr2LBhGjdunLy9vdWmTRtdvHhRc+fO1enTp696mXVeunbtqmXLlqlnz54aMGCAKlWqpO+//15vvfWWunfvLl9f36uu26BBA23cuFErV65UzZo1tX//fr3xxhuyWCxKT0+3zwsODtauXbu0Y8cOh/vVpStn5fv166fXX39dvr6+atOmjU6cOKFXX31VtWrVUpcuXfJ9LH/n5eWl4cOHa8yYMRoxYoTuvfdenT9/XnPmzNENN9ygnj17Or3Nc+fO6ccff8xzmbe3t+rXr68GDRpIkiZOnKhu3brpwoULWr58ufbv3y/pyn3ppUuX1hNPPKGJEyeqQoUKatu2rY4eParZs2frkUceKVDf5Shp/TRixAj17t1b/fr108MPP6zMzEy9+eabysjIuOrzGAAAhUfwBwB4jNDQUK1atUozZszQ+PHjZbVaVa1aNb3wwgu6//77JUldunTRiRMntHbtWq1YsUKhoaG67bbb9PDDD+u5557T4cOHVbNmTaf227p1a61evVpdu3bN1/xatWrpgw8+0Jo1a7Rx40atWrVKf/75p0JCQhQTE6Onn37a4TLsf//73ypVqpQWLFig1atXKygoSNHR0Zo+fbpTl8cHBQVp+fLlmjFjhqZNm6Y//vhDlStX1ogRI9SrV69rrvv0008rMzNTs2bNUkZGhqpUqaKBAwfq0KFD+uKLL5SdnS1vb28NGDBAc+fOVd++fbVhw4Zc23niiSd04403atmyZVq9erXKli2ru+66S0OHDi30Pdldu3ZVqVKlNH/+fA0ePFilS5dWy5YtNXz4cFWsWNHp7X399de5HhiXo0yZMkpISFDTpk01btw4vf322/rkk0904403qmnTppozZ44GDx6snTt36rbbbtMjjzyioKAgLVy4UKtXr1ZYWJj69u2rvn37FuqYpZLVT3FxcXr77bc1e/ZsDR8+XH5+fmrSpImmTp2qW265pcDvIQDg2ixGfp/oAwCAST3//PP66aeftG7dOneXAgAA4HKc8QcAlFhLlizRkSNHtGbNGk2bNs3d5QAAABQJgj8AoMRKSEjQt99+qx49euT6bnoAAACz4FJ/AAAAAABMjK/zAwAAAADAxAj+AAAAAACYGMEfAAAAAAAT4+F+LrB7924ZhiFfX193lwIAAAAAKAEyMzNlsVgUFRX1j3M54+8ChmHoenlGomEYysjIuG7qRclDj8LT0aPwdPQoPB09Ck93vfSoMzmUM/4ukHOmv379+m6u5J+lpaUpMTFRtWrVUlBQkLvLAXKhR+Hp6FF4OnoUno4ehae7Xnp07969+Z7LGX8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxHiqPwAAAADA7bKzs5WZmenuMmS1Wu1/enm571y5r6+vvL29XbItgj8AAAAAwG0Mw1BycrJSU1PdXYokyWazycfHRydPnnRr8JeksmXLKiwsTBaLpVDbIfgDAAAAANwmJ/SHhIQoKCio0CG3sLKzs2W1WuXv7++yM+7OMgxDaWlpSklJkSRVqlSpUNsj+AMAAAAA3CI7O9se+itUqODuciRdqUmSAgIC3Bb8JSkwMFCSlJKSopCQkELVwsP9AAAAAABukXNPf1BQkJsr8Uw570thn31A8AcAAAAAuJW7L+/3VK56Xwj+AAAAAABcg2EY7i6hUAj+AAAAAIDr0qOPPqpHH330qsvbtm2rp59+2qltPvPMM+rQoYP99eeff66nnnoqX+tOnjxZI0aMsL++//77tWTJEqf2XxQI/gAAAAAA/H8DBgzQjBkz7K/feecdnTp1Kl/r7ty5U9HR0ZKk9PR0JSYmqnHjxkVSpzN4qj8AAAAAAP9f1apVFRIS4vR6ly5d0oEDB+xB/8cff5S/v78iIyNdXaLTCP4AAAAAgBKhbdu26ty5s9LT07V+/XpdunRJMTExeu6551StWjVJVy7137Ztmz7//HM9+uij2r59uyQpIiJCS5YsUdOmTR22+fTTT+uDDz6wv77vvvscltepUyfP9YoTl/oDAAAAAEqMJUuW6MiRI5oyZYomT56s//3vf1e9h//5559XnTp1VKdOHa1evVp169bNNWfQoEFavXq1HnjgATVo0ECrV6/W6tWrFRUVpW7dul11veLEGX8AAAAAQIkRHBysuXPnytvbW5L066+/6rXXXtP58+dVrlw5h7m1atVS6dKlJUmNGjXKc3tVq1ZV1apVtWDBAsXGxtrnHT9+XH369LnqesWJM/4AAAAAANOyWCwOr+vXr28P/ZIUFhYm6crD+ArCZrMpKytLP/30k+rVq6esrCz9+uuvOnv2rOrXr6+srCy3fx0gZ/wBAAAAANeloKAgpaamXnV5RkaGAgMDHcb+/trL68r5cJvNVqAannnmGfs9/kOHDnVY1qpVK0ly+z3+BH8AAAAAwHXpxhtv1MGDB/NclpGRoXPnzunGG28s0hqGDBmimjVratGiRXrzzTclXfkKwLNnz2rkyJGSpOrVqxdpDf+ES/0BAAAAANel2NhYnTx5Uj/++GOuZZs3b1Z2draaNWtWqH3kXBFwNVWqVJHValXt2rVVv3591a9fX6mpqYqOjra/znlOgLsQ/AEAAAAA16V77rlHdevWVf/+/bVo0SJt27ZNW7du1euvv66xY8eqY8eOio6OLtQ+goODdfToUW3dulUXLlzIc86BAwcUGRnp8Lp27dqF2q8rEfwBAAAAANclX19fLVu2TA8++KDeffdd9e/fX4MHD9bmzZs1bNgwTZs2rdD7eOSRR+Tr66u+ffvqm2++yXPO/v377cH/3LlzOnPmjMMHAe7GPf4AAAAAgOtWUFCQhg8fruHDh//j3C+++CLXWNeuXdW1a1f76xdffFGXL1+2v27WrJm+/PLLa273s88+s/9evnx5HThwID+lFxvO+AMAAAAAYGIEfwAAAAAATIzgDwAAAACAiRH8AQAAAAAwMYI/AAAAAAAmRvAHAAAAAMDECP4AAAAAAJgYwR8AAAAAABMj+AMAAAAAYGIEfwAAAAAATIzgDwAAAABAIdlsNs2ePVstW7ZUo0aN1LdvXx0/ftzdZUki+AMAAAAAUGhz587VihUrNGnSJK1atUo2m019+vRRRkaGu0sj+AMAAAAAUBgZGRlatGiR4uPj1bp1a0VGRmrmzJlKTk7Wpk2b3F2efNxdAAAAAAAAf2UYhi6nWd2yb19/52Py/v379eeffyouLs4+FhwcrDp16mjHjh3q2LGjK0t0GsEfAAAAAOAxDMPQ0JbPad/3B9yy/zq3RuiFT552ap3k5GRJUqVKlRzGQ0JC7MvciUv9AQAAAAAexWJxdwXOSU9PlyT5+fk5jPv7+8tqdc+VC3/FGX8AAAAAgMewWCya+c0kt17q72xYDwgIkHTlXv+c3yXJarUqMDDQpfUVBMEfAAAAAOBRLBaLAksF/PPEIpCdne30OjmX+KekpKhq1ar28ZSUFEVERListoLiUn8AAAAAAAohMjJSpUuX1rZt2+xjFy9e1L59+xQTE+PGyq7gjD8AAAAAAIXg5+en7t27a/r06SpfvrwqV66sadOmKSwsTO3bt3d3eQR/AAAAAAAKKz4+XllZWXr22Wd1+fJlxcTEaOHChfL19XV3aQR/AAAAAAAKy9vbW6NGjdKoUaPcXUou3OMPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJXRfB32azafbs2WrZsqUaNWqkvn376vjx41edf/78eY0YMUIxMTGKjY3VhAkTlJ6enufcjIwMderUSU8//XRRlQ8AAAAAMLnU1FSNGzdOrVq1UnR0tB566CElJCS4uyxJ10nwnzt3rlasWKFJkyZp1apVstls6tOnjzIyMvKcHx8fr6SkJL3zzjt69dVX9fXXX2v8+PF5zn355Zd18ODBIqweAAAAAGB2w4cP1+7du/XKK69o7dq1ql27tnr37q0jR464uzTPD/4ZGRlatGiR4uPj1bp1a0VGRmrmzJlKTk7Wpk2bcs3fvXu3tm/frqlTp6pu3bqKi4vTxIkTtX79ep0+fdph7rfffquNGzfqlltuKa7DAQAAAACYTFJSkr777juNHz9eTZo0UfXq1fXcc88pJCREH330kbvL8/zgv3//fv3555+Ki4uzjwUHB6tOnTrasWNHrvkJCQmqWLGiatasaR+LjY2VxWLRzp077WPnzp3TmDFjNGnSJJUrV65oDwIAAAAAYFrlypXTm2++qfr169vHLBaLLBaLLl686MbKrvBxdwH/JDk5WZJUqVIlh/GQkBD7sr86ffp0rrl+fn4qW7asTp06ZR8bO3as2rRpo7Zt2+rtt98udJ2GYSgtLa3Q2ylqOc86uNozDwB3o0fh6ehReDp6FJ6OHsVfWa1W2Ww2ZWdnKzs72z5uGIaslzPdUpOfv4+9hr/WdC2lSpVSixYtJMm+zqZNm5SUlKSnn34639v5u+zsbNlsNqWnp8tmszksMwxDFoslX9vx+OCf8xeCn5+fw7i/v78uXLiQ5/y/z82Zb7VaJUmrVq3S4cOHNWPGDJfVmZmZqcTERJdtr6gdO3bM3SUA10SPwtPRo/B09Cg8HT2KHD4+PvasJl0JtGMHLteBvb+5pZ7IBpU1ee4jDjU566efftLYsWPVtm1bNW3aVJcvXy7QdqxWq7Kysq76nIC8sm9ePD74BwQESLpyr3/O79KVNyAwMDDP+Xk99M9qtSooKEhHjhzRtGnTtHDhQgUFBbmsTl9fX9WqVctl2ysq6enpOnbsmKpVq5bn+we4Gz0KT0ePwtPRo/B09Cj+ymq16uTJk/L397fnPcMw5O3lvrvSvSxX9u3v75/vM+p/9fnnn2v06NGKiorSjBkz5O/vX6h6fHx8VLVq1VzbOXToUP63UagKikHOZfspKSmqWrWqfTwlJUURERG55oeFhWnz5s0OYxkZGUpNTVVISIg2bNigP//8Uz179rQvv3z5snbt2qVPP/1Uu3fvLlCdFovFpR8kFLXAwMDrql6UPPQoPB09Ck9Hj8LT0aOQJC8vL3l5ecnb21ve3t728Rnv9HHbpf4+vl6yWq2yWCwONeXHsmXL9MILL+iuu+7S1KlT831G/mq8vb3l5eWlwMBAhxPhkpz6UMLjg39kZKRKly6tbdu22YP/xYsXtW/fPnXv3j3X/JiYGE2fPl1JSUm6+eabJUnbt2+XJDVu3Fi33nqrOnXq5LDOyJEjFRYWppEjRxbx0QAAAAAA/onFYlFAYOFCc0EV9H78nK+gf/TRRzV27NgCXS1QVDw++Pv5+al79+6aPn26ypcvr8qVK2vatGkKCwtT+/btlZ2drXPnzqlMmTIKCAhQw4YNFR0drWHDhmn8+PFKS0vTuHHj1LlzZ4WGhkqSypYt67CPgIAAlSpVyv5BAQAAAAAA+XX06FG9+OKLuuOOO9S/f3+dPXvWviwgIEBlypRxY3XXQfCXpPj4eGVlZenZZ5/V5cuXFRMTo4ULF8rX11cnTpzQ7bffrilTpqhr166yWCyaM2eOJkyYoB49esjf31933XWXxowZ4+7DAAAAAACY0KeffqrMzEx99tln+uyzzxyWdenSRS+99JKbKrviugj+3t7eGjVqlEaNGpVrWZUqVXTgwAGHsQoVKmj27Nn53v7SpUsLXSMAAAAAoGQaMGCABgwY4O4yrsp9j0oEAAAAAABFjuAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJ+bi7AAAAAAAArnenT59Wq1atco1PmTJFXbt2dUNF/4fgDwAAAABAIe3fv1/+/v7avHmzLBaLfbxMmTJurOoKgj8AAAAAAIV08OBBVatWTSEhIe4uJRfu8QcAAAAAoJAOHDigmjVruruMPHHGHwAAAADgUQzD0OWMLLfs29fb8s+T8nDw4EGVK1dOjzzyiI4ePaqbb75ZAwcOzPO+/+JG8AcAAAAAeAzDMNRr+mr9dOSUW/bfsEYlvTawo1PrZGVl6ciRI6pVq5aefvpplS5dWv/973/Vr18/vf3224qLiyuiavOH4A8AAAAA8Ch/fTje9cDHx0fbtm2Tt7e3AgICJEn16tXTL7/8ooULFxL8AQAAAADIYbFYtHDEA2691N9qtTq9XqlSpXKN3XLLLdqyZYsryioUgj8AAAAAwKNYLBYF+vu6Zd/Z2dlOr/PLL7/owQcf1BtvvKGmTZvax//3v/+pVq1ariyvQHiqPwAAAAAAhVCzZk3VqFFDEydOVEJCgg4fPqwpU6boxx9/1MCBA91dHmf8AQAAAAAoDC8vL82bN08zZszQ0KFDdfHiRdWpU0dvv/22wsPD3V0ewR8AAAAAgMK68cYbNWXKFHeXkScu9QcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmJiPuwsAAAAAAOB6tm3bNj322GN5LqtSpYo+//zzYq7IEcEfAAAAAIBCiIqK0pYtWxzGfvzxRz3xxBMaNGiQm6r6PwR/AAAAAAAKwc/PTxUrVrS/TktL05QpU9SlSxd169bNjZVdQfAHAAAAAHgUwzCUnpnlln37eVkKvY158+YpPT1dTz31lAsqKjyCPwAAAADAYxiGoQeXr9au3065Zf/RlStpUeeOBV7/3LlzeueddzRixAiVLVvWdYUVAk/1BwAAAAB4FIsKf9bdXVasWKEyZcrowQcfdHcpdpzxBwAAAAB4DIvFolWPPODWS/2tVmuB11+3bp06d+6sgIAAF1ZVOAR/AAAAAIBHsVgsCvLzdcu+s7OzC7zu/v37dfz4cXXq1MmFFRUel/oDAAAAAOACCQkJqlChgiIjI91digOCPwAAAAAALrBv3z5FRES4u4xcCP4AAAAAALjAmTNnPOZJ/n/FPf4AAAAAALjAW2+95e4S8sQZfwAAAAAATIzgDwAAAACAiRH8AQAAAAAwMYI/AAAAAAAmRvAHAAAAAMDECP4AAAAAAJgYwR8AAAAAABMj+AMAAAAAYGIEfwAAAAAATIzgDwAAAACAC82fP1+PPvqow1hiYqK6d++uRo0aqW3btlqyZEmx1UPwBwAAAADARZYvX65Zs2Y5jJ0/f149e/ZU1apVtXbtWg0ePFjTp0/X2rVri6Umn2LZCwAAAAAAJnb69Gk9//zz2rZtm6pVq+awbM2aNfL19dXEiRPl4+OjmjVrKikpSW+++aa6detW5LVxxh8AAAAAgEL6+eef5evrqw8//FANGzZ0WJaQkKDY2Fj5+PzfufdmzZrp2LFjOnv2bJHXxhl/AAAAAIBHMQxDl7Mz3bJv3wKeH2/btq3atm2b57Lk5GSFh4c7jIWEhEiSTp06pRtvvLFA+8wvgj8AAAAAwGMYhqG+2+ZrT+qvbtl/g7JVNated5du8/Lly/Lz83MY8/f3lyRZrVaX7isvXOoPAAAAAPAoFlncXYJLBQQEKCMjw2EsJ/AHBQUV+f454w8AAAAA8BgWi0VvNu3n1kv9XX0WPiwsTCkpKQ5jOa9DQ0Nduq+8EPwBAAAAAB7FYrEo0MfvnycWgezsbJdvMyYmRqtWrVJ2dra8vb0lST/88IOqV6+uChUquHx/f8el/gAAAAAAFKFu3brp0qVLGjt2rA4dOqT3339f77zzjvr3718s+yf4AwAAAABQhCpUqKAFCxbo6NGj6tKli+bMmaPRo0erS5cuxbJ/LvUHAAAAAMCFXnrppVxjDRo00OrVq91QDWf8AQAAAAAwNYI/AAAAAAAmRvAHAAAAAMDECP4AAAAAAJgYwR8AAAAAABMj+AMAAAAAYGIEfwAAAAAATOy6CP42m02zZ89Wy5Yt1ahRI/Xt21fHjx+/6vzz589rxIgRiomJUWxsrCZMmKD09HSH7S1YsEB33nmnGjVqpA4dOujdd98tjkMBAAAAAKBYXRfBf+7cuVqxYoUmTZqkVatWyWazqU+fPsrIyMhzfnx8vJKSkvTOO+/o1Vdf1ddff63x48fbl8+fP1/z58/Xk08+qQ8//FCPPfaYxo8fr3Xr1hXPAQEAAAAAUEw8PvhnZGRo0aJFio+PV+vWrRUZGamZM2cqOTlZmzZtyjV/9+7d2r59u6ZOnaq6desqLi5OEydO1Pr163X69GlJ0sqVK9WrVy/dc889qlq1qh588EHdd999nPUHAAAAAJiOxwf//fv3688//1RcXJx9LDg4WHXq1NGOHTtyzU9ISFDFihVVs2ZN+1hsbKwsFot27twpm82mqVOnqkuXLg7reXl56eLFi0V3IAAAAACAEmH+/Pl69NFHHca++OILdevWTVFRUWrbtq2mTp2qy5cvF0s9PsWyl0JITk6WJFWqVMlhPCQkxL7sr06fPp1rrp+fn8qWLatTp07Jy8vL4UMESTp58qT++9//6j//+U+B6zQMQ2lpaQVev7jkPOvgr888ADwJPQpPR4/C09Gj8HT0KP7KarXKZrMpOztb2dnZ7i5H0pVsl/NnQWpauXKlZs2apcaNG9vXT0hI0JAhQzRkyBC9/PLL+vXXXzV+/HidP39eL7zwwlW3lZ2dLZvNpvT0dNlstlx1WiyWfNXk8cE/5y8EPz8/h3F/f39duHAhz/l/n5sz32q15ho/e/as+vbtqwoVKmjgwIEFrjMzM1OJiYkFXr+4HTt2zN0lANdEj8LT0aPwdPQoPB09ihw+Pj55ZjV3c7amM2fOaPLkyUpISFDVqlVls9nsZ/RXrlypJk2aqEePHpKksLAwDRo0SBMnTtRTTz2VZ4bNqSErK0tHjhzJc/nV1vs7jw/+AQEBkq7c65/zu3TlDQgMDMxzfl4P/bNarQoKCnIYO3LkiPr166fs7GwtWbJEwcHBBa7T19dXtWrVKvD6xSU9PV3Hjh1TtWrV8nz/AHejR+Hp6FF4OnoUno4exV9ZrVadPHlS/v7+DnnPMAxlGu75MMBHfsrIyJC/v3++z6hL0qFDhxQQEKB169bpjTfe0G+//WY/pt69e8vLy8vhGP39/ZWVlaXs7GyH8Vz1+PioatWq8vf3z7W//B+Th8u5bD8lJUVVq1a1j6ekpCgiIiLX/LCwMG3evNlhLCMjQ6mpqQoJCbGP7dy5UwMHDlRoaKgWLFig0NDQQtVpsVhyfbDgyQIDA6+relHy0KPwdPQoPB09Ck9Hj0K68qw1Ly8veXt7y9vbW9KV0P/m4Wf0a9oBt9RUNShCj4SNlcVisdeUH+3atVO7du0kXcmHf12/fv36DnMzMzO1ZMkS1atXTzfeeONVt+nt7S0vLy8FBgbm+nDAmQ8lPP7hfpGRkSpdurS2bdtmH7t48aL27dunmJiYXPNjYmKUnJyspKQk+9j27dslSY0bN5Yk7dmzR3369NEtt9yi5cuXFzr0AwAAAABcx6L8h9rrTVZWlkaPHq1ffvlFzz//fLHs0+PP+Pv5+al79+6aPn26ypcvr8qVK2vatGkKCwtT+/btlZ2drXPnzqlMmTIKCAhQw4YNFR0drWHDhmn8+PFKS0vTuHHj1LlzZ4WGhiorK0sjR45UhQoV9NJLL8lqterMmTOSrnyaUr58eTcfMQAAAACUXBaLRX1rvuC2S/29bEX3zIFLly5p6NCh2r59u+bMmaMGDRoUyX7+zuODvyTFx8crKytLzz77rC5fvqyYmBgtXLhQvr6+OnHihG6//XZNmTJFXbt2lcVi0Zw5czRhwgT16NFD/v7+uuuuuzRmzBhJV87251wNkHMZRo7KlSvriy++KPbjAwAAAAD8H4vFIj/L1e97L0rZRtF8u0BKSor69u2r3377TQsXLszzCvaicl0Ef29vb40aNUqjRo3KtaxKlSo6cMDx3o8KFSpo9uzZeW4rOjo613wAAAAAAIrKhQsX1KNHD126dEnLly/P83l1Rem6CP4AAAAAAFyvpkyZouPHj2vBggUqX768/XZzSSpfvrxTDxEsCII/AAAAAABFJDs7Wxs2bFBmZqZ69OiRa/nnn3+uKlWqFGkNBH8AAAAAAFzopZdesv/u7e2tPXv2uLGa6+Dr/AAAAAAAQMER/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxAj+AAAAAACYGMEfAAAAAAATI/gDAAAAAGBiPgVdMS0tTadOndKlS5dUrlw5hYaGyt/f35W1AQAAAACAQnIq+GdkZOi9997TRx99pL179yo7O9u+zNvbW02aNNHdd9+tLl26yM/Pz+XFAgAAAAAA5+Q7+L///vuaMWOGrFar2rRpo7vvvluVK1dWUFCQLly4oOTkZO3atUuvvPKK5syZo/j4eP373/8uytoBAAAAAMA/yFfw79+/v86cOaNx48apTZs2Vz2b//jjjysjI0MbNmzQ22+/rU2bNumtt95yacEAAAAAAHiy+fPna8uWLVq6dKl97Nlnn9W7777rMK9y5cr64osviryefAX/9u3bq1u3bvnaoJ+fnzp37qz77rtP7733XqGKAwAAAADgerJ8+XLNmjVLTZo0cRg/cOCABgwYoO7du9vHvL29i6WmfAX//Ib+v7JYLFzqDwAAAAAoEU6fPq3nn39e27ZtU7Vq1RyWGYahQ4cOqV+/fqpYsWKx11agp/rbbDYdOnRIFy9elGEYuZbHxMQUujAAAAAAQMlkGIZkpLtp5wV7UP3PP/8sX19fffjhh3r99df122+/2Zf9+uuvSktLU40aNVxVpVOcDv579+7VwIED9fvvv+daZhiGLBaLEhMTXVIcAAAAAKBkMQxDxrmHpMxd7inAJ1oKWOD0am3btlXbtm3zXHbw4EFJ0tKlS/XNN9/Iy8tLrVq10rBhw1SmTJlClZsfTgf/F154QX5+fpo0aZKqVKkiLy+voqgLAAAAAABTOHjwoLy8vBQSEqJ58+bp119/1csvv6xffvlFixcvLvJc7XTwT0xM1PTp03XHHXcURT0AAAAAgBLMYrFI5Ve67VJ/w+YnWa0u3ebAgQP18MMPq1y5cpKk8PBwVaxYUQ888ID27t2rhg0bunR/f+d08C9fvrx8fX2LohYAAAAAAK6Ef0uQe3ZuZLt8k15eXvbQn+OWW26RJCUnJxd58Hf6eoJHHnlE8+bN0x9//FEU9QAAAAAAYCqjR4/W448/7jC2d+9eSVKtWrWKfP/5OuP/2GOP2X83DEN79uxRq1atVKtWLQUGBjrMtVgsWrx4sWurBAAAAADgOnXnnXdq0KBBmjNnju69914dPXpUEydOVMeOHVWzZs0i33++gv/fv7KvcePGV12W19f7AQAAAABQUt1+++2aNWuW3nzzTb311lsqU6aMOnXqpKFDhxbL/vMV/JcuXVrUdQAAAAAAYAovvfRSrrG7775bd999txuqyec9/j179tTChQu1f//+oq4HAAAAAAC4UL7O+J89e1bTp0/X9OnTVa5cOcXFxal58+Zq3ry5QkNDi7pGAAAAAABQQPkK/h999JEuXLigHTt2aOfOnUpISNCnn36q7Oxs1ahRQ7feequaN2+upk2b5nrYHwAAAAAAcJ98BX9JuuGGG9SuXTu1a9dOkpSWlqbdu3dr586d2rFjh9577z1lZWWpUaNGPBMAAAAAAAAPke/g/3dBQUGKiYmRt7e3vLy8VKpUKW3ZskW7d+92ZX0AAAAAAKAQnA7+Bw8e1Lfffqtvv/1Wu3btUmZmpipXrqzmzZtr5syZiouLK4o6AQAAAAAmxdfC581V70u+gv/GjRv17bffasuWLUpJSVHp0qXVtGlTPf3002rRooWqVq3qkmIAAAAAACWHr6+vpCu3kvO8uNzS0tIk/d/7VFD5Cv7Dhg1TuXLl9OCDD6pFixaKioqSt7d3oXYMAAAAACjZvL29VbZsWaWkpEi6cku5xWJxa03Z2dmyWq2S5LbcaxiG0tLSlJKSorJlyxa6jnwF/1q1aunQoUNaunSpDhw4oJYtW6ply5a66aabCrVzAAAAAEDJFhYWJkn28O9uNptNWVlZ8vHxkZeXl1trKVu2rP39KYx8Bf+PP/5Yp0+ftt/bP2vWLE2aNElVqlRRixYt1LJlSzVt2lSlSpUqdEEAAAAAgJLDYrGoUqVKCgkJUWZmprvLUXp6uo4cOaKqVau69fYDX19fl11xkO+H+4WGhur+++/X/fffL5vNph9//FFbtmzRli1btHr1anl5eSkqKkotW7ZUv379XFIcAAAAAKBk8Pb29ohbym02myTJ399fAQEBbq7GNQp03YKXl5eio6MVHx+vNWvW6P3331fHjh31448/aubMma6uEQAAAAAAFJDTX+eXlZWlffv2adeuXfaf33//XWXLllW7du34Oj8AAAAAADxIvoL/V199pd27d2vXrl3au3evrFarAgICFBMTo969eysuLk6RkZFFXSsAAAAAAHBSvoL/gAED5OPjowYNGqhPnz5q1qyZGjVqJB8fpy8YAAAAAAAAxShfyX3+/PmKiYlRUFBQUdcDAAAAAABcKF/B/5ZbblFqaqpSU1PztdF//etfhakJAAAAAAC4SL6C/+233+7URhMTEwtUDAAAAAAAcK18BX/DMCRJderU0V133aWKFSsWaVEAAAAAAMA18hX8N2zYYP959dVXFRsbqw4dOujOO+9UmTJlirpGAAAAAABQQF75mVSjRg0NGTJEGzZs0Nq1a1W/fn3NmzdPzZs318CBA7VhwwZdvny5qGsFAAAAAABOylfw/6vIyEgNHz5cmzdv1tKlS1W1alW9/PLLiouL04gRI/TFF18URZ0AAAAAAKAAnA7+f9WwYUONGTNGmzdvVu/evfXpp59q8ODBrqoNAAAAAAAUUr7u8c+LzWbTDz/8oE8++USfffaZzp8/r/r16+uee+5xZX0AAAAAAKAQnAr+eYX92rVrq2fPnrr77rt10003FVWdAAAAAACgAPIV/L///nt72E9NTVWtWrX06KOP6p577lG1atWKuEQAAAAAAFBQ+Qr+vXr1kre3t6Kjo3X33XfrlltukSSdOXNGZ86cyTU/JibGtVUCAAAAAIACyfel/tnZ2dqxY4cSEhIcxg3DkCRZLBYZhiGLxaLExETXVgkAAAAAAAokX8F/yZIlRV0HAAAAAAAoAvkK/rGxsUVdBwAAAAAAKAJe+Zk0evRonT171qkNJycna8SIEQUqCgAAAAAAuEa+gn9kZKQ6dOigyZMna8+ePdecu2fPHo0dO1adOnVS7dq1XVIkAAAAAAAomHw/1f+2227T9OnT9eCDDyokJET169dXlSpVFBgYqD/++EOnTp3S7t27df78ebVu3VrLly9XeHh4UdcPAAAAAACuId9P9a9Zs6beeOMNHTx4UB999JG2bdumnTt36o8//lC5cuVUuXJlPfTQQ2rfvr0iIiKKsmYAAAAAAJBP+Q7+OcLDw7l3HwAAAACA60S+7vEHAAAAAADXJ4I/AAAAAAAmRvAHAAAAAMDECP4AAAAAAJgYwR8AAAAAABNz+qn+kmQYhhITE5WWlibDMHItj4mJKXRhAAAAAACg8JwO/nv27NGTTz6p5OTkXMsMw5DFYlFiYqJLigMAAAAAAIXjdPCfMmWKfHx8NGXKFIWFhcnLi7sFAAAAAADwVE4H/59//lmvvPKK2rVrVxT1AAAAAAAAF3L6dH2FChXk7e1dFLUAAAAAAAAXczr4P/zww5o/f77S0tKKoh4AAAAAAOBCTl/qn5SUpMOHD6t58+a65ZZbFBAQ4LDcYrFo8eLFLisQAAAAAAAUnNNn/JOSkhQZGal69erJ399fhmE4/NhsNpcXabPZNHv2bLVs2VKNGjVS3759dfz48avOP3/+vEaMGKGYmBjFxsZqwoQJSk9Pd5izceNG3XPPPWrQoIE6d+6srVu3urxuAAAAAADczekz/kuXLi2KOq5p7ty5WrFihV566SWFhYVp2rRp6tOnjz766CP5+fnlmh8fH6/09HS98847unjxosaOHau0tDRNnTpVkvTDDz9o1KhRGj16tJo3b6733ntP/fr107p161SzZs3iPjwAAAAAAIpMgb+L7/Dhw1q5cqXefPNNvfvuuzpy5Igr67LLyMjQokWLFB8fr9atWysyMlIzZ85UcnKyNm3alGv+7t27tX37dk2dOlV169ZVXFycJk6cqPXr1+v06dOSpLfeekvt2rXTY489ppo1a+qpp55S3bp1uUUBAAAAAGA6Tp/xNwxDzz//vN59910ZhmEft1gs6tKli1588UWXFrh//379+eefiouLs48FBwerTp062rFjhzp27OgwPyEhQRUrVnQ4cx8bGyuLxaKdO3fqrrvu0q5du/T00087rNe0adM8P0gwmwsXUrXlyA86+Mchefnx7QzwPLaMbKWcOUuPwmPRo/B09Cg8HT0KT2fLyFaY143uLsOlnA7+CxYs0Nq1axUfH697771XFStWVEpKitavX6833nhD4eHhevzxx11WYHJysiSpUqVKDuMhISH2ZX91+vTpXHP9/PxUtmxZnTp1ShcvXlRaWprCwsLytb38MgzD47/p4MKFVAUat+mJlhZ3lwJcW6S7CwD+AT0KT0ePwtPRo/BwF22Gkk9/orDQSv882U0Mw5DFkr9s53Twf++999SnTx8NHDjQPlalShUNHjxYmZmZWrNmjUuDf85D+f5+L7+/v78uXLiQ5/y87vv39/eX1WrV5cuXr7o9q9Va4DozMzOVmJhY4PWLw8U/UxVVy91VAAAAAIDnSzp+TOfPpbq7jGvKK/vmxengf+rUKTVr1izPZU2bNtWiRYuc3eQ15XxdYEZGhsNXB1qtVgUGBuY5PyMjI9e41WpVUFCQ/P397dv7+/K8tpdfvr6+qlXL81N18ulPtDjhE5Ure4N8fX3dXQ6QS2Zmps6nXqBH4bHoUXg6ehSejh6Fp8vMzNRN/pXUoG6jQmXEonbo0KF8z3U6+FeuXFkHDhxwuOc+x/79+1W+fHlnN3lNOZftp6SkqGrVqvbxlJQURURE5JofFhamzZs3O4xlZGQoNTVVISEhKlu2rIKCgpSSkuIwJyUlRaGhoQWu02KxKCgoqMDrF5ew0EpqUaOZateufV3Ui5InLS1NiYmJ9Cg8Fj0KT0ePwtPRo/B0OT0aGBjo0T2a38v8pQI81b9jx4567bXXtHHjRvvD/QzD0IYNGzRnzhzdc889zm7ymiIjI1W6dGlt27bNPnbx4kXt27dPMTExuebHxMQoOTlZSUlJ9rHt27dLkho3biyLxaLo6Gj7WI5t27apSZMmLq0dAAAAAAB3c/qMf9++fZWQkKBhw4Zp1KhRKleunM6fP6/s7GzFxsbqySefdGmBfn5+6t69u6ZPn67y5curcuXKmjZtmsLCwtS+fXtlZ2fr3LlzKlOmjAICAtSwYUNFR0dr2LBhGj9+vNLS0jRu3Dh17tzZfka/Z8+e6tevn+rUqaNWrVpp7dq1SkxM1AsvvODS2gEAAAAAcDeng7+fn5/efvttff3119q+fbsuXryoG264QTExMbrtttuKokbFx8crKytLzz77rC5fvqyYmBgtXLhQvr6+OnHihG6//XZNmTJFXbt2lcVi0Zw5czRhwgT16NFD/v7+uuuuuzRmzBj79lq0aKEXX3xRc+fO1cyZM1WrVi3NmzfP4SsAAQAAAAAwA6eDf47bbrutyIL+33l7e2vUqFEaNWpUrmVVqlTRgQMHHMYqVKig2bNnX3ObnTt3VufOnV1ZJgAAAAAAHidfwf+xxx7T888/r5o1a+qxxx675lyLxaLFixe7pDgAAAAAAFA4+Qr+OQ/x+/vv/zQXAAAAAAC4V76C/9KlS/P8HQAAAAAAeDanv87vscce0+HDh/Nctn//fnXq1KnQRQEAAAAAANfI1xn/hIQE+yX827dv144dO3Tu3Llc87788ksdP37ctRUCAAAAAIACy1fwf/fdd7V+/XpZLBZZLBZNmDAh15ycDwY6duzo2goBAAAAAECB5Sv4P/vss+rWrZsMw1CPHj00btw41apVy2GOl5eXgoODdcsttxRJoQAAAAAAwHn5Cv5lypRRbGysJGnJkiWqU6eOSpcuXaSFAQAAAACAwstX8P+r2NhYnT59Wt98840yMjLs4zabTenp6UpISNDMmTNdWiQAAAAAACgYp4P/J598opEjRyorK0sWi0XSlfv7c36vUaOGaysEAAAAAAAF5vTX+c2bN09169bV+++/r65du+q+++7Tf//7X40aNUre3t565plniqJOAAAAAABQAE6f8T969KhmzJihOnXqqGnTplq0aJFq1qypmjVr6uzZs5o3b56aN29eFLUCAAAAAAAnOX3G38vLSzfccIMk6eabb9aRI0dks9kkSa1atdKhQ4dcWyEAAAAAACgwp4N/jRo1tGvXLvvvGRkZ2r9/vyTp4sWLDg/8AwAAAAAA7uX0pf7/+c9/9PzzzystLU3Dhg1Ts2bNNGbMGN1///1atmyZ6tatWxR1AgAAAACAAnD6jP+///1vjR071n5mf9KkSbJarXrhhReUlZWlsWPHurxIAAAAAABQME6f8d+6dau6deumgIAASdJNN92kjRs36vz58ypfvrzLCwQAAAAAAAXn9Bn/J554Qps2bXIYs1gshH4AAAAAADyQ08E/ODjYfrYfAAAAAAB4Nqcv9e/fv78mT56so0ePKjIyUkFBQbnmxMTEuKQ4AAAAAABQOE4H/+eff16SNHPmTElXLvPPYRiGLBaLEhMTXVQeAAAAAAAoDKeD/5IlS4qiDgAAAAAAUAScDv6xsbFFUQcAAAAAACgCTgd/STp37pwWLlyo77//XmfOnNGCBQu0efNmRUZGql27dq6uEQAAAAAAFJDTT/U/fvy47r33Xq1Zs0ahoaH6/ffflZ2draNHjyo+Pl5fffVVEZQJAAAAAAAKwukz/lOnTlWFChW0dOlSBQUFqV69epKkGTNmyGq1at68eWrdurWr6wQAAAAAAAXg9Bn/rVu3atCgQQoODnZ4or8kPfjgg/rll19cVhwAAAAAACgcp4O/JPn45H2hQEZGRq4PAwAAAAAAgPs4HfybNGmi+fPnKy0tzT5msVhks9m0cuVKRUdHu7RAAAAAAABQcE7f4z9ixAg99NBDat++vZo2bSqLxaKFCxfq8OHDSkpK0ooVK4qiTgAAAAAAUABOn/EPDw/X2rVr1bRpU23btk3e3t76/vvvVbVqVa1atUq1a9cuijoBAAAAAEABOH3GX5KqVaumGTNmuLoWAAAAAADgYgUK/oZhKDExUWlpaTIMI9fymJiYQhcGAAAAAAAKz+ngv2fPHj355JNKTk6WJHvwt1gsMgxDFotFiYmJrq0SAAAAAAAUiNPBf8qUKfLx8dGUKVMUFhYmL68CfSMgAAAAAAAoBk4H/59//lmvvPKK2rVrVxT1AAAAAAAAF3L6dH2FChXk7e1dFLUAAAAAAAAXczr4P/zww5o/f77S0tKKoh4AAAAAAOBCTl/qn5SUpMOHD6t58+a65ZZbFBAQ4LDcYrFo8eLFLisQAAAAAAAUXIGCf2RkpP3137/OL6+v9wMAAAAAAO7hdPBfunRpUdQBAAAAAACKgNPBP8eFCxeUkJCglJQU3XnnnUpNTVX16tVlsVhcWR8AAAAAACiEAgX/N954Q/Pnz9fly5dlsVjUoEEDzZo1S+fPn9eiRYsUHBzs6joBAAAAAEABOP1U/2XLlum1115Tz549tWbNGvs9/d27d9fx48f16quvurxIAAAAAABQME4H/6VLl6pfv3568sknVbduXfv4bbfdpqFDh+qLL75waYEAAAAAAKDgnA7+J0+eVGxsbJ7LatSoobNnzxa6KAAAAAAA4BpOB/9KlSpp9+7deS773//+p0qVKhW6KAAAAAAA4BpOP9zv/vvv12uvvaaAgAC1bt1akpSWlqZPP/1U8+fPV8+ePV1dIwAAAAAAKCCng3/fvn114sQJTZ8+XdOnT5ckPfbYY5KkTp06qX///q6tEAAAAAAAFJjTwd9isWjixInq1auXtm7dqgsXLqhMmTKKiYlReHh4UdQIAAAAAAAKyOngn6NatWqqVq2aC0sBAAAAAACu5lTw37hxoyTp7rvvls1m0x133OGwvFOnTho6dKjLigMAAAAAAIWTr6f6Z2dna/DgwRo+fLi++eYbSZJhGPrtt990yy23KDY2VmFhYVqwYIF+/fXXIi0YAAAAAADkX77O+K9Zs0bffPONXn31VbVv395h2RNPPKG6devq8uXLuvPOO7Vq1SqNHj26SIoFAAAAAADOydcZ//Xr1+vBBx/MFfr/KiAgQN26ddN3333nsuIAAAAAAEDh5Cv4Hzp0SK1atfrHedHR0VzqDwAAAACAB8nXpf5ZWVkKDAx0GPP29tamTZsUFhbmMOblla/PEgAAAAAAQDHIV0oPDQ3V0aNHc41XrVpVfn5+9tcHDx7Uv/71L9dVBwAAAAAACiVfwb9FixZavXq1bDbbVedkZmbqvffeU5s2bVxWHAAAAAAAKJx8Bf9HHnlEhw8f1tChQ3X+/Plcy9PS0vTUU0/p1KlTeuihh1xeJAAAAAAAKJh83eNfo0YNvfjii3rmmWd0++23Ky4uTtWqVZMk/fbbb9qyZYuysrL08ssvq1KlSkVZLwAAAAAAcEK+gr8k3XPPPYqMjNRbb72lL774Qp9//rkkKTAwUG3btlX//v0VHh5eZIUCAAAAAADn5Tv4S1fO/E+ZMkWSdPHiRdlsNpUtW7Yo6gIAAAAAAC7gVPD/q+DgYFfWAQAAAAAAikC+Hu4HAAAAAACuTwR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAE7sugr/VatWECRMUFxenqKgojRgxQufOnbvmOidOnFD//v0VHR2tFi1aaNasWcrOzrYvv3z5smbMmKG2bdsqKipKXbt21eeff17UhwIAAAAAQLG6LoL/+PHjtWXLFr322mtavHixjhw5ovj4+KvOz8zMVO/evSVJq1at0vjx47Vy5Uq9/vrr9jmTJ0/WRx99pOeff17r1q1Tu3btNGTIEG3btq3IjwcAAAAAgOLi4+4C/snp06e1bt06zZs3T02aNJEkvfLKK7rrrru0e/duRUVF5Vrn008/1cmTJ7VmzRrdcMMNCg8P1++//66XX35ZAwYMUHZ2ttatW6cXX3xRt912myRp0KBB2rZtm9auXaumTZsW6zECAAAAAFBUPP6M/86dOyVJzZo1s49Vr15doaGh2rFjR57rJCQkqG7durrhhhvsY82aNdOlS5eUmJgoi8WiefPmqVWrVg7reXl56eLFi0VwFAAAAAAAuMd1cca/XLly8vf3dxgPCQlRcnJynuskJycrLCws13xJOnXqlBo2bKgWLVo4LN+zZ49++OEHPfvsswWq0zAMpaWlFWjd4pSenu7wJ+Bp6FF4OnoUno4ehaejR+HprpceNQxDFoslX3PdHvxPnDih22+//arLn3zySfn5+eUa9/f3l9VqzXOdy5cvKzg4ONd8SXmuc+TIEQ0ePFgNGjTQAw884Ez5dpmZmUpMTCzQuu5w7Ngxd5cAXBM9Ck9Hj8LT0aPwdPQoPN310KN5ZeW8uD34h4aGasOGDVdd/vXXXysjIyPXuNVqVWBgYJ7rBAQE5FonJ/AHBQU5jO/atUuDBg1SWFiY5s2bJ19fX2cPQZLk6+urWrVqFWjd4pSenq5jx46pWrVqV33/AHeiR+Hp6FF4OnoUno4ehae7Xnr00KFD+Z7r9uDv6+urmjVrXnX5gQMHlJqaqoyMDIdPM1JSUhQaGprnOmFhYTp48KDDWEpKiiQ5rLNp0yaNHDlSDRs21Ny5c1WmTJkCH4fFYsn1oYInCwwMvK7qRclDj8LT0aPwdPQoPB09Ck/n6T2a38v8pevg4X6NGzeWzWazP+RPko4eParTp08rJiYmz3ViYmK0b98+Xbp0yT72ww8/qFSpUoqMjJQkffHFFxo2bJhat26thQsXFir0AwAAAADgqTw++IeGhqpDhw569tlntW3bNu3Zs0fDhw9XbGysGjVqJEnKyMjQmTNn7Jf3t2vXThUrVtTQoUO1f/9+bd68Wa+88op69eolPz8/XbhwQU899ZTq1q2rsWPH6sKFCzpz5ozOnDmj1NRU9x0sAAAAAAAu5vHBX5ImTZqkuLg4DRkyRL1791aNGjU0e/Zs+/Ldu3erRYsW2r17t6QrD/JbsGCBbDabHnjgAU2YMEEPP/ywBg0aJEn65ptvdPHiRf30009q1aqVWrRoYf954okn3HKMAAAAAAAUBbff458fQUFBmjx5siZPnpzn8qZNm+rAgQMOYzfffLMWLVqU5/xOnTqpU6dOLq8TAAAAAABPc12c8QcAAAAAAAVD8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADCx6yL4W61WTZgwQXFxcYqKitKIESN07ty5a65z4sQJ9e/fX9HR0WrRooVmzZql7OzsPOeeO3dOLVq00GuvvVYU5QMAAAAA4DbXRfAfP368tmzZotdee02LFy/WkSNHFB8ff9X5mZmZ6t27tyRp1apVGj9+vFauXKnXX389z/nPPvuszpw5UyS1AwAAAADgTj7uLuCfnD59WuvWrdO8efPUpEkTSdIrr7yiu+66S7t371ZUVFSudT799FOdPHlSa9as0Q033KDw8HD9/vvvevnllzVgwAD5+fnZ565evVrHjh1TxYoVi+2YAAAAAAAoLh5/xn/nzp2SpGbNmtnHqlevrtDQUO3YsSPPdRISElS3bl3dcMMN9rFmzZrp0qVLSkxMtI8dPXpU06dP17Rp0xw+DAAAAAAAwCyuizP+5cqVk7+/v8N4SEiIkpOT81wnOTlZYWFhueZL0qlTp9SwYUNlZmZqxIgR6t27t+rWrVvoOg3DUFpaWqG3U9TS09Md/gQ8DT0KT0ePwtPRo/B09Cg83fXSo4ZhyGKx5Guu24P/iRMndPvtt191+ZNPPpnn2Xh/f39ZrdY817l8+bKCg4NzzZdkX2f27Nny9/dX3759C1q6g8zMTIerCTzdsWPH3F0CcE30KDwdPQpPR4/C09Gj8HTXQ4/m98p1twf/0NBQbdiw4arLv/76a2VkZOQat1qtCgwMzHOdgICAXOvkBP6goCBt375dK1eu1AcffCBvb+9CVP9/fH19VatWLZdsqyilp6fr2LFjqlat2lXfP8Cd6FF4OnoUno4ehaejR+HprpcePXToUL7nuj34+/r6qmbNmlddfuDAAaWmpiojI8Ph04yUlBSFhobmuU5YWJgOHjzoMJaSkiLpygcNK1euVFpamu6991778vT0dM2fP1+ffPKJ/vvf/zp9HBaLRUFBQU6v5y6BgYHXVb0oeehReDp6FJ6OHoWno0fh6Ty9R/N7mb/kAcH/nzRu3Fg2m007d+5UXFycpCsP5Tt9+rRiYmLyXCcmJkbr1q3TpUuXVLp0aUnSDz/8oFKlSikyMlIjR47UgAEDHNZ59NFH1b59e/Xs2bNoDwgAAAAAgGLk8U/1Dw0NVYcOHfTss89q27Zt2rNnj4YPH67Y2Fg1atRIkpSRkaEzZ87YL+9v166dKlasqKFDh2r//v3avHmzXnnlFfXq1Ut+fn6qUKGCbr75ZocfHx8f3XDDDapcubIbjxYAAAAAANfy+OAvSZMmTVJcXJyGDBmi3r17q0aNGpo9e7Z9+e7du9WiRQvt3r1b0pUH+S1YsEA2m00PPPCAJkyYoIcffliDBg1y1yEAAAAAAOAWHn+pv3TlgXyTJ0/W5MmT81zetGlTHThwwGHs5ptv1qJFi/K9jy+++KJQNQIAAAAA4ImuizP+AAAAAACgYAj+AAAAAACYGMEfAAAAAAATI/gDAAAAAGBiBH8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxAj+AAAAAACYGMEfAAAAAAATI/gDAAAAAGBiBH8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxAj+AAAAAACYGMEfAAAAAAATI/gDAAAAAGBiBH8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxAj+AAAAAACYGMEfAAAAAAATI/gDAAAAAGBiBH8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxAj+AAAAAACYGMEfAAAAAAATI/gDAAAAAGBiBH8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxAj+AAAAAACYGMEfAAAAAAATI/gDAAAAAGBiBH8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGCPwAAAAAAJkbwBwAAAADAxAj+AAAAAACYGMEfAAAAAAATI/gDAAAAAGBiBH8AAAAAAEyM4A8AAAAAgIkR/AEAAAAAMDGLYRiGu4u43u3atUuGYcjPz8/dpfwjwzCUmZkpX19fWSwWd5cD5EKPwtPRo/B09Cg8HT0KT3e99GhGRoYsFouio6P/ca5PMdRjep7cDH9nsViuiw8oUHLRo/B09Cg8HT0KT0ePwtNdLz1qsVjynUU54w8AAAAAgIlxjz8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAAAICJEfwBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4m4zNZtPs2bPVsmVLNWrUSH379tXx48evOv/8+fMaMWKEYmJiFBsbqwkTJig9Pb0YK0ZJ42yP/vLLL+rXr5+aNm2quLg4xcfH6+TJk8VYMUoaZ3v0rz788ENFREToxIkTRVwlSjJnezQzM1MzZsywz+/evbsSExOLsWKUNM726O+//64RI0aoWbNmatq0qYYNG6bTp08XY8UoyebPn69HH330mnPMkJkI/iYzd+5crVixQpMmTdKqVatks9nUp08fZWRk5Dk/Pj5eSUlJeuedd/Tqq6/q66+/1vjx44u3aJQozvTo+fPn1bNnTwUEBGjp0qV66623dO7cOfXp00dWq9UN1aMkcPbv0Ry//fabJk6cWExVoiRztkfHjx+v999/Xy+++KLWrl2r8uXLq2/fvvrjjz+KuXKUFM726NChQ3Xy5Em9/fbbevvtt3Xy5EkNHjy4mKtGSbR8+XLNmjXrH+eZIjMZMA2r1WpERUUZy5cvt49duHDBaNCggfHRRx/lmr9r1y4jPDzcOHTokH3s22+/NSIiIozk5ORiqRkli7M9umbNGiMqKspIT0+3j508edIIDw83vv/++2KpGSWLsz2aIzs723jooYeMxx57zAgPDzeOHz9eHOWiBHK2R3/99VcjIiLC+PLLLx3mt2nThr9HUSSc7dELFy4Y4eHhxueff24f27x5sxEeHm6cP3++OEpGCZScnGz079/faNSokXHXXXcZ3bt3v+pcs2QmzvibyP79+/Xnn38qLi7OPhYcHKw6depox44dueYnJCSoYsWKqlmzpn0sNjZWFotFO3fuLJaaUbI426NxcXGaO3euAgIC7GNeXlf+2rp48WLRF4wSx9kezTFv3jxlZmaqf//+xVEmSjBne/S7775TmTJl1KpVK4f5X3zxhcM2AFdxtkcDAgJUqlQprVu3TpcuXdKlS5e0fv16Va9eXcHBwcVZOkqQn3/+Wb6+vvrwww/VsGHDa841S2bycXcBcJ3k5GRJUqVKlRzGQ0JC7Mv+6vTp07nm+vn5qWzZsjp16lTRFYoSy9kerVKliqpUqeIw9uabbyogIEAxMTFFVyhKLGd7VJL27NmjRYsW6b333uOeVBQ5Z3v06NGjuummm7Rp0ya9+eabOn36tOrUqaOnn37a4X9iAVdxtkf9/Pz00ksvady4cWrSpIksFotCQkK0bNky+4f9gKu1bdtWbdu2zddcs2Qm/m0ykZwHTPj5+TmM+/v753k/dHp6eq6515oPFJazPfp3S5cu1bJlyzRy5EiVL1++SGpEyeZsj6alpWnkyJEaOXKkqlWrVhwlooRztkcvXbqkpKQkzZ07V8OHD9cbb7whHx8fPfzww/r999+LpWaULM72qGEYSkxMVFRUlJYvX67FixfrX//6lwYNGqRLly4VS83AtZglMxH8TSTncui/PzjFarUqMDAwz/l5PWTFarUqKCioaIpEieZsj+YwDEOzZs3S5MmTNXDgwH988ipQUM726OTJk1W9enX95z//KZb6AGd71MfHR5cuXdLMmTPVokULNWjQQDNnzpQkffDBB0VfMEocZ3t048aNWrZsmaZNm6bGjRsrNjZW8+bN02+//ab33nuvWGoGrsUsmYngbyI5l6CkpKQ4jKekpCg0NDTX/LCwsFxzMzIylJqaqpCQkKIrFCWWsz0qXfkaqlGjRmnevHkaM2aMhg4dWtRlogRztkfXrl2r77//XlFRUYqKilLfvn0lSR07dtS8efOKvmCUOAX5b72Pj4/DZf0BAQG66aab+NpJFAlnezQhIUHVq1dX6dKl7WM33HCDqlevrqSkpKItFsgHs2Qmgr+JREZGqnTp0tq2bZt97OLFi9q3b1+e90PHxMQoOTnZ4S/V7du3S5IaN25c9AWjxHG2RyVp9OjR+uSTTzRjxgw9/vjjxVQpSipne3TTpk36+OOPtW7dOq1bt06TJ0+WdOVZFFwFgKJQkP/WZ2Vlae/evfaxy5cv6/jx47r55puLpWaULM72aFhYmJKSkhwumU5LS9OJEye4hQoewSyZiYf7mYifn5+6d++u6dOnq3z58qpcubKmTZumsLAwtW/fXtnZ2Tp37pzKlCmjgIAANWzYUNHR0Ro2bJjGjx+vtLQ0jRs3Tp07d77q2VegMJzt0ffff18bNmzQ6NGjFRsbqzNnzti3lTMHcCVne/TvwSnnwVX/+te/VLZsWTccAczO2R5t0qSJbr31Vj311FOaOHGiypYtq9mzZ8vb21v33Xefuw8HJuRsj3bu3FkLFy7U0KFD9eSTT0qSZs2aJX9/f3Xt2tXNR4OSyKyZiTP+JhMfH6/7779fzz77rB566CF5e3tr4cKF8vX11alTp9SiRQtt2LBBkmSxWDRnzhxVqVJFPXr00NChQ9WqVSuNHz/evQcBU3OmRz/++GNJ0ssvv6wWLVo4/OTMAVzNmR4F3MHZHn3ttdcUGxurIUOG6P7779elS5e0ZMkSHpKKIuNMj4aEhGjFihUyDEM9evRQz5495evrqxUrVqhMmTJuPhKURGbNTBbDMAx3FwEAAAAAAIoGZ/wBAAAAADAxgj8AAAAAACZG8AcAAAAAwMQI/gAAAAAAmBjBHwAAAAAAEyP4AwAAAABgYgR/AAAAAABMjOAPAAAKZcyYMYqIiNCWLVvyXP7tt98qIiJC06dPL+bKAACAJFkMwzDcXQQAALh+Xbx4UR06dJCvr68+/vhjBQUF2ZddunRJnTp1UpkyZfTee+/Jz8/PjZUCAFAyccYfAAAUSnBwsCZMmKDffvtNM2fOdFg2Y8YMnTlzRi+//DKhHwAANyH4AwCAQmvbtq06deqkZcuW6aeffpIk7dy5UytXrlR8fLwiIyN18uRJDR8+XLGxsWrYsKF69Oihffv2OWznxIkTGj16tFq0aKG6desqLi5Oo0eP1vnz5x329eKLL6pHjx5q0KCBxo4dW6zHCgDA9YZL/QEAgEukpqaqQ4cOqlSpklasWKFu3bqpVKlSWr58uS5cuKDOnTsrMDBQQ4YMUWBgoBYvXqz//e9/eu+991SzZk2lp6erQ4cOKleunAYMGKAyZcpo9+7dmjNnjrp166aJEydKuhL8T58+rZ49e6pZs2YqVaqUoqKi3Hz0AAB4Lh93FwAAAMyhbNmyGj9+vIYMGaJevXrpxIkTWrdunby9vbV48WKlpqZq5cqVqly5siSpVatWuueee/Tqq69q9uzZOnbsmMLCwjR16lTddNNNkqRmzZrpp59+0vbt2x329a9//UsjR44s9mMEAOB6RPAHAAAuc8cdd+iee+7Rhg0bNG7cON18882SpK1bt6p27doKDQ1VVlaWJMnLy0utWrXShx9+KEmqXbu2VqxYIZvNpmPHjikpKUmHDh3SkSNH7OvkqF27dvEeGAAA1zGCPwAAcKmWLVtqw4YNuu222+xjqampSkpKUt26dfNcJz09XYGBgXr77bc1b948paam6sYbb1S9evUUGBioP/74w2H+X785AAAAXBvBHwAAFLkyZcooNjZWo0ePznO5n5+fPvroI7300ksaNWqUunbtqvLly0uSnnzySe3du7c4ywUAwFQI/gAAoMjFxsbqo48+UvXq1VW6dGn7+OTJk5WZmakJEyZo586dCg4OVp8+fezL//zzT+3cuVM+PvwvCwAABcXX+QEAgCL3+OOPy2az6fHHH9eGDRu0detWPffcc1q6dKmqV68uSWrQoIEuXryol156Sdu2bdNHH32kRx55RGfPnlV6erqbjwAAgOsXH58DAIAiFxoaqlWrVmnGjBkaP368rFarqlWrphdeeEH333+/JKlLly46ceKE1q5dqxUrVig0NFS33XabHn74YT333HM6fPiwatas6eYjAQDg+mMxDMNwdxEAAAAAAKBocKk/AAAAAAAmRvAHAAAAAMDECP4AAAAAAJgYwR8AAAAAABMj+AMAAAAAYGIEfwAAAAAATIzgDwAAAACAiRH8AQAAAAAwMYI/AAAAAAAmRvAHAAAAAMDECP4AAAAAAJgYwR8AAAAAABP7fyvJHjhZItfbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1,df2,df2_grouped,df2_grouped_profit, profits = InvestmentProblem(Yearly_Season_Daily_Results, Generation_Asset_Data_New, Fuel_Cost_Data_Normalized,Fuel_Cost_Absolute,Generation_Data_Normalized,budget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
